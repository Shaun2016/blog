<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[限流]]></title>
    <url>%2F2020%2F02%2F21%2Flimit-traffic%2F</url>
    <content type="text"><![CDATA[限流算法令牌桶算法 有一个装有固定容量令牌的大桶，按照固定速率往桶里添加令牌，当装满时，新添加的令牌被拒绝添加；当一个n字节大小的数据包到达时，如果桶内令牌数大于n，从桶中删除n个令牌，放数据包通过，如果桶中令牌数不足n个，不会删除令牌，且该数据包被限流（丢弃，或进入缓冲队列等待） 1234RateLimiter limiter = RateLimiter.create(5); // 桶容量为5，且每秒增加5个令牌for (int i=0; i&lt;5; i++) // 消费一个令牌，如果桶中有足够的令牌，成功，返回0；如果桶中没有令牌，暂停一段时间直到桶中有令牌 System.out.println(limiter.acquire()); 令牌桶允许一下全部取走所有令牌，也可以消费未来的令牌，这样系统可能扛不住瞬间很大的突发请求 12345RateLimiter limiter = RateLimiter.create(5);System.out.println(limiter.acquire(10)); // 0.0 消费了未来的令牌System.out.println(limiter.acquire()); // 1.996597 由于没有令牌，要等待产生令牌System.out.println(limiter.acquire()); // 0.18827 0.2 秒产生一个令牌System.out.println(limiter.acquire()); // 0.198813 漏桶算法 有一个固定容量的漏桶，按照常量速率流出水滴，流出水滴相当于处理请求；如果水空了，不会流出；当有请求来时，流入水，如果水满了，新流入的请求被拒绝； 令牌桶和漏桶的区别： 令牌桶限制的是流入速率（固定值），允许突发请求，只要有足够的令牌即可； 漏桶限制的是流出速率，流出水滴意味着处理请求，可以平滑突发流入速率； 应用级限流可以从以下方面考虑： 限制总并发，连接数，请求数 限制总资源数：如线程池，连接池 限制某个接口的总并发/请求数（粒度更细） 限制某个接口的时间窗请求数：每秒（分钟，天）请求数 使用Guava的Cache存储计数器，过期时间为2秒，保证能够存储1秒以内访问数： 12345678910111213141516171819202122232425public static void main(String[] args) throws Exception &#123; LoadingCache&lt;Long, AtomicLong&gt; counter = CacheBuilder.newBuilder() .expireAfterWrite(2, TimeUnit.SECONDS) .build(new CacheLoader&lt;Long, AtomicLong&gt;() &#123; @Override public AtomicLong load(Long aLong) throws Exception &#123; return new AtomicLong(0); &#125; &#125;); long limit = 95; // 每秒请求最大次数 int turn = 0; // 测试中发送的请求次数 Random r = new Random(); while (turn &lt; 1000) &#123; long currentSeconds = System.currentTimeMillis() / 1000; // 发送一次请求，记录时间，统计1秒内的次数，并判断是否需要限流 if (counter.get(currentSeconds).incrementAndGet() &gt; limit) &#123; System.out.println("当前" + currentSeconds + "秒限流了：" + (counter.get(currentSeconds).longValue() - limit) + "次"); continue; &#125; // 没有被限流 // 业务代码... Thread.sleep(r.nextInt(10) + 5); // 下一次间隔5~14毫秒 turn ++; &#125;&#125; 平滑限流 以上的限流方法都不能很好地处理突发请求，即瞬间请求可以很大。一些场景需要对突发请求进行平滑，可以使用Guava提供的令牌桶实现： RateLimiter limiter = RateLimiter.create(double permitsPerSecond, long warmupPeriod, TimeUnit unit)，其中，permitsPerSecond表示每秒新增的令牌数，warmupPeriod表示从冷启动速率过渡到平均速率的时间间隔 分布式限流（不懂） 节流throttleFirst/throttleLast 在一个时间窗内，如果有多个相同事件要处理，只处理第一个（或最后一个），则一个时间段内重复的事件变为一个，减少重复事件处理的次数 应用场景：当我们使用滚轮改变浏览器放缩比时，会触发resize事件 ，当我们快速连续执行这个操作时（110%，120%，…，200%），如果连续地触发resize事件，会造成UI反应慢卡顿，节流的做法是只处理最后一个放缩命令：200% throttleWithTimeout 两个连续时间的时间间隔小于最小间隔时间窗口时，就会丢弃上一个时间，如果最后一个事件等待了最小间隔时间窗口，还没有新的事件到来，处理最后一个事件。 应用场景：搜索关键词的自动补全和下面的搜索提示列表时，如果用户每录入一个字就发送一次请求，先输入的字的自动补全很快被下一个字符覆盖，下面的提示列表也会随之变化，会导致先期的自动补全无用。throttleWithTimeout可以解决这个问题，减少频繁的网络请求，避免每输入一个字就请求一次。（在线翻译，等等场景）]]></content>
      <categories>
        <category>website architecture</category>
      </categories>
      <tags>
        <tag>website architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes]]></title>
    <url>%2F2020%2F01%2F31%2Fkubernetes%2F</url>
    <content type="text"><![CDATA[K8s的安装 环境 Master : 192.168.137.100 Slave1 : 192.168.137.101 Slave2 : 192.168.137.102 下面的操作为仅在Master中的操作，其余两台从节点也要执行相应的操作 设置主机名和时区 timedatectl set-timezone Asia/Shanghai hostnamectl set-hostname master 配置主机名对应的IP vi /etc/hosts 1234192.168.137.100 master192.168.137.101 slave1192.168.137.102 slave2192.168.137.103 slave3 关闭防火墙 123sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/configsystemctl disable firewalldsystemctl stop firewalld 安装kubeadmin XFTP上传kubernetes离线安装文件 在每个节点上安装Docker docker info | grep cgroup查看Cgroup Driver:cgroupfs tar -zxvf kube114-rpm.tar.gz cd kube114-rpm yum localinstall -y *.rpm 关闭交换区swapoff -a，vi /etc/fstap注释带有swap一行 配置网桥 12345cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.confnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1EOFsysctl --system 指令随记 cat &gt;file表示重定向输出到file中，用户输入内容后按ctrl+c结束编写内容并将内容输出到file中，注：会覆盖file中原始的内容； cat &gt;&gt; file是在file 中追加内容 上述的两个指令无法在脚本执行中使用，因为会阻塞等待用户输入，需要使用下面的指令： cat &lt;&lt;EOF &gt; file创建文件并写入内容，输入完成后以EOF结束，其中EOF只是一个字符串标记，可以随意指定，只是默认的写法是EOF；在脚本中想向文件中写入内容时使用，cat &lt;&lt;EOF &gt;&gt; file表示追加内容 echo 12345 &gt; 1.txt cat &lt; 1.txt &gt; 2.txt 在上面的两条指令中，&gt;表示输出流（&gt;覆盖&gt;&gt;追加），&lt;表示输入流，如cat &lt; 1.txt &gt; 2.txt表示将1.txt的内容做为输入，输出到2.txt中]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker容器间通讯与数据共享与Docker Compose]]></title>
    <url>%2F2020%2F01%2F28%2Fdocker-component-communication%2F</url>
    <content type="text"><![CDATA[容器间单向通信 Tomcat容器要访问MySQL容器：docker容器在创建时都会有一个虚拟IP，使用IP地址进行通讯显然不现实， 给容器命名和建立单向连接docker run -d --name database mysql创建了一个名为database的mysql容器； 创建一个名为bd_web连接到database的tomcat容器，docker run -d -p 80:8080 --link database --name bd_web tomcat 进入名为bd_web的tomcat容器访问database容器：docker exec -it xxx(database&#39;s containerID) /bin/bash，ping database，可以ping通 容器间双向通信 可以在两个容器创建时link对方的name，有更简单灵活的方法是建立网桥 创建两个容器name分别为web和database 创建网桥：docker network create -d bridge my-bridge docker network connect my-bridge web docker network connect my-bridge database 在web与database中互相可以ping通 当创建了一个网桥后，docker会创建一个虚拟网卡，不同的容器通过这个虚拟网卡进行网络通信 容器间共享数据 当很多容器中部署的相同的项目时，更新项目文件时如果需要更新很多容器的话是一件很麻烦的事，将宿主机的目录设置为Docker容器的工程目录，修改宿主机目录中的文件就可以同时对很多容器进行更新 设置挂载宿主机路径docker run --name 容器名 -v 宿主机路径:容器内挂载路径 tomcat 每次创建容器都要设置挂载路径是一件很麻烦的事情 创建共享容器docker create --name c1 -v 宿主机路径:容器内挂载路径 tomcat /bin/true 设置共享容器docker run --volumes-from c1 --name t1 -d -p 8000:8080 tomcat 这样创建容器时通过设置c1为共享容器，就挂载上了c1中挂载的宿主机路径 Docker Compose 单节点多容器的部署工具，使用yml文件定义多容器如何部署 Docker Compose的安装在https://docs.docker.com/compose按照文档： 不过使用curl在线安装docker compose很慢容易失败，我找到了一个使用离线或者pip安装的方法https://my.oschina.net/thinwonton/blog/2985886 指令随记docker inspect containerID查看容器的信息]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker镜像与容器]]></title>
    <url>%2F2020%2F01%2F26%2Fdocker%2F</url>
    <content type="text"><![CDATA[安装Docker安装环境依赖 1yum install -y yum-utils device-mapper-persistent-data lvm2 添加yum源 1yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 注：这里不需要添加国内镜像源也可以安装docker服务及客户端，添加国内镜像则要保证链接有效，并使用yum makecache fast检测哪个安装源是最快的，如： 12yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repoyum makecache fast 安装docker 1yum install -y docker-ce 配置阿里云镜像加速 1234567mkdir /etc/dockervi /etc/docker/daemon.json # 路径不能错# 加入以下内容&#123;"registry-mirrors": ["https://***.mirror.aliyuncs.com", "http://hub-mirror.c.163.com"]&#125; 其中，https://***.mirror.aliyuncs.comdocker加速器地址需要到https://cr.console.aliyun.com上注册账号后，在镜像加速器一栏中获取 启动docker服务 1service docker start 常用命令 docker pull image_name:tag从远程仓库下载镜像 docker images查看本地镜像 docker run image_name创建容器，运行镜像 docker ps查询运行中的容器 docker ps -a列出所有容器（包括没有运行的） docker rm (-f)（强制）删除容器 docker rmi (-f)（强制）删除镜像 注：容器和镜像的存放位置：/var/lib/docker下containers存放创建的容器，image下存放创建的镜像 运行Tomcat镜像容器 docker pull tomcat拉去Tomcat镜像 在https://hub.docker.com网站上有镜像的不同版本，指定对应的tag，如docker pull tomcat:jdk8-openjdk，若不加tag为最新版本 端口映射：docker run -p 8000:8080 -d tomcat 宿主机对外的端口为8000，映射到内部运行的docker容器的8080端口 -d表示后台运行 或者先创建容器后运行：docker create -p 8000:8080 tomcat，查看创建容器的containerID：docker ps -a，运行容器：docker start containerID netstat -tulpn查看运行的进程的端口 停止运行的容器 docker ps查看容器的Container ID docker stop containerID停止容器 docker rm -f containerID删除容器 在容器中执行命令 docker exec -it containerID /bin/bash 执行apt-get update 执行apt-get install vim 进入webapps文件夹，创建文件夹并进入，创建index.html，通过浏览器访问tomcat服务 这样可以在docker容器中发布一个主页，但是通过vim编辑网页是很麻烦的，大型的项目需要整体提交到docker容器中，如何将web项目上传到docker容器中的指定目录下呢？ Dockerfile 构建镜像1234FROM tomcat:latestMAINTAINER xxx.comWORKDIR /usr/local/tomcat/webapps # 要将工程拷贝到宿主机里的路径ADD docker-web ./docker-web # 将docker-web下的文件复制到/usr/local/tomcat/webapps/docker-web下 将docker-web和Dockerfile上传到宿主机中，在上传文件夹中执行： docker build -t xxx.com/docker-web:1.0 . 构建镜像 通过docker images查看创建的镜像：可以发现 运行镜像文件：docker run -d -p 80:8080 xxx.com/docker-web:1.0 注：一定要在镜像名后面加上TAG 这样运行起来的Tomcat容器就已经含有docker-web工程了，不过如何对容器中的工程进行更新呢？可以找到在宿主机上工程的文件路径，然后进行文件的替换，如docker inspect containerID查看GraphDriver.Data.MergedDir和GraphDriver.Config.WorkingDir，就可以找到容器中tomcat在宿主机中的目录，然后进入webapps中更新工程，这样做对一个容器更新项目还好，如果有很多Tomcat容器都运行相同的web服务，更新起来就比较麻烦了，后文会介绍共享目录的方式的更新容器中的项目 Dockerfile 中的指令 RUN在构建镜像时执行，CMD|ENTRYPOINT在创建容器时执行 指令的两个格式 Shell格式：创建子进程执行脚本 Exec格式：不创建子进程，创建新的进程替换当前进程执行脚本 注：推荐使用Exec的方式 RUNENTRYPOINT 入口点，用于容器启动时执行的命令 CMD CMD用于设置容器启动时的附加指令，Dockerfile中只有最后一条CMD会被执行，如果容器启动时人为给出附加指令，则CMD被忽略 例如在Dockerfile中编辑如下： 1234FROM tomcatRUN ['echo', 'image building']ENTRYPOINT ['echo', 'entrypoint of container ']CMD ['container starting'] 构建竟像时，输出：image building 构建容器时，输出：entrypoint of container container starting 如果构建容器时加入了其他指令，如docker run xxx.com/dc_run:1.1 aaaa输出：`entrypoint of container aaaa，说明CMD被替换了，而Entropoint没有被替换； 下面是一个用 Dockerfile 构建 redis 镜像的实例： 12345678910FROM centosRUN ["yun", "install", "-y", "gcc", "gcc-c++", "net-tools", "make"]WORKDIR /usr/localADD redis-4.0.14.tar.gzWORKDIR /usr/local/redis-4.0.14/srcRUN make &amp;&amp; make installWORKDIR /usr/local/redis-4.0.14ADD redis-7000.confEXPOSE 7000CMD ["redis-server", "redis-7000.conf"] 当然，在https://hub.docker.com网站上已经有构建好的redis镜像，完全没有必要自己从centos开始构建镜像]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[load_balance_reverse_proxy]]></title>
    <url>%2F2020%2F01%2F25%2Fload-balance-reverse-proxy%2F</url>
    <content type="text"><![CDATA[GSLB LVSF5负载均衡算法 round-robin (default)：轮训 ip_hash：相同ip的请求发送到相同的服务器 hash key 哈希算法 一致性哈希算法 least_conn：将请求发送到最小活跃连接的上游服务器上 失败重试1234upstream backend &#123; server 192.168.31.1:8080 max_fails=2 fail_timeout=10s weight=1; server 192.168.31.2:8080 max_fails=2 fail_timeout=10s weight=2;&#125; 当fail_timeout内失败了max_fails次请求，认为该上游服务器不可用，移除该服务器，尝试下一台服务器 健康检查 TCP心跳检查 12345upstream backend &#123; server 192.168.31.1:8080 max_fails=2 fail_timeout=10s weight=1; server 192.168.31.2:8080 max_fails=2 fail_timeout=10s weight=2; check interval=3000 rise=1 fall=3 timeout=2000 type=tcp;&#125; interval 每隔3秒检查一次，timeout 连接超时为失败一次，fall 失败3次后标记为不存活，rise 成功1次后标记为存活 HTTP 心跳检查]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python program skill]]></title>
    <url>%2F2019%2F11%2F16%2Fpython-program-skill%2F</url>
    <content type="text"><![CDATA[写项目中遇到的小技巧记录 检查 key 是否存在123d = &#123;1:2, 3:4&#125;print(1 in d) # Trueprint(2 in d) # False 对 dict 排序12345678dict1 = &#123;1: 4, 2: 1, 3: 2&#125;d1 = sorted(dict1.items(), key=lambda d: d[1]) # 按 value 升序print(d1) # [(2, 1), (3, 2), (1, 4)] d2 = sorted(dict1.items(), key=lambda d: d[1], reverse=True) # 按 value 降序print(d2) # [(1, 4), (3, 2), (2, 1)] d3 = sorted(dict1.items(), key=lambda d: d[0]) # 按 key 升序print(d3) # [(1, 4), (2, 1), (3, 2)] print(dict1) # &#123;1: 4, 2: 1, 3: 2&#125; 注：sorted函数不会改变排序对象 集合运算12345x&amp;y # 交集x|y # 并集x-y # 差集x.issubset(y) # x 是否为 y 的子集x.issuperset(y) # x 是否为 y 的父集 由已有的list做为key建立dict12d=&#123;&#125;.fromkeys([1,2,3]) # &#123;1: None, 2: None, 3: None&#125;d=dict().fromkeys([...]) python 线程与线程池创建线程的两种方法：_thread和threading _thread 1234567import _threadimport timedef crawl(url, name): print(url, name) time.sleep(2)_thread.start_new_thread(crawl, ('www', 'thread-1'))time.sleep(5) # 阻塞主线程，否则子线程也会被销毁 _thread.start_new_thread(function, args)，args为传递给线程函数的参数，为tuple类型 threading 123456import threadingdef crawl(url, name): print(url, name) time.sleep(2)thread1 = threading.Thread(target=crawl, name='thread-1', args=('www', 'zjm'))thread1.start() 区别：在主线程执行完毕后，_thread创建的线程如果还存活，会直接结束；threading创建的线程如果还存活，会等待子线程完成后再退出 线程池 12345678910111213from concurrent.futures import ThreadPoolExecutorimport timedef crawl(url, name): print(url, name) time.sleep(2)urls = ['www.baidu.com', 'www.tencent.com', 'www.taobao.com']# submit的形式: 每次都要提交一个目标函数和对应的参数with ThreadPoolExecutor(3) as executor: # 线程数 for index, url in enumerate(urls): executor.submit(crawl, url, 'Thread-'+str(index))# map的形式: 只需要提交一次目标函数，目标函数的参数以列表形式传入with ThreadPoolExecutor(3) as executor: executor.map(crawl, urls, ['Thread-'+str(_) for _ in range(len(urls))]) list 反转1l = l[::-1] 返回list中值为1的下标12l = np.array([1, 0, 0, 1, 1]) # 必须是numpy的array类型，list类型不可以d = np.where(l == 1) # tuple:(array([0, 3, 4], dtype=int64),) 注：np.where返回的是tuple类型，要取到数组还需要访问：d[0] 两个 np.array类型的数组做差集后保持原始顺序1234a = np.array([3, 2, 0, 1])b = np.array([2])c = np.setdiff1d(a, b) # [0 1 3] 去掉 b 中的元素后排序了d = a[~np.in1d(a, b)] # [3 0 1] 没有排序]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 写实验的时候遇到的矩阵操作]]></title>
    <url>%2F2019%2F11%2F11%2Fpython-math-skill%2F</url>
    <content type="text"><![CDATA[矩阵平铺成向量12a = np.array([[3,4],[1,2]])b = a.reshape(-1) 返回排序下标，向量反转12bsortIndex = np.argsort(b) # [2 3 0 1]bsortIndex = bsortIndex[::-1] 取二维数组的某一列123a = [[1,3],[2,5]]a[:,0] # 第一列a[:,1] # 第二列 保留三个小数12a = 12.3456round(a, 2) # 12.346 矩阵求和1234567# 按列求和c = np.array([[1, 3], [2, 0]])print(np.sum(c, axis=0)) # [3, 3]# 按行求和print(np.sum(c, axis=1)) # [4, 2]# 全部和print(np.sum(c)) # 6 矩阵变形123# 一维变二维c = np.array([1, 3, 2, 0, 6])print(c.reshape(len(c), 1)) ### [[1], [3], [2], [0], [6]] 矩阵值替换123# 将数组的0替换为1 (前提是0为最小值)c = np.array([1, 3, 2, 0, 6])print(c.clip(min=1)) # [1 3 2 1 6] 行向量与列向量123456[1, 3] # 对于给出的一维数组，都是列向量：两行一列，shape=(2,1)[[1, 2]] # 行向量，一行两列，shape=(1,2)# 列向量变行向量np.array([1,2,3]).reshape(1,-1)# 列向量变行向量np.array([[1,2,3]]).T 矩阵与向量的乘法1234567a = np.array([1, 3])b = np.array([1, 3]).reshape(1, -1)c = np.ones([2, 3])# 注意相乘的顺序：矩阵(n*m)*向量(m*1)(列向量)np.matmul(c.T, a)# 向量(1*m)*矩阵(m*n)np.matmul(b, c)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql 事务隔离级别与锁的使用]]></title>
    <url>%2F2019%2F09%2F13%2Fmysql-transaction-isolation%2F</url>
    <content type="text"><![CDATA[事物的隔离级别 事务的隔离级别 脏读 不可重复读 幻读 读未提交 (READ UNCOMMITTED) √ √ √ 读已提交 (READ COMMITTED) √ √ 可重复读 (REPEATABLE READ) √ 串行化 (SERIALIZABLE) 查看提交方式：select @@autocommit; 改为手动提交：set autocommit=0 读未提交首先开启两个会话，分别设置事物的隔离级别为读未提交： set session transaction isolation level read uncommitted; 在一个会话中更新一个字段，并未提交，但是在另一个会话中可以看到更新的字段值，属于脏读； 读已提交set session transaction isolation level read committed; 在一个会话中开启一个事务A：begin或start transaction，查询一个字段值，在另一个会话B中修改这个字段值并提交，如果在事务A中再次查询得到了B更新的值，则在一个事务中重复读结果不一致，属于不可重复读 可重复读set session transaction isolation level repeatable read; 可重复读保证了在一个事务中每次查询的结果都是一致的，只有将此次事务commit;后才能查询到变动的值； 在一个会话中开启事务A，在另一个事务中开启事务B，A中插入id=4的记录并提交，B 中虽然读不到id=4的记录，但是B也插入 id=4 的记录时报错，发生幻读 串行化set session transaction isolation level serializable; 隔离性实现原理：锁mysql 中，锁分为： 共享锁（读锁）：对已经锁定的对象不能更新，可以读 排它锁（写锁）：对已经锁定的对象不能读，也不能更新 mysql 中，锁的粒度： ​ 记录(行)，表，数据库]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>transaction</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 多线程]]></title>
    <url>%2F2019%2F09%2F09%2Fjava-threads%2F</url>
    <content type="text"><![CDATA[Semaphore的应用场景与使用实例 在停车场中有5个停车位，现有十辆车想进入停车场，每辆车最多停留 1000 ms，每辆车随机抢占车位，但要保证一个车位只有一辆车 Semaphore 是信号量，内部有一个成员变量int state，调用acquire()方法，如果state大于0，将state减一，如果state不大于0，会阻塞，直到其他线程调用release()方法，将state加一 12345678910111213141516171819202122232425262728public class CarPark &#123; public static void main(String[] args) &#123; BlockingQueue&lt;Integer&gt; parks = new LinkedBlockingQueue&lt;&gt;(5); for (int i=0; i&lt;5; i++) parks.offer(i); Semaphore semaphore = new Semaphore(5); List&lt;Thread&gt; list = new ArrayList&lt;&gt;(); for (int i=0; i&lt;10; i++) &#123; list.add(new Thread(()-&gt;&#123; try &#123; // 占用车位 semaphore.acquire(); int parkNum = parks.take(); System.out.println(parkNum); Thread.sleep(2000); // 释放车位 parks.offer(parkNum); semaphore.release(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;)); &#125; for (Thread t : list) &#123; t.start(); &#125; &#125;&#125; ThreadLocal 的应用场景与使用实例 有三个用户，服务器要为每个登陆的用户创建一个线程，如果当天登陆了就将登陆次数加一； ThreadLocal可以让共享变量对每个线程都是内部的，各个线程之间的是相互独立的，不会相互影响；实现原理简单的说：是ThreadLocal内有一个线程安全的 map，线程的 id 作为 key，实例对象为 value； 12345678910111213141516171819202122public class LoginTimeLogs &#123; private static ThreadLocal&lt;Integer&gt; loginTimeInMonth = new ThreadLocal&lt;Integer&gt;() &#123; @Override protected Integer initialValue() &#123; return Integer.valueOf(0); &#125; &#125;; public static void main(String[] args) &#123; for (int i=0; i&lt;3; i++) &#123; new Thread(()-&gt;&#123; // 假设每个用户都是每天都登陆 for (int j=1; j&lt;=7; j++) &#123; loginTimeInMonth.set(loginTimeInMonth.get()+1); System.out.println(Thread.currentThread().getName() + " " + loginTimeInMonth.get()); &#125; &#125;, "t"+i).start(); &#125; &#125; &#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Semaphore</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mycat 表分库与读写分离]]></title>
    <url>%2F2019%2F08%2F17%2Fmycat-sub-library-and-rw-separation%2F</url>
    <content type="text"><![CDATA[分库分表，读写分离都是数据库层面的负载均衡策略，由于单节点数据库存在单点故障和响应瓶颈，人们希望数据库以集群的形式对外提供服务，实现高可用，为了管理集群数据库，产生了Mycat这款中间件 Mycat是阿里开发的开源的数据库分库分表中间件，mycat管理多节点的mysql，请求访问数据时，由mycat处理这条请求应该发送到哪个或哪些节点上执行操作，对外界就像访问单节点的 mysql 一样 MyCat 安装及配置安装 上传压缩包解压即可 配置server.xml 设计 mycat 服务端口号（默认8066），登陆名密码等，用户操作权限 schema.xml 设计逻辑库，逻辑表与实际库的映射关系： 12345678910111213141516171819&lt;?xml version="1.0"?&gt;&lt;!DOCTYPE mycat:schema SYSTEM "schema.dtd"&gt;&lt;mycat:schema xmlns:mycat="http://io.mycat/"&gt; &lt;schema name="TESTDB" checkSQLschema="false" sqlMaxLimit="100"&gt; &lt;table name="student" dataNode="dn1,dn2,dn3" rule="crc32slot" /&gt; &lt;/schema&gt; &lt;dataNode name="dn1" dataHost="localhost1" database="db1" /&gt; &lt;dataNode name="dn2" dataHost="localhost1" database="db2" /&gt; &lt;dataNode name="dn3" dataHost="localhost1" database="db3" /&gt; &lt;dataHost name="localhost1" maxCon="1000" minCon="10" balance="1" writeType="0" dbType="mysql" dbDriver="native" switchType="1" slaveThreshold="100"&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host="hostM1" url="master:3306" user="root" password="root"&gt; &lt;readHost host="hostS1" url="slave:3306" user="root" password="root" /&gt; &lt;/writeHost&gt; &lt;/dataHost&gt;&lt;/mycat:schema&gt; TESTDB 是逻辑库(schema)，student 是逻辑表，将 student 表分片到三个 dataNode : dn1, dn2, dn3 中，对应三个实际库：db1, db2, db3，上图的配置中，三个实际库都在 dataHost : localhost1 中，对应主节点 master 及其从节点 slave。即在 mycat 中的 student 的数据实际上是存储在 master 节点的 mysql 中的三个库 db1, db2, db3 中的 student 表中，slave 节点为 master 的备份节点 rule.xml123&lt;function name="crc32slot" class="io.mycat.route.function.PartitionByCRC32PreSlot"&gt; &lt;property name="count"&gt;3&lt;/property&gt;&lt;!-- 要分片的数据库节点数量，必须指定，否则没法分片 --&gt; 启动和访问Mycat服务 将 mycat/bin 添加到环境变量，执行 mycat start 启动 mycat 服务，mycat status 查看服务状态，mysql -uroot -p123456 -hmaster -P8066 进入 mycat 的 DBMS，可以看打 mycat 中有一个库为 TESTDB，里面有一个表 student，而实际对应的mysql中并没有db1, db2, db3这三个库，需要手动创建 注：搭建 Mycat 分表和读写分离是建立在Mysql主备模式已经建立的基础上 分表 当一张表中字段数非常多时，会影响查询效率，我们希望将数据分散到多个表中，有两种方法：1. 可以放到一个库的不同表中，2. 也可以放到多个库的不同表中；放到多个库的不同表中可以令表名相同，方便管理，如下图： 手动建库 在 master 节点中创建库：create database db1, create database db2, create database db3 mycat中建表 虽然在 mycat 中能看到 TESTDB 库中已经有了 student 表，但这是在配置文件中读到的逻辑表，实际表没有创建，这里不需要到 master 中手动自己创建，在 mycat 中执行建表语句，会自动在对应的物理库中生成对应的表： 1create table student(id int not null primary key, name varchar(24), age int); 新增的 _slot 字段用来保存 crc32slot 分片算法为每条记录计算结果，用来散列记录到某个表中，避免迁移时重新计算 分表结果 在 MySQL 实际表中查询结果： 在 Mycat 的逻辑表中查询结果： 读写分离 Mycat 将读请求发送给多个从库处理，增删改请求发送给主库，达到负载均衡的效果 在 schema.xml 中配置 dataHost 的属性：（官网文档抄的，我还没有配置主备HA） balance=”1” 表示：全部的 readHost 与 stand by writeHost 参与 select 语句的负载均衡，简单的说，当双主双从模式(M1-&gt;S1，M2-&gt;S2，并且 M1 与 M2 互为主备)，正常情况下，M2,S1,S2 都参与 select 语句的负载均衡 或者：balance=”3” 表示：所有读请求随机的分发到 writerHost 对应的 readhost 执行，writerHost 不负担读压力 writeType=”0” 表示：所有写操作发送到配置的第一个 writeHost，第一个挂了切到还生存的第二个 writeHost 12345678&lt;dataHost name="localhost1" maxCon="1000" minCon="10" balance="1" writeType="0" dbType="mysql" dbDriver="native" switchType="1" slaveThreshold="100"&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host="hostM1" url="master:3306" user="root" password="root"&gt; &lt;readHost host="hostS1" url="slave:3306" user="root" password="root" /&gt; &lt;/writeHost&gt; &lt;/dataHost&gt; 为了验证读到的是从节点的数据，可以手动修改一条记录，使其与主结点中对应记录不同，如果结果是修改过的说明是从节点中读的 遇到问题 无法将查询请求发送到从节点 实验中读到的是主节点中的值，通过 logs/mycat.log 中发现 mycat 无法连接从节点：io.mycat.sqlengine.SQLJob.connectionError(SQLJob.java:114)) - can&#39;t get connection for sql :select user()，即 mycat 通过schema.xml 中的 readHost中从节点的 url，用户名密码去访问被拒绝；在从节点的 mysql 库的 user 表中添加用户： 12grant all privileges on *.* to 'username'@'ip' identified by 'password' with grant option;flush privileges; 其中：username=root, password=root, 第一次我将 ip 设为 master，经测试 mycat 依旧无法连接，改为 ip 后连接成功，可以查询到从库的数据 注：从库是为了备份主库数据和响应读请求的，可以使用更适合读请求的 MyISAM 存储引擎，从库数据要与主库保持一致，自己手动修改只是为了测试读写分离，如果在从库中修改了数据主库不会同步，造成不一致 Referencemycat中文指南手册]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>mycat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql 主从备份]]></title>
    <url>%2F2019%2F08%2F16%2Fmysql-master-slave-backup%2F</url>
    <content type="text"><![CDATA[概述：在两台虚拟机master和slave中安装相同版本的 mysql，在master中的mysql做为主库，slave中的mysql做为从库，对主库和从库配置，从库可以从主库的日志文件中读取SQL语句并执行，从库中的数据就和主库中一致，到达备份的目的；主从库除了保障了数据的安全性，还可以做读写分离，从库负责读请求，主库负责写请求 主库配置修改主库配置文件 编辑/etc/my.cnf，加入以下配置： 12server-id = 1log_bin = master_log server-id 是mysql服务的标识，master的标识必须小于slave的标识 log_bin 是日志文件名，记录主库执行的除了查询以外的SQL指令，slave要读取的文件，mysql会自动增加文件后缀名和文件类型 重启mysql服务 service mysqld restart 为从库创建访问用户 进入mysql DBMS: mysql -u username -p password，执行： 12grant all privileges on *.* to 'username'@'ip' identified by 'password' with grant option;flush privileges; 其中，ip 是从库所在服务器的ip地址(注：经测试，不能是域名)，执行完，就向 mysql 库的 user 表中添加了一个用户，对应从库的 ip 和使用的用户 从库配置修改 slave 配置文件 vi /etc/my.cnf，添加server-id = 2，这里要大于主库的server-id即可，不要和其他从库重复 同上，重启 mysql 服务 查看主库日志文件 在主库DBMS中执行：show master status;，查看日志文件名 配置主库信息 进入DBMS：mysql -uroot -proot ，先停止slave功能：stop slave;，将主库的ip或域名，主库提供的对应从库的用户名密码，日志文件（上图中的文件名）输入到主库信息中： 12change master to master_host=&apos;master&apos;, master_user=&apos;slave&apos;, master_passowrd=&apos;slave&apos;, master_log_file=&apos;master_log.000002&apos;; 执行完，开启slave：start slave; 查看slave情况 执行show slave status \G; 查看slave连接情况： 图二中没有错误就是连接成功，且没有执行错误的sql语句 验证 在主库中创建数据库，数据表，插入记录，在从库中查询结果 遇到的问题从库执行日志记录出错 在从库读取主库日志文件时，我遇到了 Last_IO_Error: Got fatal error 1236 from master 在执行主库日志记录过程中出现了执行错误，应该是主从库初始状态不一致导致的，我的主库中原来是有自己创建的库的，如果日志中有对这个库的操作，那么从库执行这些代码都会报错，虽然我删除了自己创建的库让主从库的库一样，并在my.cnf中修改日志文件名，企图在新的日志文件中重新记录，但是从库执行依旧报错 解决方法 首先在从库执行stop slave;命令，将同步停止， 然后在主库中执行flush logs;命令，刷新日志， 在主库中执行show master status;来查看当前日志的位置 在从库中执行change master to master_log_file=&#39;master_log.000002&#39;, master_log_pos=964; 在从库中开启slave: start slave 启动同步，查看 slave 状态 此外，还有主从库版本不同带来的问题，我换成相同版本问题消失，但是不同版本的解决方案我没有测试]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java proxy 代理模式]]></title>
    <url>%2F2019%2F07%2F24%2Fproxy%2F</url>
    <content type="text"><![CDATA[代理模式：当用户不想直接访问对象，而是通过代理类来访问对象，代理类可以帮助用户包装，加工对象，比如学校想购买一批电脑，学校不直接和电脑厂商联系，而是通过销售人员，销售人员帮学校给电脑装指定的操作系统、驱动、杀毒办公软件等 代理模式分为静态代理和动态代理 静态代理 代理确定类型的对象，不同的代理实现同一个接口，代理内部聚合接口类型的属性，可以将代理之间相互嵌套，被代理对象也实现相同的接口 1234567891011121314151617181920212223242526class Car implements Movable &#123; public void move() &#123; System.out.println("I'm a car, I'm running..."); &#125;&#125;class LogProxy implements Movable &#123; private Movable movable; public LogProxy(Movable movable) &#123; this.movable = movable; &#125; public void move() &#123; // ...logs this.movable.move(); // ...logs &#125;&#125;// similarity, another proxy just like LogProxyclass AuthProxy implements Movable &#123; private Movable movable; public void move() &#123; //... &#125;&#125;interface Movable &#123; void move();&#125; 1234567public static void main(String[] args) &#123; new LogProxy( new AuthProxy( new Tank() ) ).move();&#125; 动态代理 代理不确定类型的对象，生成代理的两种方式： jdk 的动态代理，必须让被代理的类实现某个接口； cglib 生成代理 二者都是使用 ASM 操作二进制文件修改类的属性和方法 jdk 的动态代理的代理类 被代理类一定要实现某个接口，下面先定义接口Actor和被代理类Singer 12345678910111213public interface Actor &#123; void sing(); void dance();&#125;public class Singer implements Actor &#123; public void sing(String song, int volume) &#123; System.out.println("I'm a singer, I can sing " + song + "at volume " + volume); &#125; public void dance() &#123;/*...*/&#125;;&#125;public class Dancer implements Actor &#123; //...&#125; 单例的动态代理类，传入委托类(被代理类)，返回动态代理对象 1234567891011121314151617public class ActorInvocationHandler implements InvocationHandler &#123; private ActorInvocationHandler() &#123;&#125; private static ActorInvocationHandler singleton = new ActorInvocationHandler(); private static Class tClass; public static Object createProxy(Class c) &#123; tClass = c; return Proxy.newProxyInstance(tClass.getClassLoader(), tClass.getInterfaces(), singleton); &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println("... start singing ..."); Object res = method.invoke(tClass.newInstance(), args); System.out.println("... end singing ..."); return res; &#125;&#125; 123456public static void main(String[] args) &#123; Actor actor = (Actor) ActorInvocationHandler.createProxy(Dancer.class); actor.dance(); Actor singer = (Actor) ActorInvocationHandler.createProxy(Singer.class); singer.sing("Always with you", 5);&#125; cglib实现代理类 对委托类不需要实现接口，但是委托类不能是 final 123456789101112131415161718public class SingerLogInterceptor implements MethodInterceptor &#123; private SingerLogInterceptor() &#123;&#125; private static SingerLogInterceptor interceptor = new SingerLogInterceptor(); private static Class targetClass; private Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; System.out.println("log start..."); Object result = methodProxy.invokeSuper(o, objects); System.out.println("log end..."); return result; &#125; public static Object getInstance(Class c) &#123; targetClass = c; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(targetClass); enhancer.setCallback(interceptor); return enhancer.create(); &#125;&#125; 12345class Singer &#123; public void sing(String song, int volume) &#123; System.out.println("I'm a singer, I can sing " + song + "at volume " + volume); &#125;&#125; 1234public static void main(String[] args) &#123; Singer singer = (Singer) SingerLogInterceptor.getInstance(Singer.class); singer.sing("Always with you", 5);&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>proxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java8 hashmap 的几点细节]]></title>
    <url>%2F2019%2F07%2F16%2Fhashmap%2F</url>
    <content type="text"><![CDATA[前言 哈希表是存储不连续主键的数据结构，如果主键是连续的，如[1,100]，可以直接将主键作为下标用数组存放。但是很多情况主键不是连续的，或者值很大，如学号(2013201320)，就要用哈希表存储。哈希表也是数组，只是存放时不是直接将主键作为下标，先通过散列函数计算应该放的位置，如：n=k%m，其中k是主键值，m是哈希表长度（数组长度），n为应该存放的位置。这样，n一定小于m，不会数组越界。但是可能发生冲突，即两个k计算的n一样，这样就需要有解决哈希冲突的策略。当需要查询时，先经过散列函数计算位置，如果主键值不是我们想要的，需要按照散列冲突去寻找主键。好的散列函数需要将主键在数组中分布的尽量均匀，一般数组长度取2的n次幂周围的素数 HashMap 是很常用的集合类，用于存储键值对(Node)。jdk1.7中hashmap用数组和链表实现，可是链表的查询效率低；在jdk1.8中hashmap使用数组+链表+红黑树的形式实现，当链表长度大于8时，会转成红黑树，提高了查询效率：O(n)到O(lgn)，本文对jdk1.8中hashmap实现中的几个有意思的细节进行叙述 如何计算 key 的hash值 由于key任意类型，要先将key变成int型。作法为：key.hashcode()的高16位与低16位的异或运算值，这样利用了所有位上的数字，使分布更均匀 图中&gt;&gt;&gt;符号为无符号右移，&gt;&gt;为带符号右移 冲突时怎么办 有了key的hash值，就可以用散列函数计算下标，如果下标处没有存Node，直接存在数组中，如果已有Node，则以链表的形式向后遍历，如果遍历过程中没有遇到相同 key 的，在链表最后插入Node，如果插入Node时链表长度大于等于8，要将链表转红黑树；如果遇到相同的key，则将新的 value 替换旧的 value 为什么hashMap数组的初始长度为2的幂位运算代替取模运算 在哈希表中，为了使 key 分布尽量均匀，一般取 2n 周围的素数，而 jdk 中 hashmap 的数组初始长度为1&lt;&lt;4=16，还强调数组长度必须是2的幂。我们知道取模运算的效率很低，对于每个 key 的hash值都要做取模运算，这个代价是很大的。如果将数组长度取2n ，可以将取模计算转化为位运算，使得效率大大提高 对于一个 int 型数字 x，用32位字节存储，如10010110...01010111，对于 y=2n (n=4) 的二进制是00000000...00010000，则 x%y 只与 x 的二进制的后4位有关，与前面的数字无关，如何取到x的二进制的 后四位呢，即用x&amp;0000...00001111，而0000...00001111=0000...00010000-1，总结为如下公式： x\%y=x\&(y-1),y=2^n扩容时的重定位 当hashmap的数组已用容量到达总容量的3/4时，需要扩容为当前容量的2倍： 2n+1，这样，所有存放的对象都要根据 key 重新定位，不然查询的时候就取不到了啊。在重新计算定位数组下标时，假设原来数组长度为16= 24 ，扩容后为32= 25 ，则现在要取二进制后五位，多的只是倒数第五位，如果倒数第五位为0，则扩容前后位置不变，如果倒数第五位为1，扩容后位置=扩容前位置+24]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>hashmap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Design Pattern]]></title>
    <url>%2F2019%2F07%2F15%2FDesignPattern%2F</url>
    <content type="text"><![CDATA[Strategy 策略模式 做一件事情有不同的执行方法时 典型案例：不同类型对象的排序：Comparator 接口 对于自定义类的排序，排序的策略肯定不同，使用Arrays.sort(T[] a, Comparator&lt;? super T&gt; c)排序时需要将一个Comparator对象传入，可以建立一个类去实现Comparator接口，也可以用匿名内部类以及lambda表示式 1234567891011Cat[] cats = &#123;new Cat(4, 5), new Cat(6, 2), new Cat(3, 8)&#125;;Arrays.sort(cats, new Comparator&lt;Cat&gt; () &#123; @Override public int compare(Cat o1, Cat o2) &#123; return 0; &#125;&#125;);// lambda 表示式代替匿名内部类Arrays.sort(cats, (c1, c2)-&gt;&#123; return c1.getWeight() - c2.getWeight();&#125;); Factory Method &amp; Abstract Method 工厂方法和抽象工厂Mediator 调停者 消息中间件 Decorator 装饰器Chain Of Responsibility 责任链 要对某件事情做一系列不同操作，如果将这些操作都写在一起，代码很多逻辑很乱，将每个操作单独在一个类中，方便扩展；将这些操作用一个链条串起来，链条之间也可以串起来，就构成了责任链 单独封装 有一个可能包含敏感词汇或非法字符的字符串 s，要对 s 进行过滤，使 s 合法，敏感词汇是随着时间变化的，我们希望方便灵活的制定过滤规则，首先将不同的过滤器单独的制定出来 1234567891011121314151617interface Filter &#123; boolean doFilter(String s);&#125;class SensitiveFilter implements Filter&#123; @Override public boolean doFilter(String s) &#123; s = s.replaceAll("炸弹", ""); return true; &#125;&#125;class ScriptFilter implements Filter &#123; @Override public boolean doFilter(String s) &#123; s = s.replaceAll("&lt;", "]").replaceAll("&gt;", "]"); return true; &#125;&#125; 链条 将过滤器都放进一个链条中 1234567891011121314class FillterChain &#123; List&lt;Filter&gt; filters = new ArrayList&lt;&gt;(); public FilterChain add(Filter f) &#123; this.filters.add(f); return this; &#125; public boolean doFilter(String s) &#123; for (Filter f : filters) &#123; if (!f.doFilter(s)) return false; &#125; return true; &#125;&#125; 执行1234567public static void main(String[] args) &#123; String s = "..."; FilterChain chain = new FilterChain(); chain.add(new ScriptFilter()).add(new SensitiveFilter()); chain.doFilter(s); System.out.println(s);&#125; Observer 观察者 事件处理模型，当一个 source (源对象，被观察的对象) 发出某个Event（动作，事件）时，Observer（观察者）对这个动作做出反应 源对象 将观察者列表作为属性，有添加观察者，执行观察者的方法；在执行观察者方法时要创建对应的事件，并传入观察者的执行方法中 12345678910111213class Button &#123; private List&lt;ButtonListener&gt; buttonListeners = new ArrayList&lt;&gt;(); public void buttonPress() &#123; ActionEvent event = new ActionEvent(System.currentTimeMillis(), this); for (ButtonListener listener:buttonListeners) &#123; listener.actionPerformed(event); &#125; &#125; // 添加观察者 public void addListener(ButtonListener listener) &#123; this.buttonListeners.add(listener); &#125;&#125; 事件 事件中包含事件源，即发出事件的对象，观察者需要这个源对象 1234567891011121314class ActionEvent &#123; long when; Object source; public ActionEvent(long when, Object source) &#123; this.when = when; this.source = source; &#125; public long getWhen() &#123; return this.when; &#125; public Object getSource() &#123; return this.source; &#125;&#125; 观察者123456789101112131415interface ButtonListener &#123; public void actionPerformed(ActionEvent e);&#125;class ButtonPressListener1 implements ButtonListener &#123; @Override public void actionPerformed(ActionEvent e) &#123; System.out.println("ButtonListener1 at " + e.when + ", do something..."); &#125;&#125;class ButtonPressListener2 implements ButtonListener &#123; @Override public void actionPerformed(ActionEvent e) &#123; System.out.println("ButtonListener2 at " + e.when + ", do something too..."); &#125;&#125; 执行123456public static void main(String[] args) &#123; Button b = new Button(); b.addListener(new ButtonPressListener1()); b.addListener(new ButtonPressListener2()); b.buttonPress();&#125; Composite 组合Flyweight 享元 字符串常量池 Iterator 迭代器 容器的遍历 1234567public static void main(String[] args) &#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); Iterator&lt;Integer&gt; iterator = list.iterator(); while (iterator.hasNext()) &#123; System.out.println(iterator.next()); &#125;&#125; Visitor 访问者Builder 构建器 构建复杂对象：属性多，属性中还含有属性的对象 Adapter(Wrapper) 适配器 例：将 FileInputStream 转成 Reader，再交给 BufferedReader(Reader) 12345678910public static void main(String[] args) throws Exception &#123; FileInputStream fis = new FileInputStream("..."); InputStreamReader isr = new InputStreamReader(fis); BufferedReader br = new BufferedReader(isr); String line = br.readLine(); while(line != null &amp;&amp; !line.equals("")) &#123; System.out.println(line); &#125; br.close();&#125; Bridge 桥接 双维度扩展 情景：维度1：温和，凶猛，敏捷；维度2：狮子，老虎，小猫；如果将维度1和维度2组合，会出现9种情况，如果每种情况都写成一个类的话，类的个数会非常的多（类爆炸） 用聚合的方式将维度1包含维度2，使类的个数为n+m，而不是n*m 12345678910111213141516171819202122public class Main &#123; public static void main(String[] args) &#123; Animal cat = new CuteAnimal(new Cat()); Animal tiger = new ScaredAnimal(new Tiger()); &#125;&#125;abstract class Animal &#123; AnimalImpl impl;&#125;class CuteAnimal extends Animal &#123; public CuteAnimal(AnimalImpl impl) &#123; this.impl = impl; &#125;&#125;class ScaredAnimal extends Animal &#123; public ScaredAnimal(AnimalImpl impl) &#123; this.impl = impl; &#125;&#125;class Cat extends AnimalImpl &#123;&#125;class Tiger extends AnimalImpl &#123;&#125;abstract class AnimalImpl &#123;&#125; Command 命令Memento 备忘录 记录快照，存盘恢复前状态 对象要实现标记接口：Serializable，即可以序列化和反序列化，将对象的状态存入文件，可从文件中读取恢复对象的状态 1234567891011121314151617181920212223242526272829303132333435363738394041424344public static void save() &#123; Person p = new Person(1, "zjm"); Location l = new Location("2", "3"); File f = new File("H:\\study\\person.data"); ObjectOutputStream oos = null; try &#123; if (!f.exists()) f.createNewFile(); oos = new ObjectOutputStream(new FileOutputStream(f)); oos.writeObject(p); oos.writeObject(l); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125;public static void load() &#123; File f = new File("H:\\study\\person.data"); ObjectInputStream oos = null; try &#123; oos = new ObjectInputStream(new FileInputStream(f)); Person p = (Person) oos.readObject(); Location l = (Location) oos.readObject(); System.out.println(p); System.out.println(l); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125;&#125;class Person implements Serializable &#123; private int id; private String name; //...&#125;class Location implements Serializable &#123; private String x; private String y; //...&#125; Template Method 模板方法 父类中有一个函数是处理某一流程，这个流程在不同子类中在特殊环节上有区别，将不同的定义一个函数，让子类去重写这个函数，而不同重写整个流程的函数 Intepreter 解释器]]></content>
  </entry>
  <entry>
    <title><![CDATA[hbase 的搭建和简单操作]]></title>
    <url>%2F2019%2F07%2F11%2Fhbase%2F</url>
    <content type="text"><![CDATA[按照 HBase官网 ，搭建 HBase 的完全分布式，角色分配如下： master slave1 slave2 slave3 Master regionserver regionserver backup-master 常用指令JDBC 连接 HBase]]></content>
      <categories>
        <category>hadoop</category>
      </categories>
      <tags>
        <tag>hbase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HotSpot VM的内存模型和GC算法]]></title>
    <url>%2F2019%2F07%2F07%2Fjvm-gc%2F</url>
    <content type="text"><![CDATA[JVM GC (Garbage Collection 垃圾收集) 可以自动的回收内存，保证 JVM 中的内存空间充足，防止内存泄漏溢出。JVM 帮助程序员去管理内存有很大好处：1. 防止没有回收不用的对象的内存而产生内存泄漏；2.防止人为的回收两次回收了错误的内存。本文记录了 Oracle 的 JVM HotSpot 的内存区域划分和垃圾收集算法 Hotspot VM 内存区域的划分 程序计数器 (Program Counter Register)：记录当前线程执行字节码行号（运行到哪了），不同线程在CPU中轮流运行需要记录接下来要运行的位置 虚拟机栈 (JVM Stack)：一个线程中要调用很多方法，方法之间也存在相互调用，每调用一个方法就会向JVMS 中插入一个栈帧，一个方法的调用到结束就对应这个栈帧在 JVMS 中的入栈到出栈。栈帧中存放着函数内的局部变量，操作数栈，常量池引用。当线程请求的栈深度大于 JVM 栈的最大深度时就会触发StackOverflowError，如递归的层数过大或无法终止 本地方法栈 (Native Method Statck)：调用C语言所用到的栈 以上的是每个线程独有的内存区域，以下是线程共有的内存区 堆区 (Heap)：存放大多数 new 出来的对象 (其他情况：栈上分配和TLAB)，字符串常量池 方法区 (Method Area)：存储已被加载的类的元数据，如：属性，方法，常量池，静态变量，这部分内存不在JVM中，而是在本地内存 注： 在jdk1.7之前，方法区 Method Area 用永久代 (PermGen) 的形式实现，它是 Heap 中的一块内存区，用于存放类的元数据以及常量池 ， jdk1.8 之后用元空间 (MetaSpace) 代替了永久代的形式去实现 Method Area ，MetaSpace 在本地内存中，默认没有最大空间限制，所以几乎不会发生（大大减少了）OOM。移除永久代，一是为了和 JRockit 融合，JRockit 没有永久代的概念；二是永久代受参数大小的限制，参数在配置时也受到 JVM 设置内存大小的限制，导致在使用中可能出现内存溢出。当然，如果不设置 MetaSpace 的内存的上限则受到本地内存的限制 ​ HotSpot 在jdk1.7之后将常量池从方法区中移动到 Heap 中 JVM GC 要干啥 确定哪些内存要回收 何时执行 GC 怎样执行 GC 哪些内存需要回收 对象创建时在堆上分配一块内存，等这个对象不再使用了要将这块内存回收好分配给新创建的对象，所以GC是发生在Heap上的，那么哪些对象是不再使用的呢？现在采用下面的2方法 Reference Counting（计数引用)：即没有引用指向这个对象了，这个对象一定是不再使用了，但是可能出现循环引用的情况，如下图中三个不再使用的对象相互引用，计数引用永远发现不了他们而导致内存泄漏 Root Search (根可达)：从一些根出发，能遍历到的对象是存活的，遍历不到的是死亡的。根包括：在 JVM Stack，native method stack, run-time constant pool, static references in metaspace 中的引用 垃圾收集算法Mark-Sweep 标记清除算法 先标记出需要回收的对象，再清除被标记的对象 优缺点：实现简单，但：1. 产生碎片，装不下新对象时会触发 full GC 压缩碎片，而 full GC 很耗时；2. 对于大内存的服务器，需要遍历很大内存才能标记完所有对象 Copying 拷贝复制 将内存分成两部分 A, B；先将创建的对象放入 A 中，当 A 无法放入对象时，将 A 中存活的对象拷贝到 B 中依次排列，这样 B 区域不需要压缩即可得到连续的可用区域；再将 A 一次性的清空；由 B 向 A 重复这个过程 优点：一次 GC 后不会产生碎片，在内存中移动对象速度快，回收效率高 缺点：浪费一半的内存 Mark-Compact 标记压缩 先标记存活对象，将存活对象向一端移动，清除边界以外的内存，可以得到连续的可用区域，效率比 Copying 低 分代的收集算法 根据对象存活时间的不同，将存活时间短的放在 eden 区，将存活时间长的放在 tenured 区。eden 区中由于对象存活时间短，每次要回收的对象很多，执行 GC 频繁，采用效率最高的 Copying，tenured 区每次要回收的对像不多，执行 GC 不频繁，采用 Mark-Compact 算法，如下图： 上图中我们先假设是初始的内存为空的状态，new 出特别大的对象直接放在老年代 tenured 区，普通对象放在新生代eden区，eden 区的对象在经过一次GC后将存活的对象拷贝到 Surviror1 区，下一次 GC 时，eden区和 Survivor1 中存活的对象拷贝到 Survivor2 中，S1到S2的存活对象的年龄增大 1，依此类推，下次 GC 将 eden 和 S2 的存活对象拷贝到 S1 中。当对象的年龄达到一定数目就放到 tenured 区，在新生代中使用的收集算法是 Copying，老年代使用 Mark-Compact GC的种类与何时触发GC 在 Heap 按对象的生命周期划分成新生代和老年代的情况下 当新生代对象满时，触发的 GC 称为 Minor GC 或 Young GC 老年代空间不足：创建的大对象无法直接放入 tenured 区或新生代 GC 后晋升为老年代的对象放不下时，会触发 Full GC 也叫 Major GC，或者程序调用System.gc();时会建议执行 Full GC 无论 Minor GC 还是 Full GC 都会使程序 STW(Stop the World) 即等待 GC 完成后才继续运行，由于 Full GC 的时间比 Minor GC 慢很多，所以要减少 Full GC 发生的次数，比如减少大对象的创建，释放一些使用完的资源，不要调用System.gc(); 垃圾收集器 垃圾收集器是 JVM 对垃圾收集算法的具体实现，现有的垃圾收集器有以下几种： Serial Parallel CMS G1 ZGC 垃圾收集器我还不是很懂啊，下一篇将具体写一下 补充栈上分配 有些对象的作用域始终都在一个方法中，它们的生命周期和方法一样：从方法被调用到方法的结束，对于作用域不会逃逸出方法的对象，将对象分配到栈上，减少gc负担 栈上分配要开启逃逸分析和标量替换 TLAB(Thread Local Allocation Buffer) TLAB(Thread Local Allocation Buffer)，线程本地分配缓冲区，为了缓解多个线程同时在堆上申请空间使得分配效率降低的问题。TLAB 是eden 区的一份空间，很小，JVM 默认会为每个线程分配一块 TLAB 空间，当线程需要创建对象（非栈上分配的对象）时，会先尝分配到试该线程的 TLAB 区，如果 TLAB 区不够再分配到堆中。由于 TLAB 区很小，当剩余空间小于一个阈值 (refill_waste) 中，需要为线程重新创建空的 TLAB，原来的 TLAB 则舍弃，被舍弃的 TLAB 即使有少许的剩余空间也无法分配对象 对象内存分配的两种方法 如何将一块指定大小的内存从堆中划分出来存储一个对象呢： 碰撞指针 (Bump the Pointer) 将 heap 的内存分成规整的两部分：已使用放在一边，空闲的放在另一边，中间放一个指针作为分界点，分配内存时将指针向空闲空间移动对象需要的大小 空闲列表 (Free List) 如果堆的内存并不是规整的，已用内存和空闲内存是相互交错，就无法简单的使用碰撞指针了，需要维护一个列表，记录可用的内存块，分配时找到足够大的空间划分给对象，并更新列表中的记录]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hive 集群搭建与表的简单操作]]></title>
    <url>%2F2019%2F07%2F05%2Fhive%2F</url>
    <content type="text"><![CDATA[Hive 是基于 hadoop 的一个数据仓库，将结构化的数据文件存储在 hdfs 上，数据的结构信息存储在关系型数据库中（如mysql, oracle, derby），可以将sql语句转化为 mapreduce 任务，mapreduce 任务需要编程人员使用 java 语言写 MapTask, ReduceTask 的逻辑代码，打包成 jar 上传到 hdfs 中，而 hive 的 sql 语句进行统计分析则省去了MR的编码打包的过程，十分适合做统计分析。 Hive 构建在 Hadoop 集群之上，查询等（除 查询外）操作通过 MR 的作业执行，所以在 Hive 搭建前，集群上要*已经部署 hadoop (hdfs, yarn 环境) 在搭建好的 hadoop 集群上部署 Hive 这里我也在上一篇的四台虚拟机上搭建 Hive，Hive 的部署分单用户模式和多用户模式，单用户模式是Hive服务和客户端在一台结点上启动，多用户模式是客户端和服务端在两台结点上，下面部署 Hive 的多用户模式，角色分配如下 结点 角色 master mysql slave1 Hive Server slave2 Hive Client 安装 mysql，开启外部访问授权，重启 mysql 服务或刷新授权表 上传 Hive 的压缩文件，解压，将 hive/bin 路径添加到环境变量中 将 mysql-connector-java-*.jar 拷贝到 hive/lib 路径下 在服务端 (slave1) 和客户端 (slave2) 中，将 hive/conf 下的 hive-default.xml.template 重命名为 hive-site.xml 将服务端 hive/conf/hive-site.xml 中内的配置项改为： 12345678910111213141516171819202122&lt;!-- hdfs 路径 --&gt;&lt;property&gt; &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt; &lt;value&gt;/usr/hive/warehouse&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; &lt;value&gt;jdbc:mysql://master:3306/hive?createDatabaseIfNotExist=true&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;&lt;/property&gt;&lt;!-- mysql 登陆名密码 --&gt;&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt; &lt;value&gt;root&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt; &lt;value&gt;root&lt;/value&gt;&lt;/property&gt; 上面配置项中hive.metastore.warehouse.dir的值为 Hive 数据仓库的数据在 hdfs 中的存储路径，当创建一个表，如 school 表，会在配置的路径下创建一个名为 school 的路径，如/usr/hive/warehouse/school，向school 表中添加的数据会存放在这个路径下 将客户端 hive/conf/hive-site.xml 中内的配置项改为： 12345&lt;!-- 服务端地址 --&gt;&lt;property&gt; &lt;name&gt;hive.metastore.uris&lt;/name&gt; &lt;value&gt;thrift://slave1:9083&lt;/value&gt;&lt;/property&gt; 启动 Hive 服务端进程：hive --service metastore 启动 Hive 客户端进程：hive，即可进入 hive 数据仓库进行操作 数据类型操作指令 hive 的很多指令与关系型数据库的 sql 语句类似 创建表 Hive 的表分为内部表和外部表 内部表 直接创建表，创建后再向表中导入数据。创建语句：指定表列名，类型，列之间 (FIELDS) 的分隔符，特殊类型: array (COLLECTION ITEMS), map (MAP KEYS) 中元素之间的分隔符（不能是分号 “;”） 123456create table student(id int, name string, interests array&lt;string&gt;, score map&lt;string, float&gt;) row format delimited FIELDS TERMINATED BY ' ' COLLECTION ITEMS TERMINATED BY ',' MAP KEYS TERMINATED BY ':'; 执行完建表语句，可以看到 hdfs 文件系统中的 hive 存储路径下多了 student文件夹，里面是空的，导入的数据则存放在 student下 外部表 先有数据，根据数据的格式建立数据表，可以理解建立表与 hdfs 一个路径下数据的映射 加入external关键字和要对应的 hdfs 路径，该路径下所有文件中的数据都是表中的数据： 1234567create external table student_external(id int, name string, interests array&lt;string&gt;, score map&lt;string, float&gt;) row format delimited FIELDS TERMINATED BY ' ' COLLECTION ITEMS TERMINATED BY ',' MAP KEYS TERMINATED BY ':'location '/usr/zjm/external/' 注：示例中 location 后的路径是 hdfs 路径，会将 /usr/zjm/external下的所有文件中的数据都作为student_external表的数据，格式不一致各字段显示 null 内部表和外部表的区别 外部表是已有数据，根据数据设计表，去对应hdfs的一个路径，外部表更常用 内部表创建之初没有数据，会在hdfs中建立以表名命名的文件夹（如果没有该文件夹的话） 删除内部表时会把文件夹以及内部文件数据一同删掉，外部表只删除表的元数据，不会删除对应的路径 向表中添加数据 使用 insert into table values(v1,v2,...); 的方式会通过 MR 任务的形式很慢，要通过文件上传的形式将数据导入到表中，文件中数据格式如下： 12340 zjm0 football,basketball,music math:91.44,chinese:76.97,english:98.751 zjm1 football,tennis,music math:97.96,chinese:80.22,english:89.792 zjm2 basketball,pingpang,swim,music math:95.62,chinese:76.54,english:90.73... 导入语句：load data local inpath &#39;/usr/local/data.txt&#39; into table student;，其中 inpath后的路径是本地路径，将一个本地文件上传到 hdfs 中做为表的数据，导入后在 hdfs 中可以看到 /usr/hive/warehouse/student下多了data.txt 注：表中的数据就是对应目录下的所有文件中的数据，所以 load 就是执行 hdfs dfs -put 将文件上传到对应hdfs目录中 查询表 当查询表内容时：select * from student，先从关系型数据库中读到表结构，再从表对应的 hdfs 路径下读到所有文件中的数据低按照表结构封装，如果不符合表结构则显示一条记录的各个字段都显示 null 分区表 对一个表的内容按某个字段分成不同区域，方便查询 1234567create table student_p(id int, name string, interests array&lt;string&gt;, score map&lt;string, float&gt;) partitioned by (grade int)row format delimited FIELDS TERMINATED BY ' ' COLLECTION ITEMS TERMINATED BY ',' MAP KEYS TERMINATED BY ':'; 上面建立了按照年级的学生分区表，当插入数据时可以将不同年级的学生的数据分别放入不同的分区中，在hdfs中一个分区是表文件夹下的一个文件夹 导入数据：load data local inpath &#39;/.../data.txt&#39; into table student_p partition (grade=3)，这里的data.txt中不能含有 grade 字段，且里面的数据都应该属于相同 grade 的 student 信息，查询的时候是根据 hdfs 的文件夹名grade=3添加字段 多分区：指定多个分区，出现多级目录 partitioned by (grade int, tall int, sex string) load data local inpath &#39;/.../data.txt&#39; into table student_p partition (grade=3, tall=170, sex=&#39;girl&#39;) 也可以先在 hdfs 上建立好分区目录，用msck repair table ...同步分区信息 导入其他表的数据12345from s1insert overwrite table s2select id,name,sex;insert into table s3;select id,tall,weight;]]></content>
      <categories>
        <category>hadoop</category>
      </categories>
      <tags>
        <tag>hive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hdfs HA using QJM]]></title>
    <url>%2F2019%2F06%2F29%2Fhdfs-ha-qjm%2F</url>
    <content type="text"><![CDATA[搭建分布式的 hdfs 集群，一台服务器部署 namenode，另一台部署 secondaryname 的方式，存在单点故障的问题，为了解决这个问题，加入备用主节点 Standby namenode ，当 Active namenode 宕机后提升为Active namenode，使集群更高可用。本文介绍如何配置和部署hdfs的高可用集群： HDFS High Availability Using the Quorum Journal Manager 使用 Virtual Box 建立虚拟机后各角色的分配如下： hdfs journalnode zookeeper master nn jn slave1 nn/dn jn zk slave2 dn jn zk slave3 dn zk 结点之间免密 通过主节点自动化的启动集群，需要主节点可以发送指令到从节点，而无需输入从节点密码，要在主节点的root/.ssh 目录下生成公钥私钥，将公钥文件分发到其他结点中，并将公钥内容添加到 authorized_keys 中 另一种免密情况是 主namenode 和 备namenode 结点的 jzfc 进程之间通信切换状态时，slave1 向 master 免密 总的说来：即 master 向 master, slave1, slave2, slave3 免密，slave1 向 master, slave1 免密，免密操作如下 1234ssh-keygen -t dsa -P 'password' -f ./id_dsa # 生成公钥私钥（master中）cat ./id_dsa.pub &gt;&gt; authorized_keys # 将公钥添加到本机的 authorized_keys 中（master中）scp ./id_dsa root@slave1:`pwd`/slave1.pub # 将公钥发送到要对免密的结点中（master中）cat ./slave1.pub &gt;&gt; authorized_keys # 在要对免密的结点中添加公钥到 authorized_keys 中（slave1中） zookeeper和 hadoop都是运行在JVM上，需要安装jdk并配置环境变量，下面的zookeeper，hadoop命令为了在任意路径下使用，都需要在/etc/profile文件中添加对应的路径 部署Zookeeper集群 解压 zk 安装包 进入安装路径下: /conf，将zoo_sample.cfg改名为zoo.cfg，编辑zoo.cfg,修改持久化文件路径：dataDir 为非 tmp 下的路径，如dataDir=/usr/zjm/zookeeper，添加结点信息： 123server.1=slave1:2888:3888server.2=slave2:2888:3888server.3=slave3:2888:3888 创建dataDir，并在其中建立文件 myid，将server后对应的数字写入 myid 中 123# 在 slave1 中mkdir -p /usr/zjm/zookeeperecho 1 &gt; /usr/zjm/zookeeper/myid 在其他结点中重复上述操作，或者将一台结点中已经解压配置好的文件分发到其他结点中：scp -r xxx root@slave2:`pwd` 在各个结点中启动 zk 服务：zkServer.sh start 查看 zk 服务状态：zkServer.sh status 编辑hadoop配置文件 在所有结点中都要编辑以下配置文件，可以配置一份然后分发给其他结点 hadoop-env.sh /hadoop-…/etc/hadoop下的 hadoop-env.sh 中加入export JAVA_HOME=/usr/java/default core-site.xml123456789101112&lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://mycluster&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/usr/hadoop-2.7.3/ha&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;slave1:2181,slave2:2181,slave3:2181&lt;/value&gt;&lt;/property&gt; hdfs-site.xml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;mycluster&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.ha.namenodes.mycluster&lt;/name&gt; &lt;value&gt;nn1,nn2&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.mycluster.nn1&lt;/name&gt; &lt;value&gt;master:8020&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.mycluster.nn2&lt;/name&gt; &lt;value&gt;slave1:8020&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.http-address.mycluster.nn1&lt;/name&gt; &lt;value&gt;master:50070&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.http-address.mycluster.nn2&lt;/name&gt; &lt;value&gt;slave1:50070&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://192.168.56.100:8485;192.168.56.101:8485;192.168.56.102:8485/mycluster&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;/usr/hadoop-2.7.3/ha/journal&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.mycluster&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt;sshfence shell(/bin/true) &lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt; &lt;value&gt;/root/.ssh/id_dsa&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt; 格式化 Namenode 格式化 namenode 是删除旧的 namenode 的镜像文件（fsimage）日志文件（edits），并新建空白的fsimage和edits，在HA QJM集群中，edits 文件存放在 Journalnode 中，所以在格式化namenode之前要先启动 journalnode进程：在 master,slave1, slave2 中执行 hadoop-daemon.sh start journalnode 在 master 中格式化 hdfs：hdfs namenode -format，启动namenode: hadoop-daemon.sh start namenode，在备主结点同步元数据：hdfs namenode -bootstrapStandby. 格式化 Zookeeper 为了让 zookeeper 选举 active namenode，要让 JKFC 进程对 zookeeper 格式化，即在 zk 的目录结构中建立路径：/hadoop-ha/mycluster，当master 与 slave1 中的 ZKFC 进程启动后去争抢 /hadoop-ha/mycluster 的使用权（锁），谁先抢到对应的 namenode 就是 active，其余的 namenode 是 standby 状态。 操作：在 master 或 slave1 中执行hdfs zkfc -formatZK 启动集群 在 master 中执行 start-dfs.sh 验证HA 浏览器访问 master:50070 和 slave1:50070，可以看到集群中 namenode 和 dataname 状态，一个namenode 为 active，另一个为 standby。将 active 的 namenode 通过 kill -9 进程号 终止进程，通过web 页面可以看到原 active 的结点已经无法访问，standby 的结点状态变为 active 遇到的问题 第一次配置时，journalnode 是在 namenode 启动之前开启的，当在 master 中 stop-dfs.sh 停止集群后，再次开启start-dfs.sh 时，启动的顺序是 namenode, datanode, journalnode, zkfc，这时，由于 namenode 先于 journalnode 启动，不断尝试与 journalnode 建立连接可能由于 journal 进程还没启动，namenode 的retry 超过最大次数限制，导致 namenode 启动失败，active namenode 结点的 namenode 进程在刚启动时是可以看到的，一会就不见了，但是 standby namenode 启动成功了 这个问题的解决方法是在start-dfs.sh 之前手动的启动 journalnode 进程，或者在配置文件中增大namenode等待journalnode 的时间，感觉是我的电脑开启四个虚拟机运行速度太慢导致的。 journalnode 是同步 active nn 与 standby nn 元数据的，但是在active nn 等待超时的情况下，standby nn 为什么能启动呢？ 以上存在个人理解，很多说法不严格，欢迎大家在评论区留言 参考文献]]></content>
      <categories>
        <category>hadoop</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>hdfs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为 github pages + hexo 博客添加 gitment 评论功能]]></title>
    <url>%2F2019%2F06%2F04%2Fgitment%2F</url>
    <content type="text"><![CDATA[如果你的博客使用 github pages 提供的服务，just like me，想添加评论功能，使用 gitment 是最佳的选择，通过 gitment 发表评论就是在 github 仓库创建 Issues， 配置过程十分简单 注册 github Oauth 应用程序 首先，注册OAuth Application（请点击） Homepage URL 和 Authorization callback URL 为你的博客地址：如 https://shaun2016.github.io/ 注册完成后可以得到 Client ID 和 Clint Secret 配置 在 主题 的配置文件 _config.yml 中，添加： 12345678910gitment: enable: true mint: true count: true lazy: false cleanly: false github_user: 'detectiveHLH' github_repo: 'detectiveHLH.github.io' client_id: 'xxx' client_secret: 'xxx' 其中后四项改为自己的 添加布局和样式 在主题目录下编辑：themes\next\layout\_partials\comments.swig（这个文件可能后缀名不同）修改如下：这里只显示一部分 12345678910111213141516171819202122232425262728293031323334353637383940414243&#123;% if page.comments %&#125; &lt;div class="comments" id="comments"&gt; &#123;% if theme.gitment.enable %&#125; &lt;div id="gitment_title" class="gitment_title"&gt;&lt;/div&gt; &lt;div id="container" style="display:none"&gt;&lt;/div&gt; &lt;link rel="stylesheet" href="https://jjeejj.github.io/css/gitment.css"&gt; &lt;script src="https://jjeejj.github.io/js/gitment.js"&gt;&lt;/script&gt; &lt;script src="https://code.jquery.com/jquery-3.3.1.min.js"&gt;&lt;/script&gt; &lt;script&gt; const myTheme = &#123; render(state, instance) &#123; const container = document.createElement('div'); container.lang = "en-US"; container.className = 'gitment-container gitment-root-container'; container.appendChild(instance.renderHeader(state, instance)); container.appendChild(instance.renderEditor(state, instance)); container.appendChild(instance.renderComments(state, instance)); container.appendChild(instance.renderFooter(state, instance)); return container; &#125; &#125; function showGitment() &#123; $("#gitment_title").attr("style", "display:none"); $("#container").attr("style", "").addClass("gitment_container"); var gitment = new Gitment(&#123; id: decodeURI(window.location.pathname), theme: myTheme, owner: '&#123;&#123; theme.gitment.gitment_user &#125;&#125;', repo: '&#123;&#123; theme.gitment.gitment_repo&#125;&#125;', oauth: &#123; client_id: '&#123;&#123; theme.gitment.client_id&#125;&#125;', client_secret: '&#123;&#123; theme.gitment.client_secret &#125;&#125;' &#125; &#125;); gitment.render('container'); &#125; showGitment(); &lt;/script&gt; &#123;% elseif (theme.duoshuo and theme.duoshuo.shortname) or theme.duoshuo_shortname %&#125; &lt;div class="ds-thread" data-thread-key="&#123;&#123; page.path &#125;&#125;" data-title="&#123;&#123; page.title &#125;&#125;" data-url="&#123;&#123; page.permalink &#125;&#125;"&gt; &lt;/div&gt; ... 我将 gitment 放在 if 条件的首位置，owner，repo，client_id，client_secret 四部分从配置文件读取，至此配置完毕 在开始时也查阅如何实现博客的评论系统时，总结了一下几个主流的第三方服务分享给大家： Valine: 国内的服务，基于Leancloud，在我绑定域名的时候发现无法绑定 *.github.io，对于自己购买备案的域名很适合 Hypercomments: 国外的，需要登录google账户，风格简约 来必力: 韩国的服务，支持很多第三方登录 多说，友言的服务都关闭了，很可惜啊，对于如何通过 github pages 搭建个人博客感兴趣的可以去找找，主要思路是通过一个博客框架，如 hexo 生成本地博客静态资源文件，网页上的内容和链接都是静态的，不涉及后台，将这些文件 push 到 github pages 的仓库中，访问***.github.io就可以显示博客内容了。修改配置文件，配置主题，加各种小功能的过程还是非常的有趣的，而且不难，查文档就好了，欢迎大家评论啊。 主要参考文章：https://www.jianshu.com/p/b8255a630d46]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo gitment</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 的 list 在循环中删除元素]]></title>
    <url>%2F2019%2F05%2F05%2Fpython-list-removeItem-in-loop%2F</url>
    <content type="text"><![CDATA[今天写一个循环中按条件删除 list 中的元素，我还是知道直接删除会导致数组越界或者漏过某个元素，我的想法是控制下标，但是用 for循环怎么也写不出来，因为python的for _ in range(len(list))的结束条件不会变啊，用while可以控制下标，看了别人的博客，找到了一个巧妙的写法，哇，惊了，长见识了 写法一：遍历深拷贝操作原始的1234l = [1, 2, 3, 4, 5]for i in l[:]: if i % 2 == 0: l.remove(i) 写法二：控制下标1234567l = [1, 2, 3, 4, 5]i = 0while i &lt; len(l): if l[i] % 2 == 0: l.pop(i) else: i += 1 写法三: 倒序遍历1234l = [1, 2, 3, 4, 5]for i in range(len(l)-1, -1, -1): if l[i] % 2 == 0: l.pop(i) 第一个会多占用一份list的内存，第三个最好了，长得好看，主要是好记呀，加三个-1 just remember it ~ dict在遍历中删除 k-v1234l = [1, 2, 3, 4, 5]for k in list(l.keys()): if k % 2 == 0: del(a[k])]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TopK问题的几种方法实现]]></title>
    <url>%2F2019%2F04%2F14%2Ftopk%2F</url>
    <content type="text"><![CDATA[求一些数中的最大的K个数可以用大顶堆，改进的快排，下面是思路和实现]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[networkx里pageRank的使用]]></title>
    <url>%2F2019%2F04%2F01%2FpageRank%2F</url>
    <content type="text"><![CDATA[使用 networkx 的 pageRank 方法对图中结点计算等级，用 draw 方法对图做可视化，使用起来超简单，超开心 1234567891011121314151617181920212223import matplotlib.pyplot as pltimport networkx as nxG = nx.DiGraph()with open('../GraphData/karate.txt', 'r') as f: for line in f.readlines(): head, tail = [int(_) for _ in line.split()] G.add_edge(head, tail) G = G.to_undirected()pr = nx.pagerank(G, alpha=0.85)x = 0for node, value in pr.items(): print('%d,%.4f' % (node, value)) x += valueprint(x)layout = nx.spring_layout(G)plt.figure(1)nx.draw(G, pos=layout, node_color='y', with_labels=True)plt.figure(2)nx.draw(G, pos=layout, node_size=[x * 6000 for x in pr.values()], node_color='m', with_labels=True)plt.show() 上面从文件中读取图结构信息，文件中每行两个数字，表示是一条边。networks里提供一些数据集可以直接载入，如：G = nx.karate_club_graph()]]></content>
      <categories>
        <category>mechine learning</category>
      </categories>
      <tags>
        <tag>图算法</tag>
        <tag>networkx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用sklearn的kmeans方法进行聚类]]></title>
    <url>%2F2019%2F04%2F01%2Fsklearn-kmeans%2F</url>
    <content type="text"><![CDATA[就是代码，也比一点不会强… 1234567891011121314import numpy as npimport matplotlib.pyplot as pltfrom sklearn.cluster import KMeansfrom sklearn.datasets.samples_generator import make_blobsX = [] # 二维数组with open('./GraphData/small_sample.txt', 'r') as f: for i in f.readlines(): X.append([int(x) for x in i.split()])X = np.asarray(X)# n_clusters 为聚类个数，y_pred 为聚类结果y_pred = KMeans(n_clusters=2, random_state=9).fit_predict(X)print(y_pred) #输出： [1 1 1 1 1 1 1 1 0 0 0 0 0]plt.scatter(X[:, 0], X[:, 1], c=y_pred)plt.show() txt 里的内容类似如下 12340 40 61 2....]]></content>
      <categories>
        <category>mechine learning</category>
      </categories>
      <tags>
        <tag>图算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[word2vec的简单理解]]></title>
    <url>%2F2019%2F03%2F19%2Fword2vec_CBOW%2F</url>
    <content type="text"><![CDATA[word2vec研究如何将词用向量表示，使用的两个重要模型——CBOW模型(Continuous Bag-of-Words Model)和Skip-gram模型(Continuous Skip-gram Model)，CBOW通过上下文预测中间词，Skip-gram对中间词预测它的上下文，本文只对CBOW进行介绍 词的向量表示 one-hot：语料库的词项个数为m，则one-hot表示的长度为m，只有一个位置是1，其余都是0 distributed representation：假设每个词项有d个特征，d远小于m，用d维向量表示每个词项 CBOW CBOW 是 word2vec 中使用的浅层神经网络模型，语料库中词项和词项的上下文做为样本，Sample(Context(x), x)，对模型的参数进行训练，得到每个词项的向量表示 词的上下文 Context(x) 一个词出现的概率只与它前后固定数目(n)的词相关，n的取值与模型参数有关，可以参考： n 模型参数数量 1 2*10^5 2 4*10^{10} 3 8*10^{15} 4 16*10^{20} 例子：我很爱学信息检索 如果n=2，则学的上下文Context(学)={ 很，爱，信息，检索 } 4 个词组成 模型结构 输入层 上下文词项的one-hot 隐藏层 对于一个样本Sample(Context(x), x)，将u_i的one-hot向量与表示矩阵W_{m*d}相乘，得到u_i的当前表示向量\hat{u_i}，u_i\in Context(x)，将\sum_{i=1}^{2n}{\hat{u_i}}/2n做为隐藏层的输出，是一个1*d的向量。 输出层 隐藏层得到的1*d向量与权重矩阵W'相乘，得到1*m的向量，通过softmax处理后得到一个1*m的向量\hat{y}，为中间词出现的概率，概率最大的index指向的词项即为预测出的中间词，与真实值的one-hot向量 y 做比较，根据误差更新权重矩阵W与W'。 softmax( \begin{bmatrix} 4.01 & 2.01 & 5& 3.34& 1.2 \end{bmatrix} )= \begin{bmatrix} 0.23&0.03&0.61&0.12&0.01 \end{bmatrix}损失函数 L=H(\hat y,y)=-\sum_i^m{\hat y_i log\ y_i} 梯度下降更新W和W'，训练完毕后，W矩阵即为词向量矩阵，用一个词项的one-hot去乘W矩阵即得到这个词项的词向量 结构分析 参数数量：2*d*m个，d为词向量长度，m为词项个数，在语料库中m的值是很大的，对于一个样本(Context(x), x)，只有一个是正确的结果，其余的m-1个全是错误的结果，每次都对大量的错误结果进行权重更新是很耗时的 改进思路：减少网络的参数个数和每次要更新的参数个数 负采样策略 对于词 w 的上下文Context(w)来预测w，Context(x)与x构成了一个正样本，Context(x)与别的词项就构成负样本，每次训练仅选择一小部分的负样本，对他们连接的权重进行更新，减少了每次训练需要更新的权重数量，应该选择多少，如何进行选择呢？大体思路是让出现频率高的词项更大概率被选做负样本。 采样率公式： len(w)=\frac{[counter(w)]^{3/4}}{\sum_{u\in D}[counter(u)]^{3/4}}len(w)表示w应该被保留作为负样本的概率，counter(w)代表w在语料库中出现的次数，指数3/4是经验值 Hierarchical softmax的CBOW 分层softmax的CBOW将输出层改为树形结构 建立哈夫曼树，使高频词项更靠近根节点，规定左孩子为负类，右孩子为正类，经过一个非叶子结点做了一次二分类，设隐藏层的输出为x，经过每个非叶子结点被分到正类的概率为： \sigma(x^T\theta)=\frac{1}{1+e^{-x^T\theta}}分到负类概率为：1-\sigma(x^T\theta)，每个非叶子结点上都有一个待定参数向量：\theta，可以计算出到达值为1的结点x的概率： 第1次：p(0|x,\theta_1)=1-\sigma(x^T\theta_1)\\ 第2次：p(1|x,\theta_2)=\sigma(x^T\theta_2)\\ 第3次：p(1|x,\theta_3)=\sigma(x^T\theta_3)\\ 第4次：p(1|x,\theta_4)=\sigma(x^T\theta_4)\\ 即：p(x|Context(x))=\prod_{i=1}^4{p(d_i|x,\theta_i)},\ d_i\in\{0,1\}目标函数：L=\sum_{x\in C}{log\ p(x|Context(x))} 最大化，通过梯度上升（或者求 1-L 的最小值，用梯度下降）更新 x 和 \theta 的值，表示矩阵是最终得到的词向量矩阵。 参考文献Efficient Estimation of Word Representations in Vector Space word2vec的数学原理 word2vec的负采样]]></content>
      <categories>
        <category>mechine learning</category>
      </categories>
      <tags>
        <tag>word2vec</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 主从服务器搭建与哨兵机制]]></title>
    <url>%2F2019%2F03%2F12%2Fredis-master-slave-sentinel%2F</url>
    <content type="text"><![CDATA[实验内容：用三台服务器运行 redis，设置主从关系进行数据存储，建立哨兵监督主节点，模拟主节点宕机后的哨兵选举新主 Redis 单节点安装 将 Redis 5.0.3压缩包解压，进入解压后的文件夹，可以看到Makefile文件，在这个路径下执行make&amp;&amp;make PREFIX=~/redis install进行编译和安装，在~/redis下可以看到bin文件夹，里面有一些脚本文件：redis-server，redis-cli，redis-sentinel等。配置环境变量使得执行脚本命令更加方便：vi /etc/profile在最后加上如下内容：(shift + g跳到最后一行，shift + $跳到一行的最后) 12export REDIS_HOME=/root/redisPATH=$PATH:$REDIS_HOME/bin 在单节点上的某个路径上运行redis-server即可按默认参数（端口6379）启动服务，redis-cli作为客户端访问服务，可以用形如：redis-server --port 6380，redis-cli -h ip -p port的方式指定参数，具体命令访问redis官网 Redis 集群搭建 创建三个服务器： 192.168.56.100 master 192.168.56.101 slave1 192.168.56.102 slave2 vim /etc/hosts设置ip对应的域名减少敲ip的麻烦 为了方便，以下都在各个服务器的~/redis/6380文件夹下操作 主结点 master为主节点，服务配置文件vi redis.conf： 12port 6380protected-mode no 哨兵配置文件vi sent.conf： 12port 26379sentinel monitor c1 master 6380 2 启动服务：redis-server redis.conf 启动哨兵：redis-sentinel sent.conf 从结点 slave1 和 slave2 作为从节点，在服务配置上加上附属主节点，在哨兵上没有不同 123port 6380protected-mode noslaveof master 6380 写好配置文件后启动服务和哨兵 实验内容 通过客户端访问不同结点：redis-cli -h master -p 6380可以执行set/get操作，访问slave结点只能执行get操作 模拟主节点宕机：使用Ctrl C命令关闭主节点redis服务进程，查看slave1和slave2 的状态，可以发现经过大约10s后哨兵重新选举slave1或者slave2作为新的主，同时将master降级为slave，再启动master的redis服务时，它以从节点的身份加入集群。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>NoSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[枫叶城]]></title>
    <url>%2F2019%2F02%2F13%2Ffyl%2F</url>
    <content type="text"><![CDATA[最近，开始练习杨昊昆的枫叶城，这首用到打板和拍弦的技巧十足需要练习一阵子。深秋的城中，枫叶在枝头，在风中，在地面，映红了这座城，在城楼高处，吉他的旋律，伴着起舞的枫叶，在簌簌的风中回荡，在寂静的空巷中飘扬。这，显然是一个人的城。这首曲子真的好听，弹琴的时候，才是我全身心投入的时候，只想沉浸在音乐中，全部的烦恼也都无暇顾及。做别的事呢，则经常是插着耳机，朋友笑着说，你真的很喜欢音乐啊。是啊，但是，不听歌做什么呢？在校园里用眼睛和腿就可以过马路，食堂吃饭只需要嘴巴，在电脑前工作音乐能让枯燥的时间过的快些。当旋律响起，枫叶出现在空中，走在古城中，青石板铺成的宽阔街道上，两侧空无一人的店铺，静止的门窗，时隐时现的风铃，也不觉得奇怪。朋友冲我笑了笑：来啦，我也向他问好，走到座位上，把耳机从手机上拔下，插在了电脑上。不知从什么时候开始，就喜欢把情绪埋在心底，脸上的表情也越来越少，即使在家里，和一年见几次面的父母，也不想让他们看出自己的喜怒哀乐。…喧嚣和嘈杂中，有能属于自己的安静，是多么珍贵。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tensorflow method]]></title>
    <url>%2F2019%2F01%2F28%2Ftensorflow-method%2F</url>
    <content type="text"><![CDATA[tf.random_uniform tf.random_uniform(shape, minval, maxval, dtype, seed, name) 产生3行4列的随机数，范围在(-1, 1)，类型是float32，可用于权重参数的初始化 1tf.random_uniform((3, 4), -1, 1, dtype=tf.float32) tf.Variable tf.Variable.init(initial_value, trainable=True, collections=None, validate_shape=True, name=None) 创建图变量，初始值为 initial_value tf.SparseTensor tf.SparseTensor(indices, values, dense_shape) indices：2维int64张量，指定稀疏张量中非零值的位置 values：1维张量，提供indices中每个位置对应的值 dense_shape：稀疏张量的形状 1234SparseTensor(indices=[[0, 0], [1, 2]], values=[1, 2], dense_shape=[3, 4])[[1, 0, 0, 0] [0, 0, 2, 0] [0, 0, 0, 0]] tf.argmax tf.arg_max(input, dimension, output_type=tf.int64, name=None) 给出某个tensor对象在某一维上的其数据最大值的索引值 12345678arr = np.array([ [1, 2, 3], [2, 3, 4], [5, 4, 3], [8, 7, 2]])tf.argmax(test, 0) # array([3, 3, 1])tf.argmax(test, 1) # array([2, 2, 0, 0]) tf.reduce_mean1234x = tf.constant([[1., 1.], [2., 2.]])tf.reduce_mean(x) # 1.5, axis=None，对所有数字tf.reduce_mean(x, 0) # [1.5, 1.5],axis=0tf.reduce_mean(x, 1) # [1., 2.],axis=1 tf.reduce_sum1234x = tf.constant([[1., 1.], [2., 2.]])tf.reduce_sum(x) # 6.0, axis=None，对所有数字tf.reduce_sum(x, 0) # [3., 3.], axis=0tf.reduce_sum(x, 1) # [2., 4.], axis=1 tf.truncated_normal tf.truncated_normal(shape,mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None) 从截断的正态分布中输出形如 shape 的随机值：生成 (μ-2σ，μ+2σ) 之间的随机数 tf.random_normal tf.random_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None) 按正太分布(μ,σ)生成形如 shape 的随机数 tf.constant tf.constant(value, dtype=None, shape=None, name=&#39;Const&#39;, verify_shape=False) 产生形如 shape 的常量 Tensor，可用于多偏执量初始化 tf.cast tf.cast(x, dtype, name=None) 将 x 的数据类型转成 dtype 123456a = tf.Variable([1, 0, 0, 1])b = tf.cast(a, dtype=tf.bool)with tf.Session() as sess: sess.run(tf.initialize_all_variables()) print(sess.run(b))# [True False False True] tf.nn.conv2d 卷积函数 tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, name=None) input: 要做卷积的输入图像，类型：Tensor [batch, in_height, in_width, in_channels]，含义：[训练一批 batch 个的图片，图片高度，宽度，颜色通道数]； filter: 卷积核，类型：Tensor [filter_height, filter_width, in_channels, out_channels]，含义：[卷积核高度，宽度，颜色通道数，卷积核个数] strides: 步长，一维Tensor，长度4，二维图片是[1, stride, stride, 1] padding: 类型: String，’SAME’ 或 ‘VALID’ 其中之一，’SAME’检测图像边缘，’VALID’不检测图像边缘 use_cudnn_on_gpu: 类型：bool，是否用 cudnn 加速，默认是 true Return: 返回值类型：feature map: Tensor [batch, height, width, channels] 123456789101112131415i = tf.Variable([[ [[1.], [2.], [3.]], [[2.], [1.], [0.]], [[0.], [3.], [0.]]]])j = tf.Variable([[ [[1.]], [[2.]]], [[[3.]], [[2.]]]])sess = tf.InteractiveSession()sess.run(tf.global_variables_initializer())op = tf.nn.conv2d(i, j, strides=[1, 1, 1, 1], padding='VALID')print(sess.run(op))# [[ [[13.] [11.]] # [[10.] [10.]] ]] tf.nn.max_pool 最大池化层 tf.nn.max_pool(value, ksize, strides, padding, name=None)，用于对卷积层输出的 featrue map 提取局部最大值 value: 池化层的输入；类型：feature map: Tensor [batch, height, width, channels]是卷积层的输出 ksize: 池化窗口的大小，四维向量，一般是 [1, height, width, 1] strides: 步长，[1, stride, stride, 1] padding: ‘VALID’ or ‘SAME’ return: Tensor，[batch, height, width, channels] 1234567891011i = tf.Variable([[ [[1.], [2.], [3.]], [[2.], [1.], [0.]], [[0.], [3.], [0.]]]])sess = tf.InteractiveSession()sess.run(tf.global_variables_initializer())op = tf.nn.max_pool(i, [1, 2, 2, 1], [1, 1, 1, 1], padding='VALID')print(sess.run(op))# [[ [[2.] [3.]]# [[3.] [3.]] ]] tf.nn.avg_pool 对 feature_map 提取局部均值 tf.nn.softmax tf.nn.softmax(logits, axis=None, name=None) 激活函数，将N*1的向量归一化为 (0, 1) 之间的值，将较大的量特征更加明显 logits: 非空 Tensor axis: 执行 softmax 的维度，默认是 -1，即最后一个维度 123456i = tf.Variable([1., 2., 3., 4.])with tf.Session() as sess: sess.run(tf.global_variables_initializer()) op = tf.nn.softmax(i) print(sess.run(op))# [0.0320586 0.08714432 0.23688284 0.6439143 ] tf.add_n tf.add_n(inputs,name=None)将列表里的元素相加，用于inputs是由for产生的情况下不方便直接相加 1tf.add_n([tf.nn.l2_loss(w) for w in X]) tf.matmul tf.matmul(a, b, transpose_a=False, transpose_b=False, adjoint_a=False, adjoint_b=False, a_is_sparse=False, b_is_sparse=False, name=None) 矩阵乘法：a, b 必须是矩阵(维度大于2)，都可以通过相应参数进行转置或共轭，可以使用稀疏矩阵乘法提高效率 1234567891011121314i = tf.Variable([ [1, 2], [2, 3]])j = tf.Variable([ [2, 3], [1, 2]])with tf.Session() as sess: sess.run(tf.global_variables_initializer()) op = tf.matmul(i, j) print(sess.run(op))#[ [4 7]# [7 12] ] tf.multiply tf.math.multiply(x, y, name=None) x, y 对应位置值相乘 12345678910i = tf.Variable([1, 2])j = tf.Variable([ [2, 1], [1, 3]])with tf.Session() as sess: sess.run(tf.global_variables_initializer()) print(sess.run(tf.multiply(i, j)))# [[2 2]# [1 6]] tf.reshape tf.reshape(tensor, shape, name=None) 变形，-1 可以用来推测形状：[-1] 可以用来展开，[-1, 3]：分成 x 组，每组 3 个，[2, -1]：分成 2 组，每组 x 个 tf.nn.relu tf.nn.relu(features, name=None)激活函数，即 max(features, 0)，将矩阵中每行的负数置 0 12345i = tf.Variable([-1, 1, 2, -2])with tf.Session() as sess: sess.run(tf.global_variables_initializer()) print(sess.run(tf.nn.relu(i)))# [0 1 2 0] tf.nn.dropout tf.nn.dropout(x, keep_prob, noise_shape=None, seed=None, name=None) 防止过拟合，一般用在全连接层，随机扔掉一部分神经元。让神经元按激活值 keep_prob 活跃还是睡眠。 x：输入 keep_prob：神经元被选中的概率，初始化 keep_prob 是一个占位符，keep_prob=tf.placeholder(tf.float32) train 的时候使用 dropout cross_entropy 交叉熵： H(p,q)=-\sum_xp(x)logq(x)p(x)是样本的标签，q(x)是模型的预估结果 由来：交叉熵 - 样本熵(常数) = 相对熵 或 KL散度 H(p,q)-H(p)=-\sum_x p(x)logq(x)+\sum_x p(x)logp(x)=\\-\sum_x p(x)(logq(x)-p(x))=-\sum_x p(x)log \frac{q(x)}{p(x)}cross_entropy = -tf.reduce_sum(y_ * tf.log(y_conv)) 其中，y_是样本 label，y_conv 是模型的输出 feed_dict 替换图中的某个 tensor 的值，可以用来设计图的输入 (替换开始声明的占位符) 123op = tf.multiply(a, 3)with tf.Session() as sess: sess.run(op, feed_dict=&#123;a: 5&#125;) # 将 a=5传给操作op tf.SparseTensor 稀疏张量：SparseTensor(indices, values, dense_shape)，即坐标，值，规模 1234SparseTensor(indices=[[0, 0], [1, 2]], values=[1, 2], dense_shape=[3, 4])[[1, 0, 0, 0] [0, 0, 2, 0] [0, 0, 0, 0]] tf.trace 计算矩阵的迹：主对角线的总和 12x = tf.constant([[1,2,3],[4,5,6],[7,8,9]])tf.trace(x) # 15 tf.nn.l2_loss L2范数计算张量的误差值，对张量中每个元素平方求和，最后乘1/2 tf.nn.l2_loss([1.0, 2.0, 3.0])=7.0 tf.train.Saver saver=tf.train.Saver(max_to_keep=5)，创建Saver对象，用于保存训练好的模型，保存最后max_to_keep次的模型参数，用Saver对象保存模型：saver.save(sess, pathd=&#39;&#39;, global_step=step) 保存的文件有四个：checkpoint，*.data，*.index，*.meta 权重参数在 .data文件中 tf.floor tf.floor(x, name=None)向下取整，x为张量 tf.assign_add tf.assign_add(ref, value)，其中ref是可变的张量， tf.Session.run tf.Session.run(fetches, feed_dict=None, options=None, run_metadata=None) 计算fetches中的所有张量，返回值是张量的个数，其中fetches可以是一个张量，列表，元组]]></content>
      <categories>
        <category>tensorflow</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简单好用的lambda与Stream]]></title>
    <url>%2F2018%2F09%2F18%2Flambda-introduce%2F</url>
    <content type="text"><![CDATA[lambda表达式是java8的新特性，使java在编程中更简单，代码更简洁可读，避免了冗长的内部类、匿名类，下面通过栗子看看lambda有哪些应用吧*^-^* ForEach 与 lambda12345678910111213Map&lt;String, Integer&gt; items = new HashMap&lt;&gt;();items.put("A", 10);items.put("B", 20);items.put("C", 30);items.put("D", 40);// 原来的写法for (Map.Entry&lt;String, Integer&gt; entry : items.entrySet()) &#123; System.out.println("item : " + entry.getKey() + "count : " + entry.getValue());&#125;// lambdaitems.forEach((k, v)-&gt;&#123; System.out.println("item : " + k + "count : " + v);&#125;); 12345678910111213List&lt;String&gt; list = new ArrayList&lt;&gt;();list.add("A");list.add("B");list.add("C");list.add("D");list.add("E");for(String item : list)&#123; System.out.println(item);&#125;// lambda 参数只有一个可以省略小括号，后面的表达式只有一句可以省略&#123;&#125;,return和分号list.forEach(x-&gt;System.out.println(x));// 上一句的简写list.forEach(System.out::println); 匿名内部类 与 lambda123456789Thread t = new Thread(new Runnable() &#123; public void run() &#123; System.out.println("How a u..."); &#125;&#125;);t.start();// lamdaThread t1 = new Thread(()-&gt;System.out.println("I'm fine...thx"));t1.start(); 12345678910111213141516String[] arr = &#123;"a", "b", "c"&#125;;List&lt;String&gt; list = Arrays.asList(arr);// 匿名内部类Collections.sort(list, new Comparator&lt;String&gt;() &#123; @Override public int compare(String o1, String o2) &#123; return o1.compareTo(o2); &#125; &#125;);// lambdaCollections.sort(list, (s1, s2)-&gt;&#123; return s1.compareTo(s2);&#125;);// 当表达式只有一句时 return 可以省略Collections.sort(list, (s1, s2)-&gt;s1.compareTo(s2)); lambda语法一般语法 ( 参数列表 )-&gt;{ 表达式语句 } (Type parameter, Type parameter,...) -&gt; {statements...} 单参数 parameter-&gt;{statements} 当 lambda 表达式的参数个数只有一个，可以省略小括号 单语句 parameter-&gt;statement 当 lambda 表达式只有一条语句时，可以省略大括号，return 和结尾的分号 方法引用 objectName::instanceMethod 或ClassName::staticMethod 把 lambda 表达式的参数直接当成 instanceMethod 或 staticMethod 的参数，比如System.out::println等同于x-&gt;System.out.println(x)，Math::max等同于(x,y)-&gt;Math::max(x,y) ClassName::instanceMethod是x-&gt;x.instanceMethod()的简化，eg: Student::getName等同于x-&gt;x.getName()，instanceMethod是一个无参的函数 访问外部变量 只能访问外部变量，不能在 lambda 内部修改，编译器将隐式将外部变量当成 final 处理，匿名函数和 lambda 函数内对外部变量的访问是一样的，都是只能访问 final 修饰的，没有 final 修饰视为 final 修饰，不可改变值。 Stream 与 lambda 流式处理Stream 是java8的新特性，大大简化了对集合的操作，本节只看顺序流式处理，请先看看下面的栗子*^-^* 找出集合中的偶数 12345678910List&lt;Integer&gt; nums = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9, 10);List&lt;Integer&gt; evens = new ArrayList&lt;&gt;();for (final int n : nums) &#123; if (n % 2 == 0) &#123; evens.add(n); &#125;&#125;// streamevens = nums.stream().filter(num-&gt;num%2 == 0).collect(Collectors.toList());evens.forEach(System.out::println); 上面的例子中，通过 stream() 将集合转成流，filter() 对流进行过滤，筛选后的结果由收集器 collect() 对结果进行封装处理 中间操作 我们先定义一个学生实体类，用来说明中间操作有什么应用 123456789public class Student &#123; private int id; private String name; private int age; private int score; private String school; private String document; //... Getters,Setters,Constructor等省略&#125; 123456789List&lt;Student&gt; students = new ArrayList&lt;Student&gt;() &#123; &#123; add(new Student(2013201319, "zcl", 18, 100, "HEU", "computer")); add(new Student(2013201320, "zjm", 20, 90, "HEU", "computer")); add(new Student(2013201321, "tyf", 19, 95, "HEU", "software")); add(new Student(2013201322, "zzh", 22, 97, "HIT", "computer")); add(new Student(2013201323, "ggy", 21, 89, "HIT", "software")); &#125;&#125;; 过滤filter 过滤姓名以‘z’开头的 12List&lt;Student&gt; z_list = students.stream().filter(stu-&gt;stu.getName() .charAt(0) == 'z').collect(Collectors.toList()); distinct 找出偶数后去掉重复的 12List&lt;Integer&gt; evens = nums.stream().filter(num-&gt;num%2==0) .distinct().collect(Collectors.toList()); sort&amp;limit 找出成绩排名前三的同学 12List&lt;Student&gt; scoreList = this.students.stream().sorted((s1, s2)-&gt; s2.getScore() - s1.getScore()).limit(3).collect(Collectors.toList()); skip 找出成绩排名第三名以后的同学 12List&lt;Student&gt; scoreList = this.students.stream().sorted((s1, s2)-&gt; s2.getScore() - s1.getScore()).skip(3).collect(Collectors.toList()); 映射当我们只想得到一个类的某一个属性值 map 想筛选出所有成绩大于80分的同学的名字，总分和平均分 (mapToInt, mapToDouble) 1234List&lt;String&gt; names = this.students.stream().filter(s-&gt;s.getScore()&gt;80) .map(Student::getName).collect(Collectors.toList());int sum = this.students.stream().mapToInt(Student::getScore).sum();OptionalDouble average_score = this.students.stream().mapToDouble(Student::getScore).average(); flagMap 现在想求几个字符串中出现的字符，比如String[] strs = {&quot;java&quot;, &quot;is&quot;, &quot;easy&quot;, &quot;to&quot;, &quot;use&quot;};，用方法一，先将集合中的每个字符串分解成字符数组，在 distinct 操作是在字符数组之间找的，不是以字符为单位；方法二，flagMap 将一个流中每个值都转成一个个流，然后再将这些流扁平化成为一个流，这样可以达到目的 123456789101112// 方法一Arrays.stream(strs).map(s-&gt;s.split("")) .distinct().collect(Collectors.toList()).forEach(l-&gt;&#123; Arrays.asList(l).forEach(s -&gt; System.out.print(s + " ")); System.out.println(); &#125;);// 方法二Arrays.stream(strs).map(s-&gt;s.split("")) .flatMap(Arrays::stream).distinct().sorted(). collect(Collectors.toList()).forEach(l-&gt;&#123; Arrays.asList(l).forEach(s-&gt; System.out.print(s + " ")); &#125;); 终端操作查找 allMatch：检测是否全部满足指定的参数行为，如果全部满则返回 true，否则返回 false anyMatch：检测是否存在满足条件 noneMatch：是否不存在 findFirst：找第一 findAny：找任意一个（顺序流式处理中，findFirst 和 findAny 返回的结果是一样的） 归约reduce方法 123456789101112// 非reduce写法int totalAge = this.students.stream() .filter(s-&gt;s.getAge()&gt;18) .mapToInt(Student::getAge).sum();// 规约操作int totalAge1 = this.students.stream().filter(s-&gt;s.getAge()&gt;18) .mapToInt(Student::getAge).reduce(0, (a, b)-&gt;a + b);int totalAge2 = this.students.stream().filter(s-&gt;s.getAge()&gt;18) .map(Student::getAge).reduce(0, Integer::sum);Optional&lt;Integer&gt; totalAge3 = this.students.stream() .filter(s-&gt;s.getAge()&gt;18) .map(Student::getAge).reduce(Integer::sum); 收集 经过中间操作处理后结果的封装，比如collect(Collectors.toList())，类似的还有 toSet``toMap，这些方法都来自于 java.util.stream.Collectors这个收集器 下面的栗子是相同功能的不同写法（“回”字的不同写法） 12345678910111213141516171819202122// 及格学生总数long a = this.students.stream().filter(s-&gt;s.getScore()&gt;60).collect(Collectors.counting());long b = this.students.stream().filter(s-&gt;s.getScore()&gt;60).count();// 最高分，最低分Optional&lt;Student&gt; maxScore = this.students.stream() .collect(Collectors.maxBy((s1, s2)-&gt;s1.getScore()-s2.getScore()));Optional&lt;Student&gt; maxScore = this.students.stream() .collect(Collectors.maxBy(Comparator.comparing(Student::getScore)));Optional&lt;Student&gt; maxScore = this.students.stream() .collect(Collectors.minBy(Comparator.comparing(Student::getScore)));// 总分和平均分int totalScore = this.students.stream().collect(Collectors.summingInt(Student::getScore));double averageScore = this.students.stream() .collect(Collectors.averagingInt(Student::getScore));// 一次性统计得到元素个数、总和、均值、最大值、最小值（这封装的也是够了）IntSummaryStatistics statistics = this.students.stream() .collect(Collectors.summarizingInt(Student::getScore));// 字符串拼接String names = this.students.stream().map(Student::getName) .collect(Collectors.joining());String names1 = this.students.stream().map(Student::getName) .collect(Collectors.joining(", ")); // 用", "分隔名字 分组1234567// 按学校对集合分组Map&lt;String, List&lt;Student&gt;&gt; groups = this.students.stream().collect(Collectors.groupingBy(Student::getSchool));groups.forEach((k, v)-&gt;&#123; System.out.println(k); v.forEach(x-&gt;System.out.print(x.getName() + " ")); System.out.println();&#125;); groupingBy 接收一个分类器Function&lt;? super T, ? extends K&gt; classifier，可以一级或多级分类，如： 123Map&lt;String, Map&lt;String, List&lt;Student&gt;&gt;&gt; group = this.students.stream().collect( Collectors.groupingBy(Student::getSchool, Collectors.groupingBy(Student::getDocument))); groupingBy 的第二个参数可以传递任意 Collector 类型，如 Collectors.groupingBy，Collectors.counting，如果不添加第二个参数，默认是Collectors.toList 123// 集合中一个学校的人数，按学校分组后统计组内人数Map&lt;String, Long&gt; groups = this.students.stream().collect( Collectors.groupingBy(Student::getSchool, Collectors.counting())); 区分 区分是分组的一种特殊情况，将集合内容分为 true, flase 两类，比如求男女人数；下面是区分的两种写法，用 groupingBy 和 partitioningBy 都能实现 12345// 求集合中学生是HEU 和不是 HEU 的人数（列表）Map&lt;Boolean, Long&gt; groups = this.students.stream().collect( Collectors.groupingBy(x-&gt;x.getSchool().equals("HEU"), Collectors.counting()));Map&lt;Boolean, List&lt;Student&gt;&gt; partition = this.students.stream().collect( Collectors.partitioningBy(stu-&gt;"HEU".equals(stu.getSchool()))); 并行流式数据处理 充分利用计算机的CPU内核数，并发处理的思想。将 stream() 替换成 parallelStream()即可，但会涉及多线程安全问题，当然效率提高的很多。 参考文献java8 新特性 lamda和Stream Java8 新特性之流式数据处理]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[singleton]]></title>
    <url>%2F2018%2F08%2F18%2Fsingleton%2F</url>
    <content type="text"><![CDATA[多线程安全的单例模式某类只能有一个对象，构造函数为 private，通过静态成员变量和函数获得变量 模式1 类加载的时候直接 new 出静态对象，无法懒加载，降低内存的使用率 12345678910public class Singleton &#123; // 直接初始化一个实例对象 private static Singleton instance = new Singleton(); // 私有构造方法保证其他类对象不能直接 new 该对象的实例 private Singleton() &#123;&#125; public static Singleton getInstance() &#123; return instance; &#125;&#125; 模式2 多线程创建实例，一个时刻只能有一个线程得到同步锁，但是，每次通过 getInstance 方法得到 singleton 实例都要获得锁，但是只有第一次创建锁才有意义，加锁是很耗时的操作 12345678910public class Singleton &#123; private static Singleton instance = null; private Singleton() &#123;&#125; public static synchronized Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 模式3 只有当 instance 为 null 时，才需要加锁，也只需创建一次实例，以后则无需加锁 123456789101112131415public class Singleton &#123; private static volatile Singleton instance = null; private Singleton() &#123;&#125; public static Singleton getInstance() &#123; // 先判断实例是否初始化 if (instance == null) &#123; synchronized(Singleton.class) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 模式4 私有内部类；不用加锁 123456789public class Singleton &#123; private Singleton() &#123;&#125; private static class Inner &#123; private static Singleton s = new Singleton(); &#125; public static Singleton getSingle() &#123; return Inner.s; &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[producter&consumer]]></title>
    <url>%2F2018%2F07%2F18%2Fproducter-consumer%2F</url>
    <content type="text"><![CDATA[生产者消费者wait &amp; notifyAll 使用 wait, notifyAll 实现生产者消费者问题，注意使用 while 判断容器的容量和 notifyAll 通知所有等待线程，notify只会唤醒一个线程，比如生产者将容器放满，又唤醒了一个生产者，使唤醒的生产者进入死循环，无法唤醒其他线程 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859import java.util.LinkedList;import java.util.concurrent.TimeUnit;public class MyContainer1&lt;T&gt; &#123; final private LinkedList&lt;T&gt; lists = new LinkedList&lt;&gt;(); final private int MAX = 10; // 生产者放入 public synchronized void put(T t) &#123; while (lists.size() == MAX) &#123; try &#123; this.wait(); // wait 一般外面都是 while，如果用if，且生产者唤醒生产者，会继续向下执行向容器中添加，导致超出最大容量 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; lists.add(t); this.notifyAll();// 不能用notify!!! 通知所有等待线程，希望唤醒的是消费者 &#125; // 消费者取出 public synchronized T get() &#123; T t = null; while (lists.size() == 0) &#123; try &#123; this.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; t = lists.removeFirst(); this.notifyAll();// 通知生产者线程进行生产 return t; &#125; public static void main(String[] args) &#123; MyContainer1&lt;String&gt; c = new MyContainer1&lt;&gt;(); // 启动消费者线程 for (int i=0; i&lt;10; i++) &#123; new Thread(()-&gt;&#123; for (int j=0; j&lt;5; j++) &#123; System.out.println(c.get()); &#125; &#125;, "c" + i).start(); &#125; try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; // 启动生产者线程 for (int i=0; i&lt;2; i++) &#123; new Thread(()-&gt;&#123; for (int j=0; j&lt;25; j++) &#123; c.put(Thread.currentThread().getName() + " " + j); &#125; &#125;, "p" + i).start(); &#125; &#125;&#125; ReentrantLock &amp; Condition 使用 ReentrantLock 和 Condition 实现P-C问题，能够控制哪些线程等待与唤醒，对于同一个锁，创建多个Condition 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374import java.util.LinkedList;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;public class MyContainer2&lt;T&gt; &#123; final private LinkedList&lt;T&gt; lists = new LinkedList&lt;&gt;(); final private int MAX = 10; private Lock lock = new ReentrantLock(); private Condition producer = lock.newCondition(); private Condition consumer = lock.newCondition(); // 生产者 public void put(T t) &#123; try &#123; lock.lock(); while (lists.size() == MAX) &#123; producer.await();// 满了生产者等待 &#125; lists.add(t); consumer.signalAll();// 唤醒消费者来取 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; // 消费者 public T get() &#123; T t = null; try &#123; lock.lock(); while (lists.isEmpty()) &#123; consumer.await();// 没有可以取的 &#125; t = lists.removeFirst(); // 有则取走 producer.signalAll();// 通知生产者放 &#125; catch(InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; return t; &#125; public static void main(String[] args) &#123; MyContainer2&lt;String&gt; c = new MyContainer2&lt;&gt;(); // 消费者线程 10*5，要小于生产者放入的个数 for (int i=0; i&lt;10; i++) &#123; new Thread(()-&gt;&#123; for (int j=0; j&lt;5; j++) &#123; System.out.println(c.get()); &#125; &#125;, "c" + i).start(); &#125; try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; // 生产者线程 2*25 要大于消费者取出的个数，如果小于消费者取出的个数，消费者会因取不到而死循环 for (int i=0; i&lt;2; i++) &#123; new Thread(()-&gt;&#123; for (int j=0; j&lt;25; j++) &#123; c.put(Thread.currentThread().getName() + " " + j); &#125; &#125;, "p" + i).start(); &#125; &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[concurrent]]></title>
    <url>%2F2018%2F07%2F14%2Fconcurrent%2F</url>
    <content type="text"><![CDATA[java 并发处理为什么要加锁 下面的例子，自增操作不具备原子性，导致多个线程同时对 count 操作时相互影响，比如一次操作一个线程取到的 count 为100，当它完成 ++ 操作把 count 赋值为 101 的时候，可能覆盖掉了这期间别的线程对count 的操作，最后结果远小于100000 12345678910111213141516171819202122232425262728293031import java.util.ArrayList;import java.util.List;public class T implements Runnable &#123; private int count = 0; // 加上 synchronized 后，线程依次执行run方法，不会相互影响 public /*synchronized*/ void run() &#123; for (int i=0;i&lt;10000;i++) &#123; count ++; &#125; &#125; public static void main(String[] args) &#123; T t = new T(); List&lt;Thread&gt; tl = new ArrayList&lt;&gt;(); for(int i=0; i&lt;5; i++) &#123; tl.add(new Thread(t, "THREAD" + i)); &#125; tl.forEach((o)-&gt;o.start()); // 等待所有线程结束 tl.forEach((o)-&gt;&#123; try &#123; o.join(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;); System.out.println(t.count); &#125;&#125; synchronized 锁定堆内存中的对象，线程执行过程中一定要取到对象的🔒才能执行，否则等待当前线程释放对象的🔒并获取才能执行，语法： 123456789101112131415161718public class Concurrent &#123; public void m() &#123; synchronized (this) &#123; // 要并发处理的代码 &#125; &#125; // or 同步方法：函数内的所有代码都加锁 public synchronized void m() &#123; &#125; // 一下两种写法都是在静态函数中锁定对象的类 public static void m() &#123; synchronized(T.class) &#125; public synchronized static void m() &#123; &#125;&#125; 注： synchronized 修饰的代码越少越好，不要包含无需并发处理的代码 锁定的是堆中的对象，不是栈中的引用，应该避免将锁定对象的引用变成另外的对象 不要以字符串常量做锁定对象：String a=&quot;hello&quot;; String b=&quot;hello&quot;; a 和 b 指向的同一个对象 对写方法加锁，读方法不加锁，容易产生脏读 (dirtyRead)（在没写完就读，读到的是过时的值） synchronized 获得的锁是可重入的：在一个类的同步方法 a() 调用该类（父类）中的另一个同步方法 b()，在这个线程已经拥有了对象的锁时候，再次申请的时候任然会得到该对象的锁。 线程执行过程中如果发生异常，默认情况锁会被释放 volatile volatile 关键字使一个变量在多个线程间可见 原理：A线程用到一个变量时，java 会在线程中保留一份copy，这样如果 B线程修改了该变量，则 A线程未必知道，使用 volatile 关键字可以让所有线程再去内存里读一下更新变量的值。 volatile boolean running = true; volatile 不能保证多线程同时对一个变量修改带来的不一致问题，不能替代 synchronized，即只能保证可见性，不能保证原子性 例如： 123456789101112131415161718192021public class T &#123; volatile int count = 0; void m() &#123; for(int i=0; i&lt;10000; i++) count++; &#125; public static void main(String[] args) &#123; T t = new T(); List&lt;Thread&gt; threads = new ArrayList&lt;Thread&gt;(); for(int i=0; i&lt;10; i++) &#123; threads.add(new Thread(t::m, "thread-"+i)); &#125; threads.forEach((o)-&gt;o.start()); threads.forEach((o)-&gt;&#123; try &#123; o.join(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); System.out.println(t.count); &#125; 上面的例子输出的结果小于100000，因为多线程同时修改变量的值，即使随时都去内存里相互更新，但互相影响，解决办法是让 m() 前加上 synchronized 修饰。 123456/*volatile*/ int count = 0;synchronized void m() &#123; for (int i = 0; i &lt; 10000; i++) count++; &#125; 但 synchronized 效率不高，有没有更好的方法呢… AtomicXXX AtomicXXX 类的方法都是原子性的，但是多个方法之间是不具备原子性的 AtomicXXX 效率很高，推荐使用 12345678910111213141516171819202122232425public class T &#123; // volatile int count = 0; AtomicInteger count = new AtomicInteger(0); void m() &#123; for (int i = 0; i &lt; 10000; i++) // while (count.get() &lt; 10000) 对于count 的 get 和 incrementAndGet() 之间不具有原子性，导致get的时候小于10000，但因为多线程共同increment可能使得最后结果大于100000 count.incrementAndGet(); &#125; public static void main(String[] args) &#123; T t = new T(); List&lt;Thread&gt; threads = new ArrayList&lt;Thread&gt;(); for (int i = 0; i &lt; 10; i++) &#123; threads.add(new Thread(t::m, "thread-" + i)); &#125; threads.forEach((o) -&gt; o.start()); threads.forEach((o) -&gt; &#123; try &#123; o.join(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); System.out.println(t.count); &#125;&#125; 线程间通信Wait &amp; Notify 小故事：厕所里只有一个坑，有很多人冲了进来上厕所，只有一个人占有了这个坑并锁上了门，其他人只能等待，处于就绪状态。就绪状态的线程是处于可运行线程池中的，就绪状态的线程除CPU之外，其他运行所需资源都已全部获得；那么厕所就是这个可运行线程池，等待的人就是就绪线程，一旦门开了，即有一个就绪线程可以运行；这把锁就相当于synchronized 锁住了坑这个对象，就绪状态的人持有资源但不能运行，无形中是一种浪费。那么，可不可以让他们先别持有资源了，先离开厕所回到座位去 wait（阻塞状态），等里面的人出来了再冲进去争抢呢？阻塞状态的线程释放占有的所有资源进入等待池中，这个状态是不能自己唤醒的，需要有人通知（notify）才被唤醒，节省了资源。 wait 会释放锁，线程进入阻塞态，前提是先获得锁，一般与 synchronized 配合使用，外面一般是 while notify 不会释放锁，会唤醒 wait 的线程，不会立即释放锁；notify 只会唤醒一个等待（对象的）线程，notifyAll 会唤醒所有等待（对象的）线程，《Effective Java》中说永远使用 notifyAll 不要使用 notify。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import java.util.concurrent.TimeUnit;public class T &#123; boolean volatile session = false; String volatile content = ""; public static void main(String[] args) &#123; T t = new T(); final Object lock = new Object(); new Thread(()-&gt;&#123; System.out.println("t1 start"); synchronized(lock) &#123; while (!t.session) &#123; try &#123; lock.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(t.content); System.out.println("t2 end"); lock.notifyAll(); // 唤醒 t2 &#125; &#125;, "t1").start(); try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; new Thread(()-&gt;&#123; System.out.println("t2 start"); synchronized (lock) &#123; for (int i=1; i&lt;=10; i++) &#123; System.out.println(i); if (i == 5) &#123; t.session = true; lock.notifyAll(); // 唤醒 t1 t.content = "Hello " + i; try &#123; lock.wait(); // 释放锁 &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;, "t2").start(); &#125;&#125; Latch wait 和 notify 通信过程比较繁琐，使用 Latch 代替 wait, notify来进行线程间的通知，好处是使通讯简单，可以指定等待时间 123456789101112131415161718192021222324252627282930313233343536373839404142434445import java.util.concurrent.CountDownLatch;import java.util.concurrent.TimeUnit;public class T3 &#123; private volatile int num = 0; public static void main(String[] args) &#123; T3 t = new T3(); CountDownLatch latch = new CountDownLatch(1); // latch的count值为1，下面自减为0可唤醒所有等待线程 new Thread(()-&gt;&#123; System.out.println("t1 start"); if (t.num != 5) &#123; try &#123; latch.await(); // 等待，放弃锁 &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; System.out.println("t1 end"); &#125;, "t1").start(); try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; new Thread(()-&gt;&#123; System.out.println("t2 start"); for (int i=0; i&lt;10; i++) &#123; System.out.println("t2:" + i); if (i == 5) &#123; latch.countDown(); // latch的count由1变0，唤醒t1 &#125; try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; System.out.println("t2 end"); &#125;, "t2").start(); &#125;&#125; ReentrantLock ReentrantLock 可以替代 synchronized 锁定 this 对象，锁定后必须要手动释放锁，经常在 finally 中进行锁的释放，synchronized 释放锁后随机选择等待的线程开始执行，ReentrantLock 可以指定为公平锁。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class T &#123; Lock lock = new ReentrantLock(); void m1() &#123; lock.lock(); // 加锁 try &#123; for (int i=0; i&lt;10; i++) &#123; System.out.println(i); TimeUnit.SECONDS.sleep(1); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); // 手动释放锁 &#125; &#125; // 同 synchronized void m2() &#123;&#125; void m2() &#123; lock.lock(); System.out.println("m2 start..."); lock.unlock(); &#125; void m3() &#123; boolean isLocked = false; try &#123; isLocked = lock.tryLock(5, TimeUnit.SECONDS); // 尝试5s获得锁，获得不到返回false，继续向下执行 System.out.println("m2 start..."); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; if (isLocked) lock.unlock(); &#125; &#125; public static void main(String[] args) &#123; T t = new T(); new Thread(t::m1).start(); try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; new Thread(t::m2).start(); &#125;&#125; 当线程 t2 等待线程 t1，而线程t1长时间占用 cpu，可以手动让 t2 打断 t1，令 t2 执行。 12345678910111213141516171819202122232425262728Thread t1 = new Thread(()-&gt;&#123; try &#123; lock.lock(); TimeUnit.SECONDS.sleep(Integer.MAX_VALUE); &#125; catch(InterruptedException e) &#123; System.out.println("interrupted!"); &#125; finally &#123; lock.unlock(); &#125;&#125;);t1.start();// 睡2sThread t2 = new Thread(()-&gt;&#123; boolean locked = lock.tryLock(); try &#123; lock.lockInterruptibly(); System.out.println(Thread.currentThread().getName() + " start"); TimeUnit.SECONDS.sleep(5); &#125; catch(InterruptedException e) &#123; System.out.println("t2 interrupted"); &#125; finally &#123; if (locked) lock.unlock(); &#125; System.out.println(Thread.currentThread().getName() + " end");&#125;, "t2");t2.start();// 睡2st2.interrupt(); 公平锁：唤醒等待线程按照先来先服务的机制而不是随机，当然公平会带来一定的负担 12345678910111213141516171819202122import java.util.concurrent.locks.ReentrantLock;public class T4 implements Runnable&#123; private static ReentrantLock lock = new ReentrantLock(true); //参数为true表示为公平锁 public static void main(String[] args) &#123; T4 t = new T4(); Thread t1 = new Thread(t); Thread t2 = new Thread(t); t1.start(); t2.start(); &#125; @Override public void run() &#123; for (int i=0; i&lt;100; i++) &#123; lock.lock(); System.out.println(Thread.currentThread().getName() + "获得锁"); lock.unlock(); &#125; &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python-data-process]]></title>
    <url>%2F2018%2F02%2F26%2Fpython-data-process%2F</url>
    <content type="text"><![CDATA[前言 Python 科学计算中用到的数据处理，图像绘制的方法记录。好多不知道啥意思，先背住吧，用到的时候再找…Python 做科学计算东西挺多的，现在还不能自己掌握，得不断积累 随机生成正态分布的数据123456789101112131415161718192021222324252627282930313233343536373839404142434445464748__author__ = 'ZJM'__time__ = '2018/2/26 15:22'import numpy as npfrom numpy.linalg import choleskyimport matplotlib.pyplot as pltimport matplotlib.mlab as mlabfrom scipy.stats import multivariate_normalfrom sklearn.mixture import GaussianMixturefrom mpl_toolkits.mplot3d import Axes3DsampleNo = 1000# 一维正太分布mu = 3sigma = 15np.random.seed(0)s = np.random.normal(mu, sigma, sampleNo)plt.subplot(221)n, bins, patches = plt.hist(s, 50, normed=1)# add a best fit lineline = mlab.normpdf(bins, mu, sigma)plt.plot(bins, line, 'r--')plt.xlabel('x')plt.ylabel('y')plt.title(r'$\mu=' + str(mu) + '$, $\sigma=' + str(sigma) + '$')# 二维正态分布mu = np.array([1, 5])sigma = np.array([[1, 0], [0, 1.5]])R = cholesky(sigma)s = np.dot(np.random.randn(sampleNo, 2), R) + muplt.subplot(222)plt.plot(s[:, 0], s[:, 1], '+')# 三维正太分布mu = np.array([0] * 3)# sigma = np.array([[1, 1, 3], [1, 2, 1], [0, 0, 1]])sigma = np.diag((1, 1, 1))data = np.random.multivariate_normal(mu, sigma, 500)norm = multivariate_normal(mu, sigma)tau = norm.pdf(data)fig = plt.figure(figsize=(13, 7), facecolor='w')ax = fig.add_subplot(223, projection='3d')ax.scatter(data[:, 0], data[:, 1], data[:, 2], c='b', s=30, marker='o', depthshade=True)ax.set_xlabel('X')ax.set_ylabel('Y')plt.tight_layout()plt.show()]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Scientific Computation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[math basic]]></title>
    <url>%2F2018%2F02%2F24%2Fmath-basic%2F</url>
    <content type="text"><![CDATA[前言 数学功底太差，概率论与数理统计、线性代数，大量概念理解不够，之前的强化记忆都为了应付考试，记题型、背步骤，现在用到数据处理和公式推导时发现都不会了。下面把一些用到的概念记录下，主要是看到的通俗的解释，直观形象的描述。尽量使概念活起来。^ - ^ 线代最小二乘法正交阵 n阶矩阵A，满足ATA=E，则A为正交阵 A=(a1,a2,…,an), A为正交阵，有： aiTai=1, aiTaj=0(i≠j) 即A的行(列)向量都是单位向量，且两两正交 单位向量保证ATA 对角线都是1，正交使得其他元素都是0 A, B 都是n阶正交阵，则A×B是正交阵 对称阵 协方差矩阵，二次型矩阵，无向图邻接矩阵都是对称阵 实对称阵不同特征值的特征向量正交 设A为n阶对称阵，则必有正交阵P，使得P-1AP = PTAP = Λ 其中P为A的特征向量组成的矩阵，Λ对角线上是A的特征值，即A为对称阵，做合同变换，特征值不变，A与Λ互为合同矩阵 正定阵 直观上：正定阵是一种实对称阵 对于n阶方阵A，若任意n阶非零向量x，都有xTAx&gt;0，则称A是正定阵。 给定任意m×n的矩阵A，ATA一定是半正定对称方阵 对称阵A是正定阵，A特征值都为正，A的顺序主子式都为正 向量的导数 问题：A为m×n的矩阵，x为n×1的列向量，则Ax为m×1的列向量，记y=Ax，y对x的偏导为AT 概率期望 平均数的扩展 小学的时候，考语数外，三科一样重要，期末成绩三科求和除以3即可得到平均分。大学了，每科都有学分，学分大的更重要，在所有科目中占的比重就大。求平均分时就要带着权重啦。xk 的概率pk 就相当于它的权重。期望反应数据的平均水平。 离散型： 连续型： 方差 衡量随机变量或一组数据时离散程度 在统计描述中： 在概率分布中： 离散型： ​ 展开后： 连续型： 协方差Cov 描述两个变量在变化过程中同向还是反向，及其程度。 你大我也大，同向，协方差为正 你大我小，反向，协方差为负 协方差数值绝对值越大则程度越强 相关系数ρ 也可以反映两个变量变化时是同向还是反向，如果同向变化就为正，反向变化就为负。 由于除以了两个变量的标准差，消除了变化幅度的影响，只考虑变化率的相似程度 似然函数 Likehood function 似然函数 是关于统计模型中的参数的函数 给定输出 x 时，关于参数θ的似然函数L(θ|x)=P(X=x|θ) 概率描述了已知参数时的随机变量的输出结果；似然描述已知随机变量输出结果时，未知参数的可能取值 离散型 L(θ|x) = P(X=x|θ) 或 P(X=x;θ) 连续型 L(θ|x) = f(x|θ) 求极大似然函数 写出似然函数 对似然函数取对数 求导数 解似然方程]]></content>
      <categories>
        <category>mechine learning</category>
      </categories>
      <tags>
        <tag>statistic</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[backtracking questions]]></title>
    <url>%2F2018%2F02%2F23%2Fbacktracking-questions%2F</url>
    <content type="text"><![CDATA[回溯法求幂集、排列组合、回文区分幂集无重复元素发幂集 Given a set of distinct integers, nums, return all possible subsets (the power set). Note: The solution set must not contain duplicate subsets. For example,If nums = [1,2,3], a solution is:[[3], [1], [2], [1,2,3], [1,3], [2,3], [1,2], []] 1234567891011121314151617def subsets(self, nums): """ :type nums: List[int] :rtype: List[List[int]] """ ans = [] l = len(nums) def backtrack(tempList, start): ans.append(tempList) for i in range(start, l): tempList.append(nums[i]) backtrack(tempList[:], i+1) tempList.pop() backtrack([], 0) return ans 存在重复元素的幂集 Given a collection of integers that might contain duplicates, nums, return all possible subsets (the power set). Note: The solution set must not contain duplicate subsets. or example,If nums = [1,2,2], a solution is: [[2], [1], [1,2,2], [2,2], [1,2], []] 123456789101112131415161718192021def subsetWithDup(self, nums): """ :type nums: List[int] :rtype: List[List[int]] """ l = len(nums) ans = [] nums = sorted(nums) tempList = [] def backtrack(start): ans.append(tempList[:]) for i in range(start, l): if i &gt; start and nums[i] == nums[i-1]: # skip duplicates continue tempList.append(nums[i]) backtrack(i+1) tempList.pop() backtrack(0) return ans 全排列问题无重复元素的全排列 Given a collection of distinct numbers, return all possible permutations. For example,[1,2,3] have the following permutations: [[1,2,3], [1,3,2], [2,1,3], [2,3,1], [3,1,2], [3,2,1]] 12345678910111213141516171819202122def permute(self, nums): """ :type nums: List[int] :rtype: List[List[int]] """ l = len(nums) ans = [] tempList = [] def backtrack(): if len(tempList) == l: ans.append(tempList[:]) else: for i in range(l): if nums[i] in tempList: continue tempList.append(nums[i]) backtrack() tempList.pop() backtrack() return ans 存在重复元素的全排列 Given a collection of numbers that might contain duplicates, return all possible unique permutations. For example,[1,1,2] have the following unique permutations: [[1,1,2], [1,2,1], [2,1,1]] 1234567891011121314151617181920212223242526def permuteWithUnique(self, nums): """ :type nums: List[int] :rtype: List[List[int]] """ nums = sorted(nums) l = len(nums) ans = [] tempList = [] used = [False] * l def backtrack(): if len(tempList) == l: ans.append(tempList[:]) else: for i in range(l): if used[i] or i &gt; 0 and nums[i] == nums[i-1] and not used[i-1]: continue used[i] = True tempList.append(nums[i]) backtrack() used[i] = False tempList.pop() backtrack() return ans Input: [3, 3, 0, 3] Output: [[0, 3, 3, 3], [3, 0, 3, 3], [3, 3, 0, 3], [3, 3, 3, 0]] 组合问题元素可以用多次 Given a set of candidate numbers (C) (without duplicates) and a target number (T), find all unique combinations in C where the candidate numbers sums to T. For example, given candidate set [2, 3, 6, 7] and target 7,A solution set is: [ [7], [2, 2, 3] ] 123456789101112131415161718192021222324def combinationSum(self, candidates, target): """ :type candidates: List[int] :type target: int :rtype: List[List[int]] """ ans = [] l = len(candidates) tempList = [] candidates = sorted(candidates) def backtrack(remain, start): if remain &lt; 0: return if remain == 0: ans.append(tempList[:]) else: for i in range(start, l): tempList.append(candidates[i]) backtrack(remain-candidates[i], i) tempList.pop() backtrack(target, 0) return ans 元素只能用一次 Given a collection of candidate numbers (C) and a target number (T), find all unique combinations in C where the candidate numbers sums to T. Each number in C may only be used once in the combination. For example, given candidate set [10, 1, 2, 7, 6, 1, 5] and target 8,A solution set is: [[1, 7], [1, 2, 5], [2, 6], [1, 1, 6]] 1234567891011121314151617181920212223242526def combinationSum2(self, candidates, target): """ :type candidates: List[int] :type target: int :rtype: List[List[int]] """ l = len(candidates) ans = [] templist = [] candidates = sorted(candidates) def backtrack(remain, start): if remain &lt; 0: return if remain == 0: ans.append(templist[:]) else: for i in range(start, l): if i &gt; start and candidates[i] == candidates[i-1]: continue templist.append(candidates[i]) backtrack(remain - candidates[i], i+1) templist.pop() backtrack(target, 0) return ans 找回文子集 Given a string s, partition s such that every substring of the partition is a palindrome. Return all possible palindrome partitioning of s. For example, given s = &quot;aab&quot;,Return [[&quot;aa&quot;,&quot;b&quot;], [&quot;a&quot;,&quot;a&quot;,&quot;b&quot;]] 1234567891011121314151617181920212223242526272829def partition(self, s): """ :type s: str :rtype: List[List[str]] """ l = len(s) ans = [] tempList = [] def isPalindrome(low, high): while low &lt; high: if s[low] != s[high]: return False low += 1 high -= 1 return True def backtrack(start): if start == l: ans.append(tempList[:]) else: for i in range(start, l): if isPalindrome(start, i): tempList.append(s[start: i+1]) backtrack(i+1) tempList.pop() backtrack(0) return ans summary: 我还没看懂… 以后再更新 -_-||| Copy from：https://leetcode.com/problems/subsets/discuss/27281/A-general-approach-to-backtracking-questions-in-Java-(Subsets-Permutations-Combination-Sum-Palindrome-Partitioning)]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java map-reduce]]></title>
    <url>%2F2018%2F02%2F11%2Fjava-map-reduce%2F</url>
    <content type="text"><![CDATA[Java开发Map/Reduce程序MR程序执行方式： 在本地运行，输入输出都在本地，用于调试程序 把远程数据拉到本地运行，输出传回远程，只适合数据量小 在远程运行，输入输出都在远程 Java程序在服务器上运行 配置系统环境变量HADOOP_HOME，指向hadoop安装目录（如果你不想招惹不必要的麻烦，不要在目录中包含空格或者中文字符） 把HADOOP_HOME/bin加到PATH环境变量（非必要，只是为了方便） 如果是在windows下开发，需要添加windows的库文件 把盘中共享的bin目录覆盖HADOOP_HOME/bin 如果还是不行，把其中的hadoop.dll复制到c:\windows\system32目录下，可能需要重启机器 maven引入依赖 新建项目，引入hadoop 所需要的jar文件 1234567891011121314151617181920212223242526&lt;properties&gt; &lt;project.build.sourceencoding&gt;UTF-8&lt;/project.build.sourceencoding&gt; &lt;hadoop.version&gt;2.7.3&lt;/hadoop.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt; &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt; &lt;version&gt;$&#123;hadoop.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt; &lt;artifactId&gt;hadoop-common&lt;/artifactId&gt; &lt;version&gt;$&#123;hadoop.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt; &lt;artifactId&gt;hadoop-hdfs&lt;/artifactId&gt; &lt;version&gt;$&#123;hadoop.version&#125;&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 代码WordMapper.java1234567891011121314151617181920212223package com.zjm;import java.io.IOException;import org.apache.hadoop.io.IntWritable;import org.apache.hadoop.io.LongWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Mapper;public class WordMapper extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt;&#123; @Override protected void map(LongWritable key, Text value, Mapper&lt;LongWritable, Text, Text, IntWritable&gt;.Context context) throws IOException, InterruptedException &#123; final IntWritable ONE = new IntWritable(1); String s = value.toString(); String[] words = s.split(" "); for(String word: words) &#123; context.write(new Text(word), ONE); &#125; &#125; &#125; WordReduce.java12345678910111213141516171819202122package com.zjm;import java.io.IOException;import org.apache.hadoop.io.IntWritable;import org.apache.hadoop.io.LongWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Reducer;public class WordReducer extends Reducer&lt;Text, IntWritable, Text, LongWritable&gt;&#123; @Override protected void reduce(Text key, Iterable&lt;IntWritable&gt; values, Reducer&lt;Text, IntWritable, Text, LongWritable&gt;.Context context) throws IOException, InterruptedException &#123; long count = 0; for(IntWritable v: values) &#123; count += v.get(); &#125; context.write(key, new LongWritable(count)); &#125;&#125; main函数1234567891011121314151617181920212223242526272829303132333435363738package com.zjm;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.Path;import org.apache.hadoop.io.IntWritable;import org.apache.hadoop.io.LongWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Job;import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;public class Test &#123; public static void main(String[] args) throws Exception&#123; Configuration conf = new Configuration(); conf.set("fs.defaultFS", "hdfs://master:9000/"); // 将项目打包到项目跟目录下 conf.set("mapreduce.job.jar", "wc.jar"); conf.set("mapreduce.framework.name", "yarn"); conf.set("yarn.resourcemanager.hostname", "master"); conf.set("mapreduce.app-submission.cross-platform","true"); Job job = Job.getInstance(conf); job.setMapperClass(WordMapper.class); job.setReducerClass(WordReducer.class); job.setMapOutputKeyClass(Text.class); job.setMapOutputValueClass(IntWritable.class); // Reduce 的输出类型 job.setOutputKeyClass(Text.class); job.setOutputValueClass(LongWritable.class); FileInputFormat.setInputPaths(job, "/input/"); FileOutputFormat.setOutputPath(job, new Path("/output")); job.waitForCompletion(true); &#125;&#125; 注： win系统的hosts文件添加虚拟机的IP和主机名 配置hadoop在win系统的环境变量 Run as —— Run Configurations —— Arguments —— VM arguments: -DHADOOP_USER_NAME=root]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Yarn&Map/Reduce]]></title>
    <url>%2F2018%2F02%2F09%2FYarn-Map-Reduce%2F</url>
    <content type="text"><![CDATA[分布式计算 设计原则：移动计算，不移动数据 Yarn Yarn: 资源调度 主从结构：ResourceManager 和 NodeManager ResourceManager 将任务分配给空闲的机器(slave)工作，NodeManager在slave中做具体的资源利用，RM管理NM yarn-site.xml的配置 修改ResourceManager和NodeManager的vim hadoop/etc/hadoop/yarn-site.xml 1234567891011121314&lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;master&lt;/value&gt;&lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.auxservices.mapreduce.shuffle.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;&lt;/property&gt; 启动yarn集群start-yarn.sh 访问8088端口 Map/Reduce 在 ResourceManager上配置mapred-site.xml 1234&lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt; 执行示例程序 1hadoop jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar wordcount /input/input.txt /output 查看运行结果 hadoop fs -text /output/part-r-00000 Map/Reduce 流程 input split 拆分（一行一行） map 映射（键值对） shuffle 派发（键值对派发到一个nodeManager） reduce 缩减（按键统计值的和） output]]></content>
      <categories>
        <category>Big Data</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java hdfs]]></title>
    <url>%2F2018%2F02%2F08%2Fjava-hdfs%2F</url>
    <content type="text"><![CDATA[Java程序访问HDFS导入所需的jar文件 12345678910111213&lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-common --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt; &lt;artifactId&gt;hadoop-common&lt;/artifactId&gt; &lt;version&gt;2.7.3&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-hdfs --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt; &lt;artifactId&gt;hadoop-hdfs&lt;/artifactId&gt; &lt;version&gt;2.7.3&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package dbfs;import java.io.FileInputStream;import java.math.BigDecimal;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.FSDataOutputStream;import org.apache.hadoop.fs.FileStatus;import org.apache.hadoop.fs.FileSystem;import org.apache.hadoop.fs.Path;import org.apache.hadoop.io.IOUtils;public class HelloHDFS &#123; public static void main(String args[]) throws Exception &#123;// URL.setURLStreamHandlerFactory(new FsUrlStreamHandlerFactory());// URL url = new URL("hdfs://192.168.137.100:9000/hello.txt");// InputStream in = url.openStream();// IOUtils.copyBytes(in, System.out, 4096, true); Configuration conf = new Configuration(); conf.set("fs.defaultFS", "hdfs://192.168.137.100:9000"); // 修改hdfs配置参数值 conf.set("dfs.replication", "5"); FileSystem fileSystem = FileSystem.get(conf); // 判断路径是否存在 boolean success = fileSystem.exists(new Path("/zjm")); System.out.println(success); // 新建路径，注意如果已经存在同名目录会覆盖原目录x_x success = fileSystem.mkdirs(new Path("/zjm")); System.out.println(success); // 删除 success = fileSystem.delete(new Path("/zjm"), true); System.out.println(success); // 上传文件 FSDataOutputStream out = fileSystem.create(new Path("/test.data")); FileInputStream fis = new FileInputStream("F:learn/mashibing/hadoop/马士兵hadoop2.7入门_03.mp4"); IOUtils.copyBytes(fis, out, 4096, true); fileSystem.delete(new Path("/video"), true); // 上传文件：IO流可计算上传进度 FSDataOutputStream out = fileSystem.create(new Path("/video")); FileInputStream in = new FileInputStream("F:learn/mashibing/hadoop/马士兵hadoop2.7入门_03.mp4"); int total = in.available(); byte[] buf = new byte[4096]; int len = in.read(buf); int now = len; while(len != -1) &#123; // 上传百分比，保留小数点后两位 System.out.println(new BigDecimal((float)now/total*100).setScale(2, BigDecimal.ROUND_HALF_UP).doubleValue()); out.write(buf, 0, len); len = in.read(buf); now += len; &#125; in.close(); out.close(); // 查看文件结构 FileStatus[] statuses = fileSystem.listStatus(new Path("/")); for(FileStatus status: statuses) &#123; System.out.println(status.getPath()); System.out.println(status.getPermission()); System.out.println(status.getReplication()); &#125; &#125;&#125; 注：需要关闭权限检查，向hdfs-site.xml中添加并重启hdfs 1234&lt;property&gt; &lt;name&gt;dfs.permissions.enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt;&lt;/property&gt; description: If “true”, enable permission checking in HDFS. If “false”, permission checking is turned off, but all other behavior is unchanged. Switching from one parameter value to the other does not change the mode, owner or group of files or directories.]]></content>
      <categories>
        <category>Big Data</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop hdfs]]></title>
    <url>%2F2018%2F02%2F06%2Fhadoop-hdfs%2F</url>
    <content type="text"><![CDATA[在多台服务器上配置Hadoop 启动namenode和datanode hadoop-daemon.sh start namenode(datanode) 在master上检测datanode hdfs dfsadmin -report | more 在web页面观察hadoop集群情况 192.168.137.100:50070 集中管理Slaves 在/usr/local/hadoop/etc/hadoop下的slaves文件中添加slaves的主机名，在master中就可以管理其中的所有slaves，如： 123slave1slave2slave3 执行：start-dfs.sh，输入master, slave, secondaryNameNode的密码 为了避免输入多次的密码，在 /.ssh 下执行 ssh-keygen -t rsa 回车三次，发现.ssh下生成两个文件：id_ras （私钥）和 id_ras.pub（公钥） 从master发送公钥到master, slave1, slave2, slave3：ssh-copy-id master, ssh-copy-id slave1, ssh-copy-id slave2, ssh-copy-id slave3 以后ssh IP 就不用再输入密码了，再执行start-dfs.sh时就不用再次输入密码了 hdfs文件系统指令 hadoop fs -ls或hdfs dfs -ls 放置一个文件到hdfs中：hadoop fs -put file / 通过网页观察现象：http://192.168.137.100:50070/explorer.html#/ 指令： hadoop fs -mkdir /dirname hadoop fs -text /filename 查看文本文件内容 hadoop fs -rm /filename 配置参数 编写/hadoop/etc/hadoop/hdfs-site.xml eg: 修改复制的个数为2份（默认为3份）： 1234&lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt;&lt;/property&gt;]]></content>
      <categories>
        <category>Big Data</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop配置环境及启动]]></title>
    <url>%2F2018%2F02%2F05%2Fhadoop-day1%2F</url>
    <content type="text"><![CDATA[VirtualBox启动虚拟机 host-only方式连接虚拟机 安装Hadoop 连接虚拟机 查看虚拟网卡的IP地址(assume:192.168.137.1)，VM设置网卡类型为host-only 设置ipv4地址：vim /etc/sysconfig/network-scripts/ifcfg-enp03 IPADDR=192.168.137.100 NETMASK=255.255.255.0 设置网关地址及域名解析：vim /etc/sysconfig/network NETWORKING=yes GATEWAY=192.168.137.1 DNS1=8.8.8.8 设置计算机上能上网的网卡共享网络给虚拟网卡 修改主机名 hostnamectl set-hostname master 重启network服务 service network restart 互相ping 虚拟机：ping 192.168.137.1 电脑：ping 192.168.137.100 安装Hadoop 打开Xftp上传jdk，hadoop安装文件至/usr/local目录下 安装jdk rpm -ivh jdk-8u91-linux-x64.rpm 解压hadoop cd local tar -xvf hadoop-2.7.3.tar.gz 发现local目录下多了hadoop-2.7.3的目录(改名为了方便：mv hadoop-2.7.3 haddop) 配置Hadoop JDK路径 cd hadoop/etc/hadoop vim hadoop-env.sh export JAVA_HOME=/usr/java/default 将hadoop执行命令添加到path环境变量里 vim /etc/profile 添加：export PATH=$PATH:/usr/local/hadoop/bin:/usr/local/hadoop/sbin 执行： source /etc/profile 以这台虚拟机做master，复制出三台虚拟机做slaver，配置IP和网关，改主机名分别为slave1, slave2, slave3 启动Hadoop配置所有虚拟机1234567cd /usr/local/hadoop/etc/hadoopvim core-site.xml # master管理结点，slave知道master&lt;!-- 在&lt;configuration&gt;内添加：--&gt;&lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://master:9000&lt;/value&gt;&lt;/property&gt; 修改所有虚拟机的host文件 vim /etc/hosts eg 1234192.168.137.100 master192.168.137.101 slave1192.168.137.102 slave2192.168.137.103 slave3 格式化namenode(仅master) hdfs namenode -format 启动namenode(仅master) hadoop-daeman.sh start namenode 输入jps，出现NameNode则namenode启动 启动datanode(slaver) hadoop-daemon.sh start datanode]]></content>
      <categories>
        <category>Big Data</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[laravel基础]]></title>
    <url>%2F2017%2F09%2F13%2Flaravel%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[安装错误 solution: 打开运行环境中的php.ini，用快速查找找到 extension=php_openssl.dll 此项，然后把该代码前面的分号去掉，最后重启运行环境，刷新页面 路由 作用: 将请求映射到程序（处理函数） laravel/app/Http/routes.php: 基础路由 123Route::get('basic1',function () &#123; return 'Hello World';&#125;); 多请求路由 123Route::match(['get','post'], 'multy', function () &#123; return 'multy';&#125;); 所有请求种类路由 123Route::any('allRequest',function() &#123; return 'all request';&#125;); 路由参数 123Route::get('user/&#123;id&#125;/&#123;name?&#125;',function ($id,$name=null) &#123; return 'User-id'.$id.'User-name:'.$name;&#125;)-&gt;where(['id'=&gt;'[0-9]+','name'=&gt;'[A-Za-z]+']); 路由别名 123Route::get('user/center',['as'=&gt;'center', function() &#123; return route('center');&#125;]); 路由群组 12345678Route::group(['prefix'=&gt;'member'], function ()&#123; Route::get('basic2',function() &#123; return 'Basic2'; &#125;); Route::get('user/center',['as'=&gt;'center', function() &#123; return route('center'); &#125;]);&#125;); 路由输出视图 123Route::get('view', function ()&#123; return view('welcome');&#125;); 控制器 laravel/app/Http/Controllers: 路由将请求发送给控制器，控制器处理请求并返回相应 路由和控制器中的方法关联： 1234567891011Route::get('member/info','MemberController@info');Route::get('member/info',['uses'=&gt;'MemberController@info']);Route::get('member/info',[ 'uses' =&gt; 'MemberController@info', 'as' =&gt; 'member_info']);Route::get('member/find/&#123;id&#125;','MemberController@find')-&gt;where('id','[0-9]+'); 控制器中有对应路由请求的函数： 12345678910111213141516171819namespace App\Http\Controllers;class MemberController extends Controller &#123; public function info() &#123; //return 'member-info'; return route('member_info'); &#125; // 接收请求参数 public function find($id) &#123; return 'member'.$id; &#125; // 返回一个视图，向视图中传递数据 public function toInfo() &#123; return view('member/info',[ 'name' =&gt; 'shaun', 'age' =&gt; 18 ]); &#125;&#125; 视图 laravel/resources/views: 控制器的方法返回一个视图，并传递参数给视图，视图使用模板解析展示数据 laravel 默认模板文件名为：xxx.blade.php 用 的形式获取变量值 模型 laravel/app: 123456789namespace App;use Illuminate\Database\Eloquent\Model;class Member extends Model &#123; public static function getMember() &#123; return 'member name is shaun'; &#125;&#125; 数据库操作DB facade 配置：laravel/config/database.php laravel/.env 使用 DB facade 实现 CURD 1234567891011121314151617181920212223namespace App\Http\Controllers;use Illuminate\Support\Facades\DB;class UserController extends Controller &#123; public function curd() &#123; // 返回是否插入成功 $bool = DB::insert('insert into user(name,sex,phone,email) VALUES(?,?,?,?) ', ['zcl','1','1365656556','zcl@163.com']); var_dump($bool); // 返回查询结果的数组 $users = DB::select('select* from user'); dd($users); // json格式 // 返回变动的数量 $num = DB::update('update user set age=? where name = ?', [18,'zjm']); var_dump($num); // 返回删除的条数 $num = DB::delete('delete from user where id=?', [3]); var_dump($num); &#125;&#125; 查询构造器 Laravel 查询构造器 (query builder) 提供接口，用来建立及执行数据库查找语法 使用 PDO 参数绑定，以保护应用程序免于 SQL 注入，传入的参数不需要额外转义特殊字符 基本可以满足所有的数据库操作 使用查询构造器新增数据 123456789101112131415161718// 返回bool插入是否成功DB::table('user')-&gt;insert([ 'name' =&gt; 'ms', 'sex' =&gt; '0', 'age' =&gt; '18', 'phone' =&gt; '13666666666', 'email' =&gt; 'maoshuo@gmail.com']);// 返回插入的 id$id = DB::table('user')-&gt;insertGetId([ 'name' =&gt; 'shaun', 'age' =&gt; 19]);// 插入多条记录，二维数组存放信息，返回boolDB::table('user')-&gt;insert([ ['name' =&gt; '张三', 'age' =&gt; 21], ['name' =&gt; '李四', 'age' =&gt; 22],]); 使用查询构造器更新数据 更新数据 自增自减 123456789101112// 返回受影响的行数$num = DB::table('user') -&gt;where('id',7) -&gt;update([ 'name' =&gt; 'zjm' ]);var_dump($num);// 自减同时更新子段值$num = DB::table('user') -&gt;where(['id'=&gt;7]) // -&gt;where('id',7) -&gt;decrement('age',3, ['name' =&gt; 'zjmhaha']); //increment 自增 decrement 自减var_dump($num); 使用查询构造器删除数据 delete trancate——清空表… 12345678$num = DB::table('user') -&gt;where('id',7) -&gt;delete();var_dump($num);$num = DB::table('user') -&gt;where('id', '&gt;=', 13) -&gt;delete();var_dump($num); 使用查询构造器查询数据 get()——获取结果集所有数据 first()——获取结果集中第一条 where()——查询条件，whereRaw()——多条件查询 pluck()——返回结果集中指定的字段 lists()——类似pluck select()——查询指定的字段 chunk() ——分页返回所有结果集 1234567891011121314151617181920212223242526272829public function search() &#123; // get() 获取表中所有数据 $users = DB::table('user')-&gt;get(); // first 获取结果集第一条 $users = DB::table('user') -&gt;orderBy('id','desc') // 倒序 -&gt;first(); $users = DB::table('user') -&gt;where('age','&gt;=',20) -&gt;get(); // 多条件查询 $users = DB::table('user') -&gt;whereRaw('id &gt;= ? and age &gt; ?', [2, 20]) -&gt;get(); // pluck 返回结果集中指定的字段 $name = DB::table('user')-&gt;pluck('name'); //$name = DB::table('user')-&gt;lists('name', 'id'); //dd($name); //select 查询指定的字段 $users = DB::table('user') -&gt;select('id','name','age') -&gt;get(); // chunk echo '&lt;pre&gt;'; $num = DB::table('user')-&gt;chunk(2, function($users) &#123; var_dump($users); &#125;); var_dump($num); &#125; 查询构造器中的聚合函数 count() max() min() avg() sum() 12345678// 聚合函数public function aggregate() &#123; $num = DB::table('user')-&gt;count(); $num = DB::table('user')-&gt;max('age'); $num = DB::table('user')-&gt;min('age'); $num = DB::table('user')-&gt;avg('age'); $num = DB::table('user')-&gt;sum('age');&#125; 数据库操作-Eloquent ORM 数据表和一个相对应的模型 (Model) 用于和数据表交互 查询构造器在ORM中依旧有应用 模型建立 laravel/app: 12345678910namespace App;use Illuminate\Database\Eloquent\Model;class Student extends Model &#123; // 指定表名，默认为 students protected $table = 'student'; // 指定id,默认为id protected $id = 'id';&#125; ORM 查询123456789101112131415161718192021public function orm() &#123; // 查询所有 $students = Student::all(); // 按主键查询 $student = Student::find(1); // 找不到id报错 $student = Student::findOrFail(2); // 查询构造器在ORM中使用 $students = Student::get(); $student = Student::where('age','&gt;',18) -&gt;orderBy('age','desc') -&gt;first(); dd($student); echo '&lt;pre&gt;'; Student::chunk(2, function ($students) &#123; var_dump($students); &#125;); $num = Student::count(); $max = Student::where('age','&gt;',18)-&gt;max('age'); var_dump($max); &#125; ORM中新增，自定义时间戳及批量赋值 通过模型新增数据（自定义时间戳） 使用模型的Create方法新增数据（批量赋值） 模型属性的定义，方法重写123456789101112131415161718192021222324252627namespace App;use Illuminate\Database\Eloquent\Model;class Student extends Model &#123; // 指定表名，默认为 students protected $table = 'student'; // 指定id,默认为id protected $id = 'id'; // 指定允许批量赋值的字段 protected $fillable = ['name', 'age']; // 指定不允许批量赋值的字段// protected $guarded = []; // 关闭created_at 和 updated_at public $timestamps = true; // 自意义返回时间戳 /*protected function getDateFormat() &#123; return time(); &#125;*/ // /*protected function asDateTime( $value ) &#123; return $value; &#125;*/&#125; 注：由于laravel自定义添加的created_at时间不是北京时间，可以将数据库 created_at字段类型改为 int，重写模型的 getDateFormat()方法，如果希望返回时间戳(数字形式)，再重写asDateTime()函数 四种常用的ORM新增1234567891011121314151617181920212223242526272829public function orm2() &#123; // 使用模型新增数据 /*$student = new Student(); $student-&gt;name = 'ms'; $student-&gt;age = 18; $bool = $student-&gt;save(); dd($bool);*/ /*$Student = Student::find(3); echo $Student-&gt;created_at.'&lt;br&gt;'; echo date('Y-m-d H:i:s', 1464509164);// 只对于数字时间戳*/ // 使用模型的Create方法新增数据，这里的属性必须为模型中指定允许批量赋值的字段 /*$student = Student::create([ 'name' =&gt; 'zjm', 'age' =&gt; 18 ]); dd($student);*/ //firstOrCreate() 按属性查找，没有找到则新加 /*$student = Student::firstOrCreate([ 'name' =&gt; 'zjm22333' ]); dd($student);*/ //firstOrNew() 按属性查找，没有则建立新的实例，自己调用save()保存 $student = Student::firstOrNew([ 'name' =&gt; 'zjm123123' ]); $student-&gt;save(); dd($student); &#125; 注： 使用模型的Create方法新增数据，这里的属性必须为模型中指定允许批量赋值的 使用Eloquent ORM修改数据 通过模型更新 结合查询语句 批量更新 1234567$student = Student::find(8);$student-&gt;name = 'shaun';$bool = $student-&gt;save();var_dump($bool);Student::where('id','&gt;',7)-&gt;update([ 'age' =&gt; 23]); 注： 使用ORM的save()方法更新子段必须使模型的主键和数据库表主键相同，包括大小写 模型中默认主键名：id 重写模型中主键名：protected $primaryKey = &#39;Id&#39;; 使用Eloquent ORM删除数据 通过模型删除 通过主键值删除 根据指定条件删除 123456789// 通过模型删除（没有会报错）$student = Student::find(9);$bool = $student-&gt;delete();// 通过主键删除,返回删除个数$num = Student::destroy(7);$num = Student::destroy(7,8,9);$num = Student::destroy([7,8,9]);// 条件删除$num = Student::where('id', '&gt;', 6)-&gt;delete(); Blade模板引擎Blade模板引擎简介及模板继承的使用 页面公共的部分提取出来形成一个父类，方便开发和维护 @section…@show @yield 12345@extends(&apos;layouts&apos;)&lt;!-- 继承 views下的基类视图 --&gt;@section(&apos;header&apos;) @parent &lt;!-- 父模板内容 --&gt; self_content@stop 基础语法及include的使用 在控制器中返回视图并传入参数 123return view('student.section1', [ 'name' =&gt; $name]); 在模板中输出参数值 1234567891011121314151617&gt; &#123;&#123; $name &#125;&#125;&gt; &lt;!-- 调用php函数，执行php代码 --&gt;&gt; &#123;&#123; time() &#125;&#125;&gt; &#123;&#123; date(&apos;Y-m-d H:i:s&apos;, time()) &#125;&#125;&gt; &#123;&#123; in_array($name, $arr) ? &apos;true&apos; : &apos;false&apos;&#125;&#125;&gt; &#123;&#123; var_dump($arr) &#125;&#125;&gt; &lt;!-- 存在输出，不存在输出默认 --&gt;&gt; &#123;&#123; isset($name) ? $name:&apos;default&apos; &#125;&#125;&gt; &lt;!-- 可简化为： --&gt;&gt; &#123;&#123; $name or &apos;default&apos; &#125;&#125;&gt; &lt;!-- 原样输出 --&gt;&gt; @&#123;&#123; $name &#125;&#125;&gt; &lt;!-- 模板中的注释：不在页面源码中显示 --&gt;&gt; &#123;&#123; -- 你的注释 -- &#125;&#125;&gt; &lt;!-- 引入子视图 --&gt;&gt; @include(&apos;student.common1&apos;)&gt; 流程控制123456789101112131415161718192021222324252627282930@if ($name == &apos;zzz&apos;) I&apos;m zzz@elseif($name == &apos;aaa&apos;) I&apos;m aaa@else ...@endif@if(in_array($name, $arr)) true@else false@endif@unless($name == &apos;zjm&apos;) &lt;!--if的取反--&gt; I&apos;m zjm@endunless@for($i=0; $i &lt; 10; $i++) &#123;&#123; $i &#125;&#125;@endfor @foreach($students as $student) &lt;p&gt;&#123;&#123; $student-&gt;name &#125;&#125;&lt;/p&gt; @endforeach@forelse($students as $student) &lt;p&gt;&#123;&#123; $student-&gt;name &#125;&#125;&lt;/p&gt; @empty &lt;p&gt;无数据&lt;/p&gt; @endforelse 模板中的URL url()——通过路由名字 action()——通过制定控制器的方法名 route()——通过路由别名 123&lt;a href="&#123;&#123; url('url) &#125;&#125;"&gt;&lt;/a&gt; &lt;a href="&#123;&#123; action('StudentController.urlTest') &#125;&#125;"&gt;&lt;/a&gt; &lt;a href="&#123;&#123; route('url') &#125;&#125;"&gt;&lt;/a&gt; `]]></content>
      <categories>
        <category>web服务</category>
      </categories>
      <tags>
        <tag>php框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[求所有LCS的简单算法及矩阵搜索算法]]></title>
    <url>%2F2017%2F08%2F21%2FLCS%2F</url>
    <content type="text"><![CDATA[动态规划——最长公共子序列（LCS）背景知识 子序列： 原序列 X，将 X 中的元素组成新序列 Z，这些元素的先后位置与原序列相对一致，Z 是 X 的一个子序列 最长公共子序列： 若 Z 是 X 的子序列 , Z 也是 Y 的子序列，且不存在比 Z 更长的 X 和 Y 的公共子序列，则称 Z 是 X 和 Y 的最长公共子序列 ，记为 Z ∈LCS( X , Y) 。最长公共子序列往往不止一个 eg: X = { A，B，C，B，D，A，B }，Y = { B，D，C，A，B，A }，则 { B，C，B，A } 是 X 和 Y 的一条公共子序列，由于没有更长的公共子序列，故也是一条最长公共子序列 最长公共子序列的结构 在穷举法中，将 X 中所有子序列，检查它是否也是 Y 的子序列，确定是公共子序列后记录最长的公共子序列。设 X 有 m 个元素，则它的子序列有 2m个，穷举法需要指数时间 最长公共子序列具有最优子结构 设序列 X = { x1，x2，···，xm } 和 Y = { y1，y2，···，yn } 的最长公共子序列为 Z = { z1，z2，···，zk }，则 若 xm = yn，则 zk = xm = yn，且Zk-1 是 Xm-1 和 Yn-1 的最长公共子序列 若 xm ≠ yn，且 zk ≠ xm，则 Z 是 Xm-1 和 Y 的最长公共子序列 若 xm ≠ yn，且 zk ≠ yn，则 Z 是 X 和 Yn-1 的最长公共子序列 子问题的递归结构 如果从顶向下计算，将出现大量的子问题重叠…动态规划的基本思想是从低向上计算不同子问题，通过底部子问题的解，得出顶部问题的解。最终目的是得到最顶上问题的解。 建立两个矩阵 c 和 b，矩阵 c 用来存放 i, j 位置的最长公共子序列长度(简记为LCS长度)，矩阵 b 存放i, j 位置是由哪个方向来的，方便回溯 建立递归关系如下： c[i,j]={0,i=0 or j=0c[i−1,j−1]+1,i,j&gt;0 and xi=yjmax(c[i−1,j],c[i,j−1]),i,j&gt;0 and xi≠yjc[i,j]=\begin{cases} 0, &amp; i=0\ or\ j=0\\ c[i-1,j-1]+1,&amp;i,j&gt;0\ and\ x_i=y_j\\ max(c[i-1,j],c[i,j-1]), &amp;i,j&gt;0\ and\ x_i\ne y_j \end{cases} c[i,j]=​⎩​⎪​⎨​⎪​⎧​​​0,​c[i−1,j−1]+1,​max(c[i−1,j],c[i,j−1]),​​​i=0 or j=0​i,j&gt;0 and x​i​​=y​j​​​i,j&gt;0 and x​i​​≠y​j​​​​ b[i,j]={1,i,j&gt;0 and xi=yj2,i,j&gt;0 and xi≠yj and c[i−1,j]&gt;c[i,j−1]3,i,j&gt;0 and xi≠yj and c[i−1,j]≤c[i,j−1] b[i,j]=\begin{cases} 1,&amp;i,j&gt;0\ and\ x_i=y_j\\ 2, &amp;i,j&gt;0\ and\ x_i\ne y_j\ and\ c[i-1,j]&gt;c[i,j-1]\\ 3, &amp;i,j&gt;0\ and\ x_i\ne y_j\ and\ c[i-1,j]\leq c[i,j-1] \end{cases} b[i,j]=​⎩​⎪​⎨​⎪​⎧​​​1,​2,​3,​​​i,j&gt;0 and x​i​​=y​j​​​i,j&gt;0 and x​i​​≠y​j​​ and c[i−1,j]&gt;c[i,j−1]​i,j&gt;0 and x​i​​≠y​j​​ and c[i−1,j]≤c[i,j−1]​​ 图中右下角 5(2) 表示 (8, 8) 位置的LCS长度为5，由上面的位置 (7, 8) 得到 右下角的值就是LCS长度，从该点通过矩阵 b 回溯，遇到 2 向上走，遇到 3 向左走，遇到 1 斜上走，当遇到边缘时(i=0 或 j=0)停止，既可以得到一条最长公共子序列 这样做只能得到两串的一条最长公共子序列，因为当 c[i−1,j]=c[i,j−1] 时可以向上也可以向左，但是我们指定它向左了，这样就不会出现不同的情况。于是，可以添加一种 b 的值： b[i,j]=4, i,j&gt;0 and xi≠yj and c[i−1,j]=c[i,j−1]b[i,j]=4,\ \ \ \ i,j&gt;0\ and\ x_i\ne y_j\ and\ c[i-1,j]=c[i,j-1]b[i,j]=4, i,j&gt;0 and x​i​​≠y​j​​ and c[i−1,j]=c[i,j−1] 当 b[i][j] = 4 时(下文称为分叉点)，向上走也向左走，这样可以遍历到所有的路径 如图，当遇到分叉点的时候将分出两个路径，将所有分叉点作为非叶子结点组成一棵二叉树： 最下面的叶子结点个数就是所有路径个数 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106#include &lt;iostream&gt;#include &lt;string.h&gt;#include &lt;set&gt;using namespace std;int num = 0; // 记录遍历路径数int** getArr(int,int); // 动态创建二维数组void LCS(int**,int**,string,string,int,int); // 给 c,b 数组赋值void TraceBack(string,string,int**,int,int); // 回溯路径set&lt;string&gt; setOfLCS; // set保存所有的LCS，set集合中元素不重复int main() &#123; string s1,s2; cin&gt;&gt;s1&gt;&gt;s2; int len1 = s1.size() + 1; int len2 = s2.size() + 1; int** c = getArr(len1,len2); int** b = getArr(len1,len2); // 使 s1,s2 与 c,b 坐标一致 s1 = " " + s1; s2 = " " + s2; // 自底向上给 c,b 数组赋值 LCS(c,b,s1,s2,len1,len2); // 显示 c,b 数组 for(int i=0;i&lt;len1;i++) &#123; for(int j=0;j&lt;len2;j++) &#123; cout&lt;&lt;c[i][j]&lt;&lt;" "; if(j == len2-1) cout&lt;&lt;endl; &#125; &#125; cout&lt;&lt;"===============================\n"; for(int i=0;i&lt;len1;i++) &#123; for(int j=0;j&lt;len2;j++) &#123; cout&lt;&lt;b[i][j]&lt;&lt;" "; if(j == len2-1) cout&lt;&lt;endl; &#125; &#125; // 从右下角根据 b 数组指向回溯到边界 TraceBack(s1,"",b,len1-1,len2-1); cout&lt;&lt;"All route number: "&lt;&lt;num&lt;&lt;endl; cout&lt;&lt;"Remove duplicate elements: "&lt;&lt;endl; // 遍历set，输出所有LCS set&lt;string&gt;::iterator iter=setOfLCS.begin(); while(iter != setOfLCS.end()) &#123; cout&lt;&lt;*iter&lt;&lt;endl; iter++; &#125; cout&lt;&lt;"LCS length: "&lt;&lt;c[len1-1][len2-1]&lt;&lt;endl; cout&lt;&lt;"LCS number: "&lt;&lt;setOfLCS.size()&lt;&lt;endl; return 0;&#125;void LCS(int** c,int** b,string s1,string s2,int m,int n) &#123; for(int i=1;i&lt;m;i++) &#123; for(int j=1;j&lt;n;j++) &#123; if(s1[i] == s2[j]) &#123; c[i][j] = c[i-1][j-1] + 1; b[i][j] = 1; // 斜上 &#125; else if(c[i-1][j] &gt; c[i][j-1]) &#123; c[i][j] = c[i-1][j]; b[i][j] = 2; // 上 &#125; else if(c[i-1][j] &lt; c[i][j-1]) &#123; c[i][j] = c[i][j-1]; b[i][j] = 3; // 左 &#125; else &#123; c[i][j] = c[i-1][j]; b[i][j] = 4; // 上 或 左 &#125; &#125; &#125;&#125;// 返回动态创建的二维数组的指针int** getArr(int M,int N) &#123; int** arr = new int*[M]; for(int i=0;i&lt;M;i++) &#123; arr[i] = new int[N]; memset(arr[i],0,sizeof(int)*N); &#125; return arr;&#125;void TraceBack(string s1,string temp,int** b,int i,int j) &#123; while(i&gt;0 &amp;&amp; j&gt;0) &#123; if(b[i][j] == 1) &#123; temp = s1[i] + temp; i--; j--; &#125; else if(b[i][j] == 2) &#123; i--; &#125; else if(b[i][j] == 3) &#123; j--; &#125; else &#123; // 递归回溯 TraceBack(s1,temp,b,i-1,j); TraceBack(s1,temp,b,i,j-1); return; &#125; &#125; num ++; // 打印一次遍历得到的字符串，可能是重复的 cout&lt;&lt;"###"&lt;&lt;temp&lt;&lt;endl; // 交给 set 来移除重复字符串 setOfLCS.insert(temp);&#125; 输入 12badcdcbaabcdcdab 得到的结果为：LCS长度=5，总路径数=18，除去重复的子串后，所有LCS个数为8 可以发现：回溯过程中不同路径出现大量交叉，由于总路径数是二叉树的叶子结点数，最坏情况下，二叉树高度为max(m,n)，即两串长度最大值，叶子结点个数为2max(m,n)，这些情况中还存在大量重复，筛选很麻烦，最后结果可能得到很少的几组数据而已。 优化：矩阵搜索求所有的最长公共子序列 鉴于上述方法的缺点，根据《利用矩阵搜索求所有最长公共子序列的算法》，宫洁卿，安徽工程科技学院学报，vol23,No.4,Dec.,2008 提出的思想，这里进行简要阐述： 将 b[i][j] = 1 的点称为跳跃点，跳跃点使LCS从n→n-1(n=1,2,…,LCS长度)，LCS是由一条路径上的跳跃点对应的字符组成。将n→n-1的每个跳跃点依次找到这个点的所有下一跳跃点，直到没有下一个跳跃点为止。 矩阵搜索算法的基本思路和步骤 两个栈：第一个栈 store 用于存放所有搜索到的元素，当该栈为空时，运算结束；第二个栈 print 用于存放准备打印的元素。先计算出二维数组 C，每个节点都纪录本节点所在的坐标，LCS 长度和指向的方向。假设该 LCS 串最长为 n，那么虚拟一个( n + 1) →n的节点，该节点的坐标位于数组 C 最右下角的节点 C[ i , j ] 的右下方，为 C[ i + 1 , j + 1 ]。将该节点压入栈 store 检测栈 store 是否为空，如果为空，则本算法结束 从 store 栈顶取出一个节点压入 print 栈 如果当前的元素是边界元素1 →0 时，打印栈 print 里面除了栈底的所有元素(无须打印原本不存在的虚拟结点) 。查看 store 栈里最上面一个元素的 LCS 长度，弹出栈 print 里面所有LCS 长度比 store 栈最上面的 LCS 长度大或相等的元素，跳转到第 2 步 设该结点的 LCS 长度为 n +1，从该节点出发，查看该节点的方向箭头，按照斜方向路线、向上的路线（如果是双向的路线则走向上的路线）、向左的路线为优先级找到一个 n → ( n - 1) 的节点，假设为C[ X1 , Y1 ] 再次从该节点出发，查看该节点的方向箭头 ,按照斜方向路线、向左的路线（如果是双向的路线则走向左的路线） 、向上的路线为优先级找到一个 n →( n - 1) 的节点 ,假设为 C[ X2 , Y2 ] 比较 C[ X1 , Y1 ] 和 C[ X2 , Y2 ] 这两个节点。如果这两个结点是同一个结点，则将该结点压入栈 store，跳转到第 2 步 从刚才得到的两个结点 C[ X1 , Y1 ] 和 C[ X2 , Y2 ]，在二维数组 C 中，以 ( X1 , Y1 ) ( X2 , Y1 ) ( X1 ,Y2 ) ( X2 , Y2 ) 这四个点为坐标所构成的矩阵，在该矩阵中搜索所有的元素，将所有满足 n →( n - 1) 的节点压入栈 store。跳转到第 2 步 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186#include &lt;iostream&gt;#include &lt;string.h&gt;#include &lt;stack&gt;using namespace std;int** getArr(int,int);void LCS(int**,int**,string,string,int,int);void TraceBack(int,int,int**,int**,string);struct node &#123; int x; int y; int lcsLen; node()&#123;&#125; node(int x,int y,int z):x(x),y(y),lcsLen(z)&#123;&#125; node(int x,int y,int** c):x(x),y(y),lcsLen(c[x][y])&#123;&#125; bool operator ==(const node &amp;n) &#123; if(this-&gt;x == n.x &amp;&amp; this-&gt;y == n.y) return true; return false; &#125;&#125;;void printStack(stack&lt;node&gt;,string);void popPrint(stack&lt;node&gt;&amp;,int);node findJump(int,int,int**,int**,int);void searchMatrix(node,node,int**,int**,stack&lt;node&gt;&amp;);int main()&#123; string s1,s2; cout&lt;&lt;"Input the first Sequence:"; cin&gt;&gt;s1; cout&lt;&lt;"Input the second Sequence:"; cin&gt;&gt;s2; int len1 = s1.length()+1; int len2 = s2.length()+1; int** c = getArr(len1,len2); int** b = getArr(len1,len2); s1 = " " + s1; s2 = " " + s2; LCS(c,b,s1,s2,len1,len2); for(int i=0;i&lt;len1;i++) &#123; for(int j=0;j&lt;len2;j++) &#123; cout&lt;&lt;c[i][j]&lt;&lt;" "; if(j == len2-1) cout&lt;&lt;endl; &#125; &#125; cout&lt;&lt;"===============================\n"; for(int i=0;i&lt;len1;i++) &#123; for(int j=0;j&lt;len2;j++) &#123; cout&lt;&lt;b[i][j]&lt;&lt;" "; if(j == len2-1) cout&lt;&lt;endl; &#125; &#125; if(c[len1-1][len2-1] == 0) &#123; cout&lt;&lt;"0 0"&lt;&lt;endl; return 0; &#125; TraceBack(len1,len2,c,b,s1); return 0;&#125;int** getArr(int M,int N) &#123; int** arr = new int*[M]; for(int i=0;i&lt;M;i++) &#123; arr[i] = new int[N]; memset(arr[i],0,sizeof(int)*N); &#125; return arr;&#125;void LCS(int** c,int** b,string s1,string s2,int m,int n) &#123; for(int i=1;i&lt;m;i++) &#123; for(int j=1;j&lt;n;j++) &#123; if(s1[i] == s2[j]) &#123; c[i][j] = c[i-1][j-1] + 1; b[i][j] = 1; &#125; else if(c[i-1][j] &gt; c[i][j-1]) &#123; c[i][j] = c[i-1][j]; b[i][j] = 2; &#125; else if(c[i-1][j] &lt; c[i][j-1]) &#123; c[i][j] = c[i][j-1]; b[i][j] = 3; &#125; else &#123; c[i][j] = c[i-1][j]; b[i][j] = 4; &#125; &#125; &#125;&#125;void TraceBack(int m,int n,int** c,int** b,string str) &#123; stack&lt;node&gt; store, print; node virtualNode = node(m,n,c[m-1][n-1]+1); //由虚拟结点引发循环 store.push(virtualNode); node storeTop; int topLen,number=0; while(!store.empty()) &#123; storeTop = store.top(); store.pop(); print.push(storeTop); // 判断弹出的元素是否是边界元素 if(storeTop.x == 1 || storeTop.y == 1 || print.size() == c[m-1][n-1]+1) &#123; number++; printStack(print,str); // 是边界将print栈除虚拟结点的所有点打印 cout&lt;&lt;endl; // 数量太多不要输出这两行了 if(!store.empty()) &#123; topLen = store.top().lcsLen; popPrint(print,topLen); // 弹出小于等于store栈顶长度的print栈中的点 &#125; &#125; else &#123; //不是边界说明还有下一跳 int x = storeTop.x; int y = storeTop.y; node e1 = findJump(x-1,y-1,b,c,0); node e2 = findJump(x-1,y-1,b,c,1); if(e1 == e2) &#123; store.push(e1); &#125; else &#123; searchMatrix(e1,e2,c,b,store); &#125; &#125; &#125; cout&lt;&lt;number&lt;&lt;endl;&#125;// 输出print栈中所有元素void printStack(stack&lt;node&gt; s,string str) &#123; while(!s.empty()) &#123; cout&lt;&lt;str[s.top().x]; s.pop(); &#125;&#125;// 弹出print栈中长度小于等于n的元素，相当于回到前一跳的状态void popPrint(stack&lt;node&gt; &amp;s,int n) &#123; // 由于进入print栈点的lcsLen值是单调减，直接出栈直到lcsLen大于n，最底下的虚拟结点不能出栈 while(s.top().lcsLen &lt;= n &amp;&amp; s.size() != 1) &#123; s.pop(); &#125;&#125;// 寻找所有下一跳，type为真：遇到跳跃点向左走，type为假：遇到跳跃点向上走，直到找到第一个跳跃点node findJump(int x,int y,int** b,int** c,int type) &#123; if(type) &#123; while(b[x][y] != 1)&#123; // 这里一定有下一个跳跃点，不用担心会找不到而越界 if(b[x][y] == 2) x--; else y--; &#125; &#125; else &#123; while(b[x][y] != 1)&#123; if(b[x][y] == 3) y--; else x--; &#125; &#125; return node(x,y,c);&#125;// 如果findJump找到的两个下一跳跃点不是一个点，则以这两个点为矩形搜索里面的跳跃点，视为下一跳跃点加入store栈中void searchMatrix(node e1,node e2,int** c,int** b,stack&lt;node&gt;&amp; store) &#123; int x1 = e1.x; int y1 = e1.y; int x2 = e2.x; int y2 = e2.y; int temp; if(x1 &gt; x2) &#123; temp = x1; x1 = x2; x2 = temp; &#125; if(y1 &gt; y2) &#123; temp = y1; y1 = y2; y2 = temp; &#125; for(int i=x2;i&gt;=x1;i--) &#123; for(int j=y2;j&gt;=y1;j--) &#123; if(b[i][j] == 1) store.push(node(i,j,c)); &#125; &#125;&#125; 根据算法的思想实现了代码，经过以下数据对直接遍历和矩阵搜索进行对比： ABCDCDABCDBADCDCBADC ABCDCDABCDABCDCDABCDBADCDCBADCBADCDCBADC ABCDCDABCDABCDCDABCDABCDCDABCDBADCDCBADCBADCDCBADCBADCDCBADC ABCDCDABCDABCDCDABCDABCDCDABCDABCDCDABCDBADCDCBADCBADCDCBADCBADCDCBADCBADCDCBADC 测试用例编号 LCS长度 所有LCS个数 直接遍历循环次数 1 6 20 60 2 12 700 7560 3 18 25460 970200 4 24 936540 没测出来 当字符串长度40时，简单的遍历所有路径就无法短时间显示结果了]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Prim-Kruscal]]></title>
    <url>%2F2017%2F08%2F13%2FPrim-Kruscal%2F</url>
    <content type="text"><![CDATA[贪心算法——最小生成树 G=(V,E) 是连通带权图，E 中每条边 (v,w) 的权为 c[v][w]，G 的一个子图 G’ 是一颗包含 G 的所有顶点的树，则称 G’ 为 G 的生成树，所有生成树中权值和最小的称为 G 的最小生成树(MST: minimum Spanning Tree) MST 性质：设 G=(V,E) 是连通带权图，U 是 V 中的一个真子集，若存在顶点 u∈U 和顶点 v∈V-U 的边（u，v）是一条具有最小权值的边，则必存在 G 的一棵最小生成树包括这条边（u，v） Prim 和 Kruscal 都应用最小生成树的 MST 性质进行贪心选择 实例中连通带权图为 图的表示：邻接矩阵——使用二维数组存放两点之间的信息 Prim 算法 设 G=(V,E) 是连通带权图，V = {1,2,…,n} 构造 G 的最小生成树的 Prim算法的基本思想是：首先置 S={1}，然后只要 S 是 V 的真子集，就做如下贪心选择：选取满足条件 i∈S，j∈V-S，且 c[i][j] 最小的边，并将顶点 j 添加到 S 中，这个过程一直进行到 S=V为止。这个过程中选取的所有边构成 G 的一颗最小生成树 Question: 如何有效地找出满足 i∈S, j∈V-S，且权 c[i][j] 最小的边 (i,j) ? 代码说明： 对于每个 j∈V-S，closest[j] 是 j 在 S 中的临界顶点，它与 j 在 S 中的其他临接顶点 k 相比较有： c[j][closest[j]]≤c[j][k] lowest[j] 的值就是 c[j][closest[j]] 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#include&lt;stdio.h&gt;#define MIN 100001int Prim(int[100][100],int);int main() &#123; int N; int arr[100][100]; // 存放两点之间连线的权值 while(~scanf("%d",&amp;N)) &#123; // 输入 for(int i=0;i&lt;N;i++) &#123; for(int j=0;j&lt;N;j++) &#123; scanf("%d",&amp;arr[i][j]); &#125; &#125; // Prim printf("最小生成树权值和：%d\n",Prim(arr,N)); &#125; return 0;&#125;// lowcost[i]:V-S中点i到S中的点连线最小权值// closet[i]:V-S中点i到s中权值最小连线应该连的点坐标int Prim(int c[100][100],int N) &#123; int lowcost[N],closest[N], res=0; bool s[N]; // S 集合最开始只有0号元素时，对lowcost, clostest初始化 s[0] = true; for(int i=1;i&lt;N;i++) &#123; lowcost[i] = c[i][0]; // 最开始 S 中只有 0 closest[i] = 0; s[i] = false; &#125; // 将 V-S 集合中的元素放到 S 中 for(int i=1;i&lt;N;i++) &#123; int k, imin = MIN; for(int j=1;j&lt;N;j++) &#123; if(!s[j] &amp;&amp; lowcost[j] &lt; imin) &#123; imin = lowcost[j]; k = j; &#125; &#125; s[k] = true; printf("%d--%d \n",k,closest[k]); res += imin; // 由于 S 中有了一个新的元素，V-S 中各点 lowcost 值可能发生变化 for(int j=1;j&lt;N;j++) &#123; if(!s[j] &amp;&amp; lowcost[j] &gt; c[j][k]) &#123; lowcost[j] = c[j][k]; closest[j] = k; &#125; &#125; &#125; return res;&#125;/*Input:40 4 9 214 0 8 179 8 0 1621 17 16 0*/ Kruscal 算法 先构造一个只含 n 个顶点、而边集为空的子图，把子图中各个顶点看成各棵树上的根结点，之后，从网的边集 E 中选取一条权值最小的边，若该条边的两个顶点分属不同的树，则将其加入子图，即把两棵树合成一棵树，反之，若该条边的两个顶点已落在同一棵树上，则不可取，而应该取下一条权值最小的边再试之。依次类推，直到森林中只有一棵树，也即子图中含有 n-1 条边为止 简单的说： Kruscal 算法先找权值最小的边，检查这条边两个端点是否在一个集合中，如果不在一个集合中，连接两点(合并点所在集合)后找下一条权值最小的边；如果在一个集合，不连接两点直接找下一条权值最小的边，直到连接的边数为n-1为止 Question: 怎样按权递增的顺序查看各边？ 怎样判断两点是否在一个集合中？ 优先队列和并查集 优先队列请见 priority-queue 并查集（Union-find Sets）主要用于处理一些不相交集合 的合并问题，使用树形结构表示一个集合，树的每个节点就表示集合中的一个元素，树根作为集合的代表。 并查集的基本操作有三个： makeSet(s)：建立一个新的并查集，其中包含 s 个单元素集合。 unionSet(x, y)：把元素 x 和元素 y 所在的集合合并，要求 x 和 y 所在的集合不相交，如果相交则不合并。 find(x)：找到元素 x 所在的集合的代表，该操作也可以用于判断两个元素是否位于同一个集合，只要将它们各自的代表比较一下就可以了。在find方法中，如果每次都沿着父节点向上查找，当树很高时，会降低查找效率（时间复杂度就是树的高度）有一种非常简单而有效的策略——路径压缩： 路径压缩，就是在每次查找时，令查找路径上的每个节点都直接指向根节点 并查集的合并：将一个集合的树根指向另一个集合的树根，这样查看每个元素所在树的根节点只需要一步 合并策略——按秩合并：用秩表示树的高度，在合并时，总是将具有较小秩的树根指向具有较大秩的树根。简单的说，就是总是将比较矮的树作为子树，添加到较高的树中。代码中 urank[x] 表示 x 为根的树的高度 使用优先队列将边升序排列（注意对自定义类型要重写 ‘&lt;’ 运算符） 使用并查集判断两点是否在一个集合上（根节点是否相等），合并两集合 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116#include&lt;stdio.h&gt;#include&lt;queue&gt;#define MAXSIZE 100using namespace std;int arr[MAXSIZE][MAXSIZE];int uset[MAXSIZE]; // uset[i] :元素i所属集合的根节点int urank[MAXSIZE]; // urank[i] :元素i为根节点集合的高度int Kruscal(int);int res = 0;struct Edge &#123; int x; int y; int weight; Edge(int x,int y,int weight) &#123; this-&gt;x = x; this-&gt;y = y; this-&gt;weight = weight; &#125; friend bool operator &lt; (Edge edge1, Edge edge2) &#123; return edge1.weight &gt; edge2.weight; &#125;&#125;;priority_queue&lt;Edge&gt; q;int main() &#123; int N; while(~scanf("%d",&amp;N)) &#123; res = 0; // 输入 for(int i=0;i&lt;N;i++) &#123; for(int j=0;j&lt;N;j++) &#123; scanf("%d",&amp;arr[i][j]); &#125; &#125; // 将边放入优先队列中 for(int i=0;i&lt;N-1;i++) &#123; for(int j=i+1;j&lt;N;j++) &#123; q.push(Edge(i,j,arr[i][j])); &#125; &#125; Kruscal(N); printf("%d\n",res); &#125; return 0;&#125;void makeSet(int N) &#123; // 初始时每个元素独立成为一个集合，根节点是本身，集合（树）高度为0 for(int i=0;i&lt;N;i++) &#123; uset[i] = i; urank[i] = 0; &#125;&#125;int findRoot(int x) &#123; // 只有根节点的父节点是本身 if(uset[x] == x) &#123; return x; &#125; // 不是根节点递归寻找根节点，找到后赋值给uset[x]减少下次递归的次数，相当于压缩了到根节点的路径 return uset[x] = findRoot(uset[x]);&#125;bool unionSet(int x,int y) &#123; // 取 x,y 所在集合的根节点 x=findRoot(x); y=findRoot(y); // x,y 属于一个集合，不可合并 if(x == y) &#123; return false; &#125; // x,y 不在同一集合，将高度小的集合加到高度大的集合根节点 else if(urank[x] &gt; urank[y]) &#123; // y 集合的根节点的父亲是 x 集合的根节点 uset[y] = x; &#125; else &#123; uset[x] = y; // 高度相等，x所在集合根节点接到y集合根节点，y集合高度加一 if(urank[x] == urank[y]) &#123; urank[y]++; &#125; &#125; return true;&#125;int Kruscal(int N) &#123; makeSet(N); int qsize = q.size(); int lineNum = 0; for(int i=0;i&lt;qsize;i++) &#123; // e为当前最小权值边 Edge e = q.top(); // 按权值降序处理每一条边，如果两点不在一个集合中，合并两点所在的集合返回true，说明生成了一条连线 if(unionSet(e.x, e.y)) &#123; lineNum ++; res += arr[e.x][e.y]; printf("%d--%d\n",e.x,e.y); // 连线数 = 点数 - 1 时为最小生成树，结束循环 if(lineNum == N - 1) &#123; break; &#125; &#125; q.pop(); &#125;&#125;/*Input:40 4 9 214 0 8 179 8 0 1621 17 16 0*/]]></content>
      <categories>
        <category>算法</category>
        <category>OJ 做题知识点积累</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot-mybatis小程序]]></title>
    <url>%2F2017%2F04%2F09%2Fspringboot-mybatis%2F</url>
    <content type="text"><![CDATA[IntelliJ开发SpringBoot-Mybatis应用程序新建工程 new Project——Spring Initializr 填好工程Name，包路径Group,Package Dependencies页面勾选Web，Mybatis，Mysql会自动帮你生产maven的pom文件，当然也可以自己后往里添加，maven会自动的帮你下载需要的依赖 Finish 注： maven默认中央仓库在国外可能使下载依赖很慢，可以修改maven的conf/settings.xml更换镜像地址： 123456&lt;mirror&gt; &lt;id&gt;alimaven&lt;/id&gt; &lt;name&gt;aliyun maven&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt; 工程结构说明 main-java 目录下的 *Application 类是项目的启动类 main 下的 application.yml 是配置文件 test 是测试类的目录 pom.xml 是 maven 的依赖管理文件 配置文件配置文件有 .properties 和 .yml 两种，格式不同而已，下面的是 .yml 1234567891011121314151617181920212223242526272829303132333435363738#serverserver: port: 80#spring configspring: aop: auto: true datasource: name: * url: jdbc:mysql://localhost:3306/* driverClassName: com.mysql.jdbc.Driver username: * password: * type: com.alibaba.druid.pool.DruidDataSource maxActive: 1000 initialSize: 5 maxWait: 60000 minIdle: 1 timeBetweenEvictionRunsMillis: 60000 minEvictableIdleTimeMillis: 300000 testWhileIdle: true testOnBorrow: false testOnReturn: false poolPreparedStatements: true maxOpenPreparedStatements: 20# MyBatismybatis: type-aliases-package: com.zjm.model mapper-locations: classpath:/mapper/*.xml configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl#PageHelperpagehelper: offsetAsPageNum: true rowBoundsWithCount: true reasonable: true 编写Mybatis 小程序准备 在上面的配置文件中 Mybatis 的配置项里 type-aliases-package：是对象类的路径 (main.java.com.*.model下) mapper-locations：是对象dao类对应的 .xml 的路径 (main.resource.mapper下) 建立以上路径及com.*.dao 在pom.xml中加入依赖：(在标签中) 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.0.20&lt;/version&gt;&lt;/dependency&gt; 在*Application.java文件的类上加入 @MapperScan(basePackages = “com.zjm.dao”) @SpringBootApplication 这两个注解 12345678@MapperScan(basePackages = "com.zjm.dao")@SpringBootApplicationpublic class IshopApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(IshopApplication.class, args); &#125;&#125; 代码User123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899package com.zjm.model;import java.util.Date;public class User &#123; private Integer id; private String nickname; private String password; private String phone; private String email; private Date regdate; private Integer sex; private String head; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public String getNickname() &#123; return nickname; &#125; public void setNickname(String nickname) &#123; this.nickname = nickname == null ? null : nickname.trim(); &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password == null ? null : password.trim(); &#125; public String getPhone() &#123; return phone; &#125; public void setPhone(String phone) &#123; this.phone = phone == null ? null : phone.trim(); &#125; public String getEmail() &#123; return email; &#125; public void setEmail(String email) &#123; this.email = email == null ? null : email.trim(); &#125; public Date getRegdate() &#123; return regdate; &#125; public void setRegdate(Date regdate) &#123; this.regdate = regdate; &#125; public Integer getSex() &#123; return sex; &#125; public void setSex(Integer sex) &#123; this.sex = sex; &#125; public String getHead() &#123; return head; &#125; public void setHead(String head) &#123; this.head = head == null ? null : head.trim(); &#125; @Override public String toString() &#123; return "User&#123;" + "id=" + id + ", nickname='" + nickname + '\'' + ", password='" + password + '\'' + ", phone='" + phone + '\'' + ", email='" + email + '\'' + ", regdate=" + regdate + ", sex=" + sex + ", head='" + head + '\'' + '&#125;'; &#125;&#125; UserMapper12345678910111213141516171819package com.zjm.dao;import com.zjm.model.User;public interface UserMapper &#123; int deleteByPrimaryKey(Integer id); int insert(User record); int insertSelective(User record); User selectByPrimaryKey(Integer id); int updateByPrimaryKeySelective(User record); int updateByPrimaryKey(User record);&#125; UserMapper.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;mapper namespace="com.zjm.dao.UserMapper"&gt; &lt;resultMap id="BaseResultMap" type="com.zjm.model.User"&gt; &lt;id column="Id" jdbcType="INTEGER" property="id" /&gt; &lt;result column="nickName" jdbcType="VARCHAR" property="nickname" /&gt; &lt;result column="password" jdbcType="VARCHAR" property="password" /&gt; &lt;result column="phone" jdbcType="VARCHAR" property="phone" /&gt; &lt;result column="email" jdbcType="VARCHAR" property="email" /&gt; &lt;result column="regDate" jdbcType="DATE" property="regdate" /&gt; &lt;result column="sex" jdbcType="INTEGER" property="sex" /&gt; &lt;result column="head" jdbcType="VARCHAR" property="head" /&gt; &lt;/resultMap&gt; &lt;sql id="Base_Column_List"&gt; Id, nickName, password, phone, email, regDate, sex, head &lt;/sql&gt; &lt;select id="selectByPrimaryKey" parameterType="java.lang.Integer" resultMap="BaseResultMap"&gt; select &lt;include refid="Base_Column_List" /&gt; from user where Id = #&#123;id,jdbcType=INTEGER&#125; &lt;/select&gt; &lt;select id="selectUserByExample" parameterType="User" resultMap="BaseResultMap"&gt; SELECT &lt;include refid="Base_Column_List" /&gt; FROM USER &lt;where&gt; &lt;if test="id != null"&gt; Id = #&#123;id&#125; &lt;/if&gt; &lt;if test="nickname != null"&gt; nickName = #&#123;nickname&#125; &lt;/if&gt; &lt;if test="password != null"&gt; password = #&#123;password&#125; &lt;/if&gt; &lt;if test="phone != null"&gt; phone = #&#123;phone&#125; &lt;/if&gt; &lt;if test="email != null"&gt; email = #&#123;email&#125; &lt;/if&gt; &lt;/where&gt; &lt;/select&gt; &lt;delete id="deleteByPrimaryKey" parameterType="java.lang.Integer"&gt; delete from user where Id = #&#123;id,jdbcType=INTEGER&#125; &lt;/delete&gt; &lt;insert id="insert" parameterType="com.zjm.model.User"&gt; insert into user (Id, nickName, password, phone, email, regDate, sex, head) values (#&#123;id,jdbcType=INTEGER&#125;, #&#123;nickname,jdbcType=VARCHAR&#125;, #&#123;password,jdbcType=VARCHAR&#125;, #&#123;phone,jdbcType=VARCHAR&#125;, #&#123;email,jdbcType=VARCHAR&#125;, #&#123;regdate,jdbcType=DATE&#125;, #&#123;sex,jdbcType=INTEGER&#125;, #&#123;head,jdbcType=VARCHAR&#125;) &lt;/insert&gt; &lt;insert id="insertSelective" parameterType="com.zjm.model.User"&gt; insert into user &lt;trim prefix="(" suffix=")" suffixOverrides=","&gt; &lt;if test="id != null"&gt; Id, &lt;/if&gt; &lt;if test="nickname != null"&gt; nickName, &lt;/if&gt; &lt;if test="password != null"&gt; password, &lt;/if&gt; &lt;if test="phone != null"&gt; phone, &lt;/if&gt; &lt;if test="email != null"&gt; email, &lt;/if&gt; &lt;if test="regdate != null"&gt; regDate, &lt;/if&gt; &lt;if test="sex != null"&gt; sex, &lt;/if&gt; &lt;if test="head != null"&gt; head, &lt;/if&gt; &lt;/trim&gt; &lt;trim prefix="values (" suffix=")" suffixOverrides=","&gt; &lt;if test="id != null"&gt; #&#123;id,jdbcType=INTEGER&#125;, &lt;/if&gt; &lt;if test="nickname != null"&gt; #&#123;nickname,jdbcType=VARCHAR&#125;, &lt;/if&gt; &lt;if test="password != null"&gt; #&#123;password,jdbcType=VARCHAR&#125;, &lt;/if&gt; &lt;if test="phone != null"&gt; #&#123;phone,jdbcType=VARCHAR&#125;, &lt;/if&gt; &lt;if test="email != null"&gt; #&#123;email,jdbcType=VARCHAR&#125;, &lt;/if&gt; &lt;if test="regdate != null"&gt; #&#123;regdate,jdbcType=DATE&#125;, &lt;/if&gt; &lt;if test="sex != null"&gt; #&#123;sex,jdbcType=INTEGER&#125;, &lt;/if&gt; &lt;if test="head != null"&gt; #&#123;head,jdbcType=VARCHAR&#125;, &lt;/if&gt; &lt;/trim&gt; &lt;/insert&gt; &lt;update id="updateByPrimaryKeySelective" parameterType="com.zjm.model.User"&gt; update user &lt;set&gt; &lt;if test="nickname != null"&gt; nickName = #&#123;nickname,jdbcType=VARCHAR&#125;, &lt;/if&gt; &lt;if test="password != null"&gt; password = #&#123;password,jdbcType=VARCHAR&#125;, &lt;/if&gt; &lt;if test="phone != null"&gt; phone = #&#123;phone,jdbcType=VARCHAR&#125;, &lt;/if&gt; &lt;if test="email != null"&gt; email = #&#123;email,jdbcType=VARCHAR&#125;, &lt;/if&gt; &lt;if test="regdate != null"&gt; regDate = #&#123;regdate,jdbcType=DATE&#125;, &lt;/if&gt; &lt;if test="sex != null"&gt; sex = #&#123;sex,jdbcType=INTEGER&#125;, &lt;/if&gt; &lt;if test="head != null"&gt; head = #&#123;head,jdbcType=VARCHAR&#125;, &lt;/if&gt; &lt;/set&gt; where Id = #&#123;id,jdbcType=INTEGER&#125; &lt;/update&gt; &lt;update id="updateByPrimaryKey" parameterType="com.zjm.model.User"&gt; update user set nickName = #&#123;nickname,jdbcType=VARCHAR&#125;, password = #&#123;password,jdbcType=VARCHAR&#125;, phone = #&#123;phone,jdbcType=VARCHAR&#125;, email = #&#123;email,jdbcType=VARCHAR&#125;, regDate = #&#123;regdate,jdbcType=DATE&#125;, sex = #&#123;sex,jdbcType=INTEGER&#125;, head = #&#123;head,jdbcType=VARCHAR&#125; where Id = #&#123;id,jdbcType=INTEGER&#125; &lt;/update&gt;&lt;/mapper&gt; 测试类进入UserMapper.java，右键——Go to—— Test——Create new test 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172package com.zjm.dao;import com.zjm.model.User;import com.zjm.util.MD5;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.test.context.junit4.SpringRunner;import java.util.Date;import static org.junit.Assert.*;/** * Created by ZJM on 2017/4/5. */@SpringBootTest@RunWith(SpringJUnit4ClassRunner.class)public class UserMapperTest &#123; @Autowired private UserMapper userMapper; @Test public void deleteByPrimaryKey() throws Exception &#123; userMapper.deleteByPrimaryKey(2); &#125; @Test public void insert() throws Exception &#123; User user = new User(); user.setPhone("13636662259"); user.setSex(0); user.setEmail("7788521@qq.com"); user.setNickname("zjm"); user.setPassword("123456"); user.setRegdate(new Date()); userMapper.insert(user); &#125; @Test public void insertSelective() throws Exception &#123; &#125; @Test public void selectByPrimaryKey() throws Exception &#123; User user = userMapper.selectByPrimaryKey(1); System.out.println(user); &#125; @Test public void updateByPrimaryKeySelective() throws Exception &#123; User user = new User(); user.setId(1); user.setNickname("shaunHaHaHa"); userMapper.updateByPrimaryKeySelective(user); &#125; @Test public void updateByPrimaryKey() throws Exception &#123; &#125; @Test public void selectUserByExample() throws Exception &#123; User user = new User(); user.setPassword("123456"); System.out.println(userMapper.selectUserByExample(user)); &#125;&#125; 点击方法旁边的绿色按钮运行就行了 发请求测试上面的是 JUnit 的单元测试，现在用发请求的方式从服务器获取响应 正常需要在controller和mapper中间建立service层，这里示例业务简单，简化省去了service层，正式的项目中再加上 新建controller 在com.*.controller下新建UserMS.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package com.zjm.controller;import com.sun.javafx.collections.MappingChange;import com.zjm.dao.UserMapper;import com.zjm.model.User;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import javax.servlet.http.HttpServletResponse;import java.util.HashMap;import java.util.List;import java.util.Map;/** * Created by ZJM on 2017/4/8. */@RestController@RequestMapping("/user")public class UserMS &#123; @Autowired private UserMapper userMapper; @RequestMapping("add") public User add(User user) &#123; userMapper.insert(user); return user; &#125; @RequestMapping("delete") public Map&lt;String,Object&gt; delete(int id) &#123; Map&lt;String,Object&gt; map = new HashMap&lt;String,Object&gt;(); boolean isOk = true; try &#123; userMapper.deleteByPrimaryKey(id); &#125; catch (Exception e) &#123; e.printStackTrace(); isOk = false; &#125; map.put("status",isOk); return map; &#125; @RequestMapping("update") public User update(User user) &#123; userMapper.updateByPrimaryKeySelective(user); return user; &#125; @RequestMapping("findUserById") public User findUserById(int id) &#123; return userMapper.selectByPrimaryKey(id); &#125; @RequestMapping("findUserByExample") public List&lt;User&gt; findUserByExample(User user) &#123; return userMapper.selectUserByExample(user); &#125;&#125; 运行*Application.java文件点击绿色三角，即可启动 IntelliJ 自带的 tomcat，按照配置的服务名及端口访问吧 发请求安装postman或者浏览器发送请求 eg 1234http://localhost:8080/user/findUserById?id=1http://localhost:8080/user/findUserByExample?sex=1http://localhost:8080/user/delete?id=5http://localhost:8080/user/update?id=6&amp;nickname=小王 要是用浏览器发post请求还得写表单，post请求就用 postman 发吧 到此一个简单的例子就可以运行了]]></content>
      <categories>
        <category>Project</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>IntelliJ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos下安装jdk和Tomcat]]></title>
    <url>%2F2017%2F03%2F05%2Finstall-jdk-tomcat%2F</url>
    <content type="text"><![CDATA[用yum安装jdk查看 yum 库中都有哪些 jdk 版本（暂时只发现了 openjdk）yum search java|grep jdk 安装yum install java-1.7.0-openjdk 设置环境变量在profile文件中添加如下内容： 1234567#set java environmentJAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.131#复制路径以防路径无法找到JRE_HOME=$JAVA_HOME/jreCLASS_PATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libPATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binexport JAVA_HOME JRE_HOME CLASS_PATH PATH 让修改生效 source /etc/profile 验证java -version 安装Tomcat使用wget命令：wget -c http://apache.fayea.com/tomcat/tomcat-8/v8.5.11/bin/apache-tomcat-8.5.11.tar.gz 解压tar -zxvf apache-tomcat-8.5.11.tar.gz 启动进入解压后的apache-tomcat-8.5.11 -- bin目录，执行命令： ./startup.sh 检查能否访问如果不能访问，可能是防火墙问题： 关闭防火墙： service firewalld stop 在iptables里添加开放 8080 端口： -A RH-Firewall-1-INPUT -m state --state NEW -m tcp -p tcp --dport 8080 -j ACCEPT 将iptables服务重启： service iptables restart]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos下安装mysql]]></title>
    <url>%2F2017%2F03%2F05%2Finstall-mysql%2F</url>
    <content type="text"><![CDATA[yum 安装yum install -y mysql-server mysql mysql-devel 启动服务service mysqld start 给root用户设置密码mysqladmin -u root password &#39;your password&#39; 登录mysql -u root -p 查看并更改字符集show variables like &#39;character%&#39;; 关闭mysql服务 service mysqld stop 修改my.cnf文件 12345678910111213141516171819202122[mysqld]default-character-set = utf8 #这个是我添加的character_set_server=utf8 #这个是我添加的init_connect='SET NAMES utf8'datadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.sockuser=mysqlsymbolic-links=0 [mysqld_safe]default-character-set = utf8 #这个是我添加的log-error=/var/log/mysqld.logpid-file=/var/run/mysqld/mysqld.pid [client]default-character-set = utf8 #这个是我添加的 [mysql.server]default-character-set = utf8 #这个是我添加的 [mysql]default-character-set = utf8 #这个是我添加的 重启服务service mysqld restart 查看监听端口netstat -anp mysql数据库绑定的默认端口号是 3306 用本地可视化工具连接服务器数据库在服务器端进入mysql服务，执行： 12grant all privileges on *.* to &apos;root&apos;@&apos;%&apos; identified by &apos;your password by root&apos;;flush privileges; 在本地即可登录访问]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[priority_queue]]></title>
    <url>%2F2017%2F02%2F06%2Fpriority-queue%2F</url>
    <content type="text"><![CDATA[STL priority_queue 优先队列在优先队列中，优先级高的元素先出队列 class template std::priority_queue1234template &lt;class T, class Container = vector&lt;T&gt;, class Compare = less&lt;typename Container::value_type&gt; &gt; class priority_queue; Priority queuePriority queues are a type of container adaptors, specifically designed such that its first element is always the greatest of the elements it contains, according to some strict weak ordering criterion.This context is similar to a heap, where elements can be inserted at any moment, and only the max heapelement can be retrieved (the one at the top in the priority queue).Priority queues are implemented as container adaptors, which are classes that use an encapsulated object of a specific container class as its underlying container, providing a specific set of member functions to access its elements. Elements are popped from the “back” of the specific container, which is known as the top of the priority queue. The standard container classes vector and deque fulfill these requirements. By default, if no container class is specified for a particular priority_queue class instantiation, the standard container vector is used.Support of random access iterators is required to keep a heap structure internally at all times. This is done automatically by the container adaptor by automatically calling the algorithm functions make_heap, push_heap and pop_heap when needed. Template parameters T Type of the elements.Aliased as member type priority_queue::value_type. Container Type of the internal underlying container object where the elements are stored.Its value_type shall be T.Aliased as member type priority_queue::container_type. Compare A binary predicate that takes two elements (of type T) as arguments and returns a bool.The expression comp(a,b), where comp is an object of this type and a and b are elements in the container, shall return true if a is considered to go before b in the strict weak ordering the function defines.The priority_queue uses this function to maintain the elements sorted in a way that preserves heap properties (i.e., that the element popped is the last according to this strict weak ordering).This can be a function pointer or a function object, and defaults to less, which returns the same as applying the less-than operator (`a). 小结： priority_queue 将其中的元素默认按照从大到小排列 默认声明：priority_queue&lt; T , vector , less &gt; q; 默认声明可省略为：priority_queue q; 声明为从小到大：priority_queue&lt; T , vector , greater &gt; q; 如果T是自定义类型，则必须重载operator&lt; eg123456789101112131415161718192021222324252627282930313233#include&lt;iostream&gt;#include&lt;queue&gt;using namespace std;struct Student &#123; string name; int score; Student(string name,int score) &#123; this-&gt;name = name; this-&gt;score = score; &#125; friend bool operator &lt; (Student stu1,Student stu2) &#123; return stu1.score &lt; stu2.score; &#125;&#125;;int main()&#123; Student stu[3] = &#123; Student("Tom",80), Student("Jerry",100), Student("Marry",90) &#125;; priority_queue&lt;Student&gt; q; for(int i=0;i&lt;3;i++) &#123; q.push(stu[i]); &#125; cout&lt;&lt;q.size()&lt;&lt;endl; for(int i=0;i&lt;3;i++) &#123; Student s = q.top(); cout&lt;&lt;s.name&lt;&lt;", "&lt;&lt;s.score&lt;&lt;endl; q.pop(); &#125; return 0;&#125;]]></content>
      <categories>
        <category>OJ 做题</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法小结]]></title>
    <url>%2F2017%2F01%2F23%2Fsort%2F</url>
    <content type="text"><![CDATA[数据结构排序算法时空稳 分类 排序方法 平均情况(时) 最坏(时) 最好(时) 空间复杂度 稳定性 插入 直接插入 O(n*n) O(n*n) O(n) O(1) 稳 折半插入 O(n*n) O(1) 稳 希尔 O(nlogn) O(nlogn) O(1) 不稳 交换 冒泡 O(n*n) O(n*n) O(n) O(1) 稳 快速 O(nlogn) O(n*n) O(nlogn) O(logn) 不稳 选择 简单选择 O(n*n) O(n*n) O(n*n) O(1) 不稳 堆排 O(nlogn) O(nlogn) O(nlogn) O(1) 不稳 其他 归并 O(nlogn) O(nlogn) O(nlogn) O(n) 稳 基数 O(d(n+r)) O(d(n+r)) O(d(n+r)) O(r) 稳 常见排序java实现直接插入1234567891011121314public class InsertSort &#123; public static void isort(int[] data) &#123; for (int i=1; i&lt;data.length; i++) &#123; int temp = data[i]; int j = i-1; while (j &gt;=0 &amp;&amp; temp &lt; data[j]) &#123; data[j+1] = data[j--]; &#125; data[j+1] = temp; &#125; &#125; &#125; 选择12345678910111213141516171819public class SelectSort &#123; // 找到待排序中最小或者最大 public static void s_sort(int[] data) &#123; for (int i=0; i&lt;data.length-1; i++) &#123; int k = i; // 记录待排序中最小下标 for (int j=i+1; j&lt;data.length; j++) &#123; if (data[j] &lt; data[k]) &#123; k = j; &#125; &#125; // 将最小放到最前面 if (k != i) &#123; int temp = data[k]; data[k] = data[i]; data[i] = temp; &#125; &#125; &#125;&#125; 快排1234567891011121314151617181920212223242526272829303132333435public class QuickSort &#123; private static int[] arr; // 讲一个数字放到正确的位置，左边都比它小，右边都比它大 private static int partition(int low, int high) &#123; int label = arr[low]; while (low &lt; high) &#123; while (low &lt; high &amp;&amp; arr[high] &gt;= label) high --; arr[low] = arr[high]; while (low &lt; high &amp;&amp; arr[low] &lt;= label) low ++; arr[high] = arr[low]; &#125; arr[low] = label; return low; &#125; private static int[] qsort(int low, int high) &#123; if (low &lt; high) &#123; int mid = partition(low, high); qsort(low, mid-1); qsort(mid+1, high); &#125; return arr; &#125; public static int[] qsort(int[] data) &#123; arr = data; qsort(0, arr.length-1); return arr; &#125; &#125; 冒泡12345678910111213141516public class BubbleSort &#123; public static void bsort(int[] arr) &#123; int temp = 0; for (int i=0; i&lt;arr.length-1; i++) &#123; for (int j=arr.length-1; j&gt;i; j--) &#123; // 将小的前移 if (arr[j] &lt; arr[j-1]) &#123; temp = arr[j]; arr[j] = arr[j-1]; arr[j-1] = temp; &#125; &#125; &#125; &#125;&#125; 堆排归并1234567891011121314151617181920212223242526272829303132333435363738394041public class MergeSort &#123; private static int[] data; public static void sort(int[] arr) &#123; data = arr; mergeSort(1, data.length); &#125; private static void mergeSort(int start, int end) &#123; if (end &gt; start) &#123; int mid = (start + end) / 2; mergeSort(start, mid); mergeSort(mid+1, end); merge(start, mid, end); &#125; &#125; private static void merge(int start, int mid, int end) &#123; int len1 = mid - start + 1; int len2 = end - mid; int[] arr1 = new int[len1 + 1]; int[] arr2 = new int[len2 + 1]; for (int i=0; i&lt;len1; i++) &#123; arr1[i] = data[start+i-1]; &#125; arr1[len1] = Integer.MAX_VALUE; for (int i=0; i&lt;len2; i++) &#123; arr2[i] = data[i+mid]; &#125; arr2[len2] = Integer.MAX_VALUE; int m = 0, n = 0; for (int i=start-1; i&lt;end; i++) &#123; if (arr1[m] &gt; arr2[n]) &#123; data[i] = arr2[n++]; &#125; else &#123; data[i] = arr1[m++]; &#125; &#125; &#125;&#125; 希尔12345678910111213141516171819public class ShellSort &#123; public static void sort(int[] arr) &#123; for (int gap=arr.length/2; gap&gt;0; gap/=2) &#123; for (int i=gap; i&lt;arr.length; i++) &#123; int j = i; int temp = arr[j]; if (arr[j] &lt; arr[j-gap]) &#123; while (j-gap&gt;=0 &amp;&amp; temp &lt; arr[j-gap]) &#123; arr[j] = arr[j-gap]; j-=gap; &#125; arr[j] = temp; &#125; &#125; &#125; &#125; &#125; 计数桶排基数小口诀 冒泡选择插入堆，快速希尔计基堆归并O(n)快logn，其他空间都是1快堆归并nlogn，插折冒选慢n方（平均时间）希尔特殊1.3，基数d把两数加（平均时间）希尔快选堆不稳，其他排序稳稳哒 注： log 的 g 不发音 第二句空间复杂度，三四句时间]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git基本操作]]></title>
    <url>%2F2017%2F01%2F15%2FGit%2F</url>
    <content type="text"><![CDATA[Git 是目前最流行的版本管理系统 Windows系统安装和使用安装后会出现三个工具-Bash,-CMD,-GUI，只用-Bash就行 在你想作为本地仓库的文件夹上（或进入文件夹空白处）鼠标右键，选择Git Bash here 常用命令git clone​ 从远程主机复制文件到本地文件夹 1$ git clone &lt;链接&gt; &lt;本地路径&gt; ​ &lt;本地路径&gt;省略即-Bash当前路径 git remote 管理远程主机名：Git要求每个远程主机都必须指定一个主机名 添加远程主机+命名 1$ git remote add &lt;主机名&gt; &lt;网址&gt; 列出所有远程主机 12$ git remoteorigin 查看远程主机名对应的网址 123$ git remote -vorigin https://... (fetch)origin https://...(push) 删除主机 1$ git remote rm &lt;主机名&gt; 改主机名 1$ git remote rename &lt;原主机名&gt; &lt;新主机名&gt; git fetch 远程主机有更新（commit），将更新的取回本地。默认情况下git fetch 取回所有分支（branch）的更新。如果只想取回特定分支的更新，可以指定分支名。 1$ git fetch &lt;远程主机名&gt; &lt;分支名&gt; eg 1$ git fetch origin master 查看远程分支 123456$ git branch -rorigin/master #查看远程分支$ git branch -a #查看所有分支（包括本地）* master remotes/origin/master 在本地分支上合并远程分支 1$ git merge origin/master git pull 取回远程主机某分支的更新，并与本地的制定分支合并 1$ git pull &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt; 与当前分支合并冒号后可省略 eg 1$ git pull origin master 相当于 12$ git fetch origin$ git merge origin/master git push 将本地分支的更新，推送到远程主机 1$ git push &lt;远程主机名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt; eg 123$ git push origin master:master#等同于$ git push origin master 如果省略远程分支名，则表示将本地分支推送与之存在”追踪关系”的远程分支（通常两者同名），如果该远程分支不存在，则会被新建。 上面命令表示，将本地的master分支推送到origin主机的master分支。 省略本地分支名，则表示删除指定的远程分支，因为这等同于推送一个空的本地分支到远程分支 123$ git push origin :master# 等同于$ git push origin --delete master 上面命令表示删除origin主机的master分支 更详细资料请参照：https://www.git-scm.com/book/en/v2]]></content>
      <categories>
        <category>版本控制</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开篇]]></title>
    <url>%2F2017%2F01%2F13%2FBegin%2F</url>
    <content type="text"><![CDATA[自序​ 大家好，我是一个普通的大学生，2013年考入哈尔滨工程大学软件工程专业，2017年想写博客，已经24岁。人生正在紧要关口，大的决策呼之欲出。 ​ 现在的我，放假在家，感到有属于自己的时间无比宝贵，没有外事打扰，想干什么就干什么，以后怕是少有了，无比珍惜。每天能做自己喜欢做的事，玩也好，学也好，不必担心衣食住行，真是最后的天堂了。 ​ 想把自己的收获、乐趣、心得，想法通过网站向有缘来访的朋友分享，留住生命中的点滴。 ​ 这两天为了建一个博客站，忙来忙去找了很多资料，问了很多朋友。总算有了点成果，虽然就是读说明书，还是很费劲，遇到的问题层出不穷……我觉的程序员最宝贵的能力就是自学能力，敢于接触新鲜事物，读懂别人的文章，英文开发文档，自己把新技术掌握了，并有自己的理解。 ​ 现在的我还差很多，希望在朋友的帮助下，师长的指导下，一点一点的，不断进步。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>life</tag>
      </tags>
  </entry>
</search>
